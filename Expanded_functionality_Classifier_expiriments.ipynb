{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f7bf8861100>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import scanpy as sc\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import sklearn.preprocessing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple MPS on Macbook Pro\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "if platform.platform() == 'macOS-10.16-x86_64-i386-64bit':\n",
    "    pio.renderers.default = 'notebook'\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using Apple MPS on Macbook Pro\")\n",
    "    gmount = False\n",
    "    \n",
    "elif platform.platform() == 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic':\n",
    "    pio.renderers.default = 'colab'\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Using CUDA GPU on Colab\")\n",
    "        gmount = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scdata = sc.read_h5ad(\"/Users/eamonmcandrew/Desktop/Single_cell_integration/Data/Multi-ome/GEX.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gmount == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    path = '/content/drive/My Drive/Colab Notebooks/Experiments/' \n",
    "    scdata = sc.read_h5ad(\"/content/gdrive/MyDrive/scintegration/GEX.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GEX_Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "      def __init__(self, data,  scaler = None, cat_var = None, label_encoder =None):\n",
    "          \n",
    "            self.data = data\n",
    "            \n",
    "            # we need to work with the dense matrix\n",
    "            self.values = data.X.todense()\n",
    "            \n",
    "            self.cat_var = cat_var\n",
    "            \n",
    "            if label_encoder == \"numeric\":\n",
    "            # numerically encode the labels\n",
    "              cat_var_data =  torch.tensor(sklearn.preprocessing.LabelEncoder().fit_transform(self.data.obs[self.cat_var]), dtype = torch.long)\n",
    "            \n",
    "            elif label_encoder == \"range_map\":\n",
    "              cat_var_data =  sklearn.preprocessing.LabelEncoder().fit_transform(self.data.obs[self.cat_var])\n",
    "              cat_var_data = cat_var_data.reshape(-1, 1) \n",
    "              cat_var_data = torch.tensor(sklearn.preprocessing.MinMaxScaler().fit_transform(cat_var_data), dtype = torch.float32)\n",
    "\n",
    "            elif label_encoder == \"one_hot\":\n",
    "              cat_var_data =  torch.tensor(sklearn.preprocessing.LabelEncoder().fit_transform(self.data.obs[self.cat_var]))\n",
    "              cat_var_data = cat_var_data.reshape(-1, 1)\n",
    "              cat_var_data = sklearn.preprocessing.OneHotEncoder().fit_transform(cat_var_data).toarray()\n",
    "              cat_var_data = torch.tensor(cat_var_data, dtype=torch.float32)\n",
    "              \n",
    "\n",
    "\n",
    "\n",
    "            self.cat_var_data = torch.tensor(cat_var_data)\n",
    "            \n",
    "            # scale the data according to user inpt to scaler argument\n",
    "            if scaler == \"Standard\":\n",
    "                self.scaled_values = torch.tensor(sklearn.preprocessing.StandardScaler().fit_transform(self.values), dtype = torch.float32)\n",
    "            elif scaler == \"MinMax\":\n",
    "                self.scaled_values = torch.tensor(sklearn.preprocessing.MinMaxScaler().fit_transform(self.values),  dtype = torch.float32)\n",
    "            else:\n",
    "                self.scaled_values = torch.tensor(self.values, dtype = torch.float32)\n",
    "                \n",
    "    #   return the number of genes when called \n",
    "             \n",
    "      @property\n",
    "      def n_features(self):\n",
    "          return self.values.shape[1]\n",
    "\n",
    "      @property\n",
    "      def n_catagories(self):\n",
    "          return self.cat_var_data.shape[1]\n",
    "        \n",
    "      \n",
    "          \n",
    "          \n",
    "    #  A dataset class needs the following two methods to work with the dataloader class     \n",
    "          \n",
    "    #   return the number of cells when called\n",
    "      def __len__(self):\n",
    "          return len(self.data)\n",
    "    \n",
    "    #  return an individual cell and its label when called\n",
    "      def __getitem__(self, idx):\n",
    "           return self.scaled_values[idx], self.cat_var_data[idx]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mw/_f0gy0f54t739qb79y8cxb_40000gn/T/ipykernel_5920/612472411.py:30: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "/Users/eamonmcandrew/opt/anaconda3/envs/scINTEGRATION/lib/python3.9/site-packages/sklearn/utils/validation.py:727: FutureWarning:\n",
      "\n",
      "np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "\n",
      "/Users/eamonmcandrew/opt/anaconda3/envs/scINTEGRATION/lib/python3.9/site-packages/sklearn/utils/validation.py:727: FutureWarning:\n",
      "\n",
      "np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GEX_Dataset = GEX_Dataset(scdata, scaler = \"Standard\", cat_var = \"batch\", label_encoder = \"one_hot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = GEX_Dataset.n_features\n",
    "output_size = GEX_Dataset.n_catagories\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "lr = 1e-3\n",
    "\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(classifier, self).__init__()\n",
    "        self.cfc1 = nn.Linear(input_size, 20)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.cfc2 = nn.Linear(20, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cfc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.cfc2(x)\n",
    "        x = F.softmax(x, dim = 1)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEX_dataloader = DataLoader(GEX_Dataset, batch_size=batch_size, shuffle=True)\n",
    "model = classifier()\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "model.train()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 0 [0/69249 (0%)]\tLoss: 2.566708, mean accuracy last epoch: 0.047\n",
      "Train Epoch 0 [2560/69249 (4%)]\tLoss: 2.421740, mean accuracy last epoch: 0.246\n",
      "Train Epoch 0 [5120/69249 (7%)]\tLoss: 2.362178, mean accuracy last epoch: 0.286\n",
      "Train Epoch 0 [7680/69249 (11%)]\tLoss: 2.259942, mean accuracy last epoch: 0.323\n",
      "Train Epoch 0 [10240/69249 (15%)]\tLoss: 2.269328, mean accuracy last epoch: 0.348\n",
      "Train Epoch 0 [12800/69249 (18%)]\tLoss: 2.272182, mean accuracy last epoch: 0.370\n",
      "Train Epoch 0 [15360/69249 (22%)]\tLoss: 2.215322, mean accuracy last epoch: 0.390\n",
      "Train Epoch 0 [17920/69249 (26%)]\tLoss: 2.266950, mean accuracy last epoch: 0.405\n",
      "Train Epoch 0 [20480/69249 (30%)]\tLoss: 2.176337, mean accuracy last epoch: 0.421\n",
      "Train Epoch 0 [23040/69249 (33%)]\tLoss: 2.117740, mean accuracy last epoch: 0.434\n",
      "Train Epoch 0 [25600/69249 (37%)]\tLoss: 2.205539, mean accuracy last epoch: 0.443\n",
      "Train Epoch 0 [28160/69249 (41%)]\tLoss: 2.135025, mean accuracy last epoch: 0.454\n",
      "Train Epoch 0 [30720/69249 (44%)]\tLoss: 2.141325, mean accuracy last epoch: 0.464\n",
      "Train Epoch 0 [33280/69249 (48%)]\tLoss: 2.087182, mean accuracy last epoch: 0.474\n",
      "Train Epoch 0 [35840/69249 (52%)]\tLoss: 2.107880, mean accuracy last epoch: 0.482\n",
      "Train Epoch 0 [38400/69249 (55%)]\tLoss: 2.089176, mean accuracy last epoch: 0.490\n",
      "Train Epoch 0 [40960/69249 (59%)]\tLoss: 2.073979, mean accuracy last epoch: 0.498\n",
      "Train Epoch 0 [43520/69249 (63%)]\tLoss: 2.116573, mean accuracy last epoch: 0.505\n",
      "Train Epoch 0 [46080/69249 (66%)]\tLoss: 2.113703, mean accuracy last epoch: 0.511\n",
      "Train Epoch 0 [48640/69249 (70%)]\tLoss: 2.083142, mean accuracy last epoch: 0.517\n",
      "Train Epoch 0 [51200/69249 (74%)]\tLoss: 2.081256, mean accuracy last epoch: 0.523\n",
      "Train Epoch 0 [53760/69249 (77%)]\tLoss: 2.107564, mean accuracy last epoch: 0.528\n",
      "Train Epoch 0 [56320/69249 (81%)]\tLoss: 2.033841, mean accuracy last epoch: 0.534\n",
      "Train Epoch 0 [58880/69249 (85%)]\tLoss: 2.062114, mean accuracy last epoch: 0.539\n",
      "Train Epoch 0 [61440/69249 (89%)]\tLoss: 2.085217, mean accuracy last epoch: 0.543\n",
      "Train Epoch 0 [64000/69249 (92%)]\tLoss: 2.078305, mean accuracy last epoch: 0.548\n",
      "Train Epoch 0 [66560/69249 (96%)]\tLoss: 2.058204, mean accuracy last epoch: 0.552\n",
      "Train Epoch 0 [34830/69249 (100%)]\tLoss: 2.023282, mean accuracy last epoch: 0.556\n",
      "Train Epoch 1 [0/69249 (0%)]\tLoss: 2.012303, mean accuracy last epoch: 0.556\n",
      "Train Epoch 1 [2560/69249 (4%)]\tLoss: 2.027202, mean accuracy last epoch: 0.561\n",
      "Train Epoch 1 [5120/69249 (7%)]\tLoss: 1.979990, mean accuracy last epoch: 0.564\n",
      "Train Epoch 1 [7680/69249 (11%)]\tLoss: 2.040332, mean accuracy last epoch: 0.568\n",
      "Train Epoch 1 [10240/69249 (15%)]\tLoss: 1.973609, mean accuracy last epoch: 0.573\n",
      "Train Epoch 1 [12800/69249 (18%)]\tLoss: 2.043441, mean accuracy last epoch: 0.576\n",
      "Train Epoch 1 [15360/69249 (22%)]\tLoss: 2.049389, mean accuracy last epoch: 0.579\n",
      "Train Epoch 1 [17920/69249 (26%)]\tLoss: 1.922153, mean accuracy last epoch: 0.583\n",
      "Train Epoch 1 [20480/69249 (30%)]\tLoss: 1.967452, mean accuracy last epoch: 0.586\n",
      "Train Epoch 1 [23040/69249 (33%)]\tLoss: 2.021956, mean accuracy last epoch: 0.589\n",
      "Train Epoch 1 [25600/69249 (37%)]\tLoss: 1.949423, mean accuracy last epoch: 0.592\n",
      "Train Epoch 1 [28160/69249 (41%)]\tLoss: 1.946177, mean accuracy last epoch: 0.594\n",
      "Train Epoch 1 [30720/69249 (44%)]\tLoss: 2.009279, mean accuracy last epoch: 0.596\n",
      "Train Epoch 1 [33280/69249 (48%)]\tLoss: 2.075068, mean accuracy last epoch: 0.599\n",
      "Train Epoch 1 [35840/69249 (52%)]\tLoss: 1.982969, mean accuracy last epoch: 0.601\n",
      "Train Epoch 1 [38400/69249 (55%)]\tLoss: 1.967010, mean accuracy last epoch: 0.603\n",
      "Train Epoch 1 [40960/69249 (59%)]\tLoss: 2.012371, mean accuracy last epoch: 0.605\n",
      "Train Epoch 1 [43520/69249 (63%)]\tLoss: 2.022583, mean accuracy last epoch: 0.607\n",
      "Train Epoch 1 [46080/69249 (66%)]\tLoss: 2.033787, mean accuracy last epoch: 0.609\n",
      "Train Epoch 1 [48640/69249 (70%)]\tLoss: 2.027429, mean accuracy last epoch: 0.611\n",
      "Train Epoch 1 [51200/69249 (74%)]\tLoss: 1.997061, mean accuracy last epoch: 0.613\n",
      "Train Epoch 1 [53760/69249 (77%)]\tLoss: 1.968730, mean accuracy last epoch: 0.614\n",
      "Train Epoch 1 [56320/69249 (81%)]\tLoss: 1.998669, mean accuracy last epoch: 0.616\n",
      "Train Epoch 1 [58880/69249 (85%)]\tLoss: 1.973976, mean accuracy last epoch: 0.618\n",
      "Train Epoch 1 [61440/69249 (89%)]\tLoss: 2.017293, mean accuracy last epoch: 0.620\n",
      "Train Epoch 1 [64000/69249 (92%)]\tLoss: 2.059556, mean accuracy last epoch: 0.621\n",
      "Train Epoch 1 [66560/69249 (96%)]\tLoss: 2.002639, mean accuracy last epoch: 0.622\n",
      "Train Epoch 1 [34830/69249 (100%)]\tLoss: 2.007825, mean accuracy last epoch: 0.624\n",
      "Train Epoch 2 [0/69249 (0%)]\tLoss: 1.973525, mean accuracy last epoch: 0.624\n",
      "Train Epoch 2 [2560/69249 (4%)]\tLoss: 1.980419, mean accuracy last epoch: 0.625\n",
      "Train Epoch 2 [5120/69249 (7%)]\tLoss: 1.998837, mean accuracy last epoch: 0.627\n",
      "Train Epoch 2 [7680/69249 (11%)]\tLoss: 1.977904, mean accuracy last epoch: 0.628\n",
      "Train Epoch 2 [10240/69249 (15%)]\tLoss: 1.980180, mean accuracy last epoch: 0.630\n",
      "Train Epoch 2 [12800/69249 (18%)]\tLoss: 2.068455, mean accuracy last epoch: 0.631\n",
      "Train Epoch 2 [15360/69249 (22%)]\tLoss: 1.970117, mean accuracy last epoch: 0.632\n",
      "Train Epoch 2 [17920/69249 (26%)]\tLoss: 1.919599, mean accuracy last epoch: 0.634\n",
      "Train Epoch 2 [20480/69249 (30%)]\tLoss: 1.965014, mean accuracy last epoch: 0.635\n",
      "Train Epoch 2 [23040/69249 (33%)]\tLoss: 1.995195, mean accuracy last epoch: 0.636\n",
      "Train Epoch 2 [25600/69249 (37%)]\tLoss: 1.960917, mean accuracy last epoch: 0.638\n",
      "Train Epoch 2 [28160/69249 (41%)]\tLoss: 1.950682, mean accuracy last epoch: 0.639\n",
      "Train Epoch 2 [30720/69249 (44%)]\tLoss: 1.979449, mean accuracy last epoch: 0.640\n",
      "Train Epoch 2 [33280/69249 (48%)]\tLoss: 1.969741, mean accuracy last epoch: 0.641\n",
      "Train Epoch 2 [35840/69249 (52%)]\tLoss: 2.002110, mean accuracy last epoch: 0.642\n",
      "Train Epoch 2 [38400/69249 (55%)]\tLoss: 1.957340, mean accuracy last epoch: 0.643\n",
      "Train Epoch 2 [40960/69249 (59%)]\tLoss: 1.972100, mean accuracy last epoch: 0.644\n",
      "Train Epoch 2 [43520/69249 (63%)]\tLoss: 1.963963, mean accuracy last epoch: 0.645\n",
      "Train Epoch 2 [46080/69249 (66%)]\tLoss: 1.995258, mean accuracy last epoch: 0.646\n",
      "Train Epoch 2 [48640/69249 (70%)]\tLoss: 1.995435, mean accuracy last epoch: 0.646\n",
      "Train Epoch 2 [51200/69249 (74%)]\tLoss: 2.038554, mean accuracy last epoch: 0.647\n",
      "Train Epoch 2 [53760/69249 (77%)]\tLoss: 1.954791, mean accuracy last epoch: 0.649\n",
      "Train Epoch 2 [56320/69249 (81%)]\tLoss: 1.963747, mean accuracy last epoch: 0.649\n",
      "Train Epoch 2 [58880/69249 (85%)]\tLoss: 2.004970, mean accuracy last epoch: 0.650\n",
      "Train Epoch 2 [61440/69249 (89%)]\tLoss: 1.989344, mean accuracy last epoch: 0.651\n",
      "Train Epoch 2 [64000/69249 (92%)]\tLoss: 1.928733, mean accuracy last epoch: 0.651\n",
      "Train Epoch 2 [66560/69249 (96%)]\tLoss: 1.968281, mean accuracy last epoch: 0.652\n",
      "Train Epoch 2 [34830/69249 (100%)]\tLoss: 1.959829, mean accuracy last epoch: 0.653\n",
      "Train Epoch 3 [0/69249 (0%)]\tLoss: 2.012432, mean accuracy last epoch: 0.653\n",
      "Train Epoch 3 [2560/69249 (4%)]\tLoss: 1.961015, mean accuracy last epoch: 0.654\n",
      "Train Epoch 3 [5120/69249 (7%)]\tLoss: 1.966385, mean accuracy last epoch: 0.655\n",
      "Train Epoch 3 [7680/69249 (11%)]\tLoss: 1.926621, mean accuracy last epoch: 0.656\n",
      "Train Epoch 3 [10240/69249 (15%)]\tLoss: 2.011394, mean accuracy last epoch: 0.656\n",
      "Train Epoch 3 [12800/69249 (18%)]\tLoss: 1.946965, mean accuracy last epoch: 0.657\n",
      "Train Epoch 3 [15360/69249 (22%)]\tLoss: 1.945108, mean accuracy last epoch: 0.658\n",
      "Train Epoch 3 [17920/69249 (26%)]\tLoss: 1.995732, mean accuracy last epoch: 0.659\n",
      "Train Epoch 3 [20480/69249 (30%)]\tLoss: 1.976795, mean accuracy last epoch: 0.659\n",
      "Train Epoch 3 [23040/69249 (33%)]\tLoss: 1.960061, mean accuracy last epoch: 0.660\n",
      "Train Epoch 3 [25600/69249 (37%)]\tLoss: 1.994608, mean accuracy last epoch: 0.661\n",
      "Train Epoch 3 [28160/69249 (41%)]\tLoss: 1.975197, mean accuracy last epoch: 0.661\n",
      "Train Epoch 3 [30720/69249 (44%)]\tLoss: 1.941503, mean accuracy last epoch: 0.662\n",
      "Train Epoch 3 [33280/69249 (48%)]\tLoss: 1.961583, mean accuracy last epoch: 0.663\n",
      "Train Epoch 3 [35840/69249 (52%)]\tLoss: 1.978677, mean accuracy last epoch: 0.663\n",
      "Train Epoch 3 [38400/69249 (55%)]\tLoss: 1.956166, mean accuracy last epoch: 0.664\n",
      "Train Epoch 3 [40960/69249 (59%)]\tLoss: 1.961704, mean accuracy last epoch: 0.664\n",
      "Train Epoch 3 [43520/69249 (63%)]\tLoss: 1.976050, mean accuracy last epoch: 0.665\n",
      "Train Epoch 3 [46080/69249 (66%)]\tLoss: 1.952880, mean accuracy last epoch: 0.666\n",
      "Train Epoch 3 [48640/69249 (70%)]\tLoss: 1.954630, mean accuracy last epoch: 0.666\n",
      "Train Epoch 3 [51200/69249 (74%)]\tLoss: 1.973153, mean accuracy last epoch: 0.667\n",
      "Train Epoch 3 [53760/69249 (77%)]\tLoss: 1.996444, mean accuracy last epoch: 0.667\n",
      "Train Epoch 3 [56320/69249 (81%)]\tLoss: 1.890279, mean accuracy last epoch: 0.668\n",
      "Train Epoch 3 [58880/69249 (85%)]\tLoss: 1.959651, mean accuracy last epoch: 0.669\n",
      "Train Epoch 3 [61440/69249 (89%)]\tLoss: 1.895230, mean accuracy last epoch: 0.669\n",
      "Train Epoch 3 [64000/69249 (92%)]\tLoss: 1.899197, mean accuracy last epoch: 0.670\n",
      "Train Epoch 3 [66560/69249 (96%)]\tLoss: 1.952501, mean accuracy last epoch: 0.671\n",
      "Train Epoch 3 [34830/69249 (100%)]\tLoss: 1.936682, mean accuracy last epoch: 0.672\n",
      "Train Epoch 4 [0/69249 (0%)]\tLoss: 1.926122, mean accuracy last epoch: 0.672\n",
      "Train Epoch 4 [2560/69249 (4%)]\tLoss: 1.953072, mean accuracy last epoch: 0.673\n",
      "Train Epoch 4 [5120/69249 (7%)]\tLoss: 1.975614, mean accuracy last epoch: 0.674\n",
      "Train Epoch 4 [7680/69249 (11%)]\tLoss: 1.960884, mean accuracy last epoch: 0.675\n",
      "Train Epoch 4 [10240/69249 (15%)]\tLoss: 1.928889, mean accuracy last epoch: 0.676\n",
      "Train Epoch 4 [12800/69249 (18%)]\tLoss: 1.940119, mean accuracy last epoch: 0.676\n",
      "Train Epoch 4 [15360/69249 (22%)]\tLoss: 1.927572, mean accuracy last epoch: 0.677\n",
      "Train Epoch 4 [17920/69249 (26%)]\tLoss: 1.900364, mean accuracy last epoch: 0.678\n",
      "Train Epoch 4 [20480/69249 (30%)]\tLoss: 1.917866, mean accuracy last epoch: 0.679\n",
      "Train Epoch 4 [23040/69249 (33%)]\tLoss: 1.912125, mean accuracy last epoch: 0.680\n",
      "Train Epoch 4 [25600/69249 (37%)]\tLoss: 1.943556, mean accuracy last epoch: 0.680\n",
      "Train Epoch 4 [28160/69249 (41%)]\tLoss: 1.925976, mean accuracy last epoch: 0.681\n",
      "Train Epoch 4 [30720/69249 (44%)]\tLoss: 1.896613, mean accuracy last epoch: 0.682\n",
      "Train Epoch 4 [33280/69249 (48%)]\tLoss: 1.893077, mean accuracy last epoch: 0.683\n",
      "Train Epoch 4 [35840/69249 (52%)]\tLoss: 1.930985, mean accuracy last epoch: 0.684\n",
      "Train Epoch 4 [38400/69249 (55%)]\tLoss: 1.966029, mean accuracy last epoch: 0.684\n",
      "Train Epoch 4 [40960/69249 (59%)]\tLoss: 1.900579, mean accuracy last epoch: 0.685\n",
      "Train Epoch 4 [43520/69249 (63%)]\tLoss: 1.880573, mean accuracy last epoch: 0.686\n",
      "Train Epoch 4 [46080/69249 (66%)]\tLoss: 1.931463, mean accuracy last epoch: 0.686\n",
      "Train Epoch 4 [48640/69249 (70%)]\tLoss: 1.940212, mean accuracy last epoch: 0.687\n",
      "Train Epoch 4 [51200/69249 (74%)]\tLoss: 1.953578, mean accuracy last epoch: 0.688\n",
      "Train Epoch 4 [53760/69249 (77%)]\tLoss: 1.962405, mean accuracy last epoch: 0.689\n",
      "Train Epoch 4 [56320/69249 (81%)]\tLoss: 1.890255, mean accuracy last epoch: 0.689\n",
      "Train Epoch 4 [58880/69249 (85%)]\tLoss: 1.944307, mean accuracy last epoch: 0.690\n",
      "Train Epoch 4 [61440/69249 (89%)]\tLoss: 1.900150, mean accuracy last epoch: 0.691\n",
      "Train Epoch 4 [64000/69249 (92%)]\tLoss: 1.967412, mean accuracy last epoch: 0.691\n",
      "Train Epoch 4 [66560/69249 (96%)]\tLoss: 1.886126, mean accuracy last epoch: 0.692\n",
      "Train Epoch 4 [34830/69249 (100%)]\tLoss: 1.953594, mean accuracy last epoch: 0.692\n",
      "Train Epoch 5 [0/69249 (0%)]\tLoss: 1.927619, mean accuracy last epoch: 0.692\n",
      "Train Epoch 5 [2560/69249 (4%)]\tLoss: 1.958477, mean accuracy last epoch: 0.693\n",
      "Train Epoch 5 [5120/69249 (7%)]\tLoss: 1.859378, mean accuracy last epoch: 0.694\n",
      "Train Epoch 5 [7680/69249 (11%)]\tLoss: 1.912553, mean accuracy last epoch: 0.694\n",
      "Train Epoch 5 [10240/69249 (15%)]\tLoss: 1.921082, mean accuracy last epoch: 0.695\n",
      "Train Epoch 5 [12800/69249 (18%)]\tLoss: 1.912187, mean accuracy last epoch: 0.696\n",
      "Train Epoch 5 [15360/69249 (22%)]\tLoss: 1.874535, mean accuracy last epoch: 0.696\n",
      "Train Epoch 5 [17920/69249 (26%)]\tLoss: 1.915877, mean accuracy last epoch: 0.697\n",
      "Train Epoch 5 [20480/69249 (30%)]\tLoss: 1.942828, mean accuracy last epoch: 0.697\n",
      "Train Epoch 5 [23040/69249 (33%)]\tLoss: 1.949956, mean accuracy last epoch: 0.698\n",
      "Train Epoch 5 [25600/69249 (37%)]\tLoss: 1.896456, mean accuracy last epoch: 0.699\n",
      "Train Epoch 5 [28160/69249 (41%)]\tLoss: 1.923789, mean accuracy last epoch: 0.699\n",
      "Train Epoch 5 [30720/69249 (44%)]\tLoss: 1.927842, mean accuracy last epoch: 0.700\n",
      "Train Epoch 5 [33280/69249 (48%)]\tLoss: 1.939927, mean accuracy last epoch: 0.700\n",
      "Train Epoch 5 [35840/69249 (52%)]\tLoss: 1.905785, mean accuracy last epoch: 0.701\n",
      "Train Epoch 5 [38400/69249 (55%)]\tLoss: 1.914974, mean accuracy last epoch: 0.701\n",
      "Train Epoch 5 [40960/69249 (59%)]\tLoss: 1.905682, mean accuracy last epoch: 0.702\n",
      "Train Epoch 5 [43520/69249 (63%)]\tLoss: 1.875978, mean accuracy last epoch: 0.703\n",
      "Train Epoch 5 [46080/69249 (66%)]\tLoss: 1.887568, mean accuracy last epoch: 0.703\n",
      "Train Epoch 5 [48640/69249 (70%)]\tLoss: 1.884776, mean accuracy last epoch: 0.704\n",
      "Train Epoch 5 [51200/69249 (74%)]\tLoss: 1.909394, mean accuracy last epoch: 0.704\n",
      "Train Epoch 5 [53760/69249 (77%)]\tLoss: 1.926092, mean accuracy last epoch: 0.705\n",
      "Train Epoch 5 [56320/69249 (81%)]\tLoss: 1.887217, mean accuracy last epoch: 0.705\n",
      "Train Epoch 5 [58880/69249 (85%)]\tLoss: 1.940970, mean accuracy last epoch: 0.706\n",
      "Train Epoch 5 [61440/69249 (89%)]\tLoss: 1.951757, mean accuracy last epoch: 0.706\n",
      "Train Epoch 5 [64000/69249 (92%)]\tLoss: 1.901299, mean accuracy last epoch: 0.706\n",
      "Train Epoch 5 [66560/69249 (96%)]\tLoss: 1.928766, mean accuracy last epoch: 0.707\n",
      "Train Epoch 5 [34830/69249 (100%)]\tLoss: 1.939395, mean accuracy last epoch: 0.707\n",
      "Train Epoch 6 [0/69249 (0%)]\tLoss: 1.915691, mean accuracy last epoch: 0.707\n",
      "Train Epoch 6 [2560/69249 (4%)]\tLoss: 1.919681, mean accuracy last epoch: 0.708\n",
      "Train Epoch 6 [5120/69249 (7%)]\tLoss: 1.908273, mean accuracy last epoch: 0.708\n",
      "Train Epoch 6 [7680/69249 (11%)]\tLoss: 1.887637, mean accuracy last epoch: 0.709\n",
      "Train Epoch 6 [10240/69249 (15%)]\tLoss: 1.945776, mean accuracy last epoch: 0.709\n",
      "Train Epoch 6 [12800/69249 (18%)]\tLoss: 1.930750, mean accuracy last epoch: 0.710\n",
      "Train Epoch 6 [15360/69249 (22%)]\tLoss: 1.885782, mean accuracy last epoch: 0.710\n",
      "Train Epoch 6 [17920/69249 (26%)]\tLoss: 1.918882, mean accuracy last epoch: 0.711\n",
      "Train Epoch 6 [20480/69249 (30%)]\tLoss: 1.952306, mean accuracy last epoch: 0.711\n",
      "Train Epoch 6 [23040/69249 (33%)]\tLoss: 1.937601, mean accuracy last epoch: 0.711\n",
      "Train Epoch 6 [25600/69249 (37%)]\tLoss: 1.903417, mean accuracy last epoch: 0.712\n",
      "Train Epoch 6 [28160/69249 (41%)]\tLoss: 1.881219, mean accuracy last epoch: 0.712\n",
      "Train Epoch 6 [30720/69249 (44%)]\tLoss: 1.928686, mean accuracy last epoch: 0.713\n",
      "Train Epoch 6 [33280/69249 (48%)]\tLoss: 1.915427, mean accuracy last epoch: 0.713\n",
      "Train Epoch 6 [35840/69249 (52%)]\tLoss: 1.939642, mean accuracy last epoch: 0.714\n",
      "Train Epoch 6 [38400/69249 (55%)]\tLoss: 1.920422, mean accuracy last epoch: 0.714\n",
      "Train Epoch 6 [40960/69249 (59%)]\tLoss: 1.877991, mean accuracy last epoch: 0.715\n",
      "Train Epoch 6 [43520/69249 (63%)]\tLoss: 1.876113, mean accuracy last epoch: 0.715\n",
      "Train Epoch 6 [46080/69249 (66%)]\tLoss: 1.864859, mean accuracy last epoch: 0.715\n",
      "Train Epoch 6 [48640/69249 (70%)]\tLoss: 1.874403, mean accuracy last epoch: 0.716\n",
      "Train Epoch 6 [51200/69249 (74%)]\tLoss: 1.888714, mean accuracy last epoch: 0.716\n",
      "Train Epoch 6 [53760/69249 (77%)]\tLoss: 1.892230, mean accuracy last epoch: 0.717\n",
      "Train Epoch 6 [56320/69249 (81%)]\tLoss: 1.907133, mean accuracy last epoch: 0.717\n",
      "Train Epoch 6 [58880/69249 (85%)]\tLoss: 1.904222, mean accuracy last epoch: 0.717\n",
      "Train Epoch 6 [61440/69249 (89%)]\tLoss: 1.909635, mean accuracy last epoch: 0.718\n",
      "Train Epoch 6 [64000/69249 (92%)]\tLoss: 1.861412, mean accuracy last epoch: 0.718\n",
      "Train Epoch 6 [66560/69249 (96%)]\tLoss: 1.872669, mean accuracy last epoch: 0.718\n",
      "Train Epoch 6 [34830/69249 (100%)]\tLoss: 1.887606, mean accuracy last epoch: 0.719\n",
      "Train Epoch 7 [0/69249 (0%)]\tLoss: 1.908732, mean accuracy last epoch: 0.719\n",
      "Train Epoch 7 [2560/69249 (4%)]\tLoss: 1.927773, mean accuracy last epoch: 0.719\n",
      "Train Epoch 7 [5120/69249 (7%)]\tLoss: 1.884198, mean accuracy last epoch: 0.720\n",
      "Train Epoch 7 [7680/69249 (11%)]\tLoss: 1.870863, mean accuracy last epoch: 0.720\n",
      "Train Epoch 7 [10240/69249 (15%)]\tLoss: 1.940336, mean accuracy last epoch: 0.720\n",
      "Train Epoch 7 [12800/69249 (18%)]\tLoss: 1.887260, mean accuracy last epoch: 0.721\n",
      "Train Epoch 7 [15360/69249 (22%)]\tLoss: 1.897256, mean accuracy last epoch: 0.721\n",
      "Train Epoch 7 [17920/69249 (26%)]\tLoss: 1.871997, mean accuracy last epoch: 0.721\n",
      "Train Epoch 7 [20480/69249 (30%)]\tLoss: 1.904867, mean accuracy last epoch: 0.722\n",
      "Train Epoch 7 [23040/69249 (33%)]\tLoss: 1.919612, mean accuracy last epoch: 0.722\n",
      "Train Epoch 7 [25600/69249 (37%)]\tLoss: 1.894261, mean accuracy last epoch: 0.722\n",
      "Train Epoch 7 [28160/69249 (41%)]\tLoss: 1.894841, mean accuracy last epoch: 0.723\n",
      "Train Epoch 7 [30720/69249 (44%)]\tLoss: 1.909666, mean accuracy last epoch: 0.723\n",
      "Train Epoch 7 [33280/69249 (48%)]\tLoss: 1.893784, mean accuracy last epoch: 0.723\n",
      "Train Epoch 7 [35840/69249 (52%)]\tLoss: 1.956777, mean accuracy last epoch: 0.724\n",
      "Train Epoch 7 [38400/69249 (55%)]\tLoss: 1.880953, mean accuracy last epoch: 0.724\n",
      "Train Epoch 7 [40960/69249 (59%)]\tLoss: 1.951309, mean accuracy last epoch: 0.724\n",
      "Train Epoch 7 [43520/69249 (63%)]\tLoss: 1.873486, mean accuracy last epoch: 0.725\n",
      "Train Epoch 7 [46080/69249 (66%)]\tLoss: 1.910247, mean accuracy last epoch: 0.725\n",
      "Train Epoch 7 [48640/69249 (70%)]\tLoss: 1.921044, mean accuracy last epoch: 0.725\n",
      "Train Epoch 7 [51200/69249 (74%)]\tLoss: 1.922094, mean accuracy last epoch: 0.726\n",
      "Train Epoch 7 [53760/69249 (77%)]\tLoss: 1.903338, mean accuracy last epoch: 0.726\n",
      "Train Epoch 7 [56320/69249 (81%)]\tLoss: 1.900283, mean accuracy last epoch: 0.726\n",
      "Train Epoch 7 [58880/69249 (85%)]\tLoss: 1.899845, mean accuracy last epoch: 0.726\n",
      "Train Epoch 7 [61440/69249 (89%)]\tLoss: 1.889157, mean accuracy last epoch: 0.727\n",
      "Train Epoch 7 [64000/69249 (92%)]\tLoss: 1.923640, mean accuracy last epoch: 0.727\n",
      "Train Epoch 7 [66560/69249 (96%)]\tLoss: 1.914892, mean accuracy last epoch: 0.727\n",
      "Train Epoch 7 [34830/69249 (100%)]\tLoss: 1.908879, mean accuracy last epoch: 0.728\n",
      "Train Epoch 8 [0/69249 (0%)]\tLoss: 1.910011, mean accuracy last epoch: 0.728\n",
      "Train Epoch 8 [2560/69249 (4%)]\tLoss: 1.944284, mean accuracy last epoch: 0.728\n",
      "Train Epoch 8 [5120/69249 (7%)]\tLoss: 1.920821, mean accuracy last epoch: 0.728\n",
      "Train Epoch 8 [7680/69249 (11%)]\tLoss: 1.901792, mean accuracy last epoch: 0.728\n",
      "Train Epoch 8 [10240/69249 (15%)]\tLoss: 1.897882, mean accuracy last epoch: 0.729\n",
      "Train Epoch 8 [12800/69249 (18%)]\tLoss: 1.920886, mean accuracy last epoch: 0.729\n",
      "Train Epoch 8 [15360/69249 (22%)]\tLoss: 1.917390, mean accuracy last epoch: 0.729\n",
      "Train Epoch 8 [17920/69249 (26%)]\tLoss: 1.887431, mean accuracy last epoch: 0.729\n",
      "Train Epoch 8 [20480/69249 (30%)]\tLoss: 1.915581, mean accuracy last epoch: 0.730\n",
      "Train Epoch 8 [23040/69249 (33%)]\tLoss: 1.916123, mean accuracy last epoch: 0.730\n",
      "Train Epoch 8 [25600/69249 (37%)]\tLoss: 1.921551, mean accuracy last epoch: 0.730\n",
      "Train Epoch 8 [28160/69249 (41%)]\tLoss: 1.917970, mean accuracy last epoch: 0.730\n",
      "Train Epoch 8 [30720/69249 (44%)]\tLoss: 1.908280, mean accuracy last epoch: 0.731\n",
      "Train Epoch 8 [33280/69249 (48%)]\tLoss: 1.873018, mean accuracy last epoch: 0.731\n",
      "Train Epoch 8 [35840/69249 (52%)]\tLoss: 1.888095, mean accuracy last epoch: 0.731\n",
      "Train Epoch 8 [38400/69249 (55%)]\tLoss: 1.914913, mean accuracy last epoch: 0.732\n",
      "Train Epoch 8 [40960/69249 (59%)]\tLoss: 1.880220, mean accuracy last epoch: 0.732\n",
      "Train Epoch 8 [43520/69249 (63%)]\tLoss: 1.871006, mean accuracy last epoch: 0.732\n",
      "Train Epoch 8 [46080/69249 (66%)]\tLoss: 1.892827, mean accuracy last epoch: 0.732\n",
      "Train Epoch 8 [48640/69249 (70%)]\tLoss: 1.890631, mean accuracy last epoch: 0.732\n",
      "Train Epoch 8 [51200/69249 (74%)]\tLoss: 1.909924, mean accuracy last epoch: 0.733\n",
      "Train Epoch 8 [53760/69249 (77%)]\tLoss: 1.847067, mean accuracy last epoch: 0.733\n",
      "Train Epoch 8 [56320/69249 (81%)]\tLoss: 1.869956, mean accuracy last epoch: 0.733\n",
      "Train Epoch 8 [58880/69249 (85%)]\tLoss: 1.892303, mean accuracy last epoch: 0.733\n",
      "Train Epoch 8 [61440/69249 (89%)]\tLoss: 1.886174, mean accuracy last epoch: 0.734\n",
      "Train Epoch 8 [64000/69249 (92%)]\tLoss: 1.864069, mean accuracy last epoch: 0.734\n",
      "Train Epoch 8 [66560/69249 (96%)]\tLoss: 1.929289, mean accuracy last epoch: 0.734\n",
      "Train Epoch 8 [34830/69249 (100%)]\tLoss: 1.833678, mean accuracy last epoch: 0.734\n",
      "Train Epoch 9 [0/69249 (0%)]\tLoss: 1.872737, mean accuracy last epoch: 0.735\n",
      "Train Epoch 9 [2560/69249 (4%)]\tLoss: 1.868660, mean accuracy last epoch: 0.735\n",
      "Train Epoch 9 [5120/69249 (7%)]\tLoss: 1.913782, mean accuracy last epoch: 0.735\n",
      "Train Epoch 9 [7680/69249 (11%)]\tLoss: 1.897896, mean accuracy last epoch: 0.735\n",
      "Train Epoch 9 [10240/69249 (15%)]\tLoss: 1.903703, mean accuracy last epoch: 0.735\n",
      "Train Epoch 9 [12800/69249 (18%)]\tLoss: 1.913369, mean accuracy last epoch: 0.736\n",
      "Train Epoch 9 [15360/69249 (22%)]\tLoss: 1.917093, mean accuracy last epoch: 0.736\n",
      "Train Epoch 9 [17920/69249 (26%)]\tLoss: 1.898297, mean accuracy last epoch: 0.736\n",
      "Train Epoch 9 [20480/69249 (30%)]\tLoss: 1.877745, mean accuracy last epoch: 0.736\n",
      "Train Epoch 9 [23040/69249 (33%)]\tLoss: 1.898903, mean accuracy last epoch: 0.736\n",
      "Train Epoch 9 [25600/69249 (37%)]\tLoss: 1.892458, mean accuracy last epoch: 0.737\n",
      "Train Epoch 9 [28160/69249 (41%)]\tLoss: 1.886781, mean accuracy last epoch: 0.737\n",
      "Train Epoch 9 [30720/69249 (44%)]\tLoss: 1.870418, mean accuracy last epoch: 0.737\n",
      "Train Epoch 9 [33280/69249 (48%)]\tLoss: 1.883062, mean accuracy last epoch: 0.737\n",
      "Train Epoch 9 [35840/69249 (52%)]\tLoss: 1.931245, mean accuracy last epoch: 0.738\n",
      "Train Epoch 9 [38400/69249 (55%)]\tLoss: 1.955714, mean accuracy last epoch: 0.738\n",
      "Train Epoch 9 [40960/69249 (59%)]\tLoss: 1.896742, mean accuracy last epoch: 0.738\n",
      "Train Epoch 9 [43520/69249 (63%)]\tLoss: 1.938994, mean accuracy last epoch: 0.738\n",
      "Train Epoch 9 [46080/69249 (66%)]\tLoss: 1.845814, mean accuracy last epoch: 0.738\n",
      "Train Epoch 9 [48640/69249 (70%)]\tLoss: 1.916153, mean accuracy last epoch: 0.739\n",
      "Train Epoch 9 [51200/69249 (74%)]\tLoss: 1.893683, mean accuracy last epoch: 0.739\n",
      "Train Epoch 9 [53760/69249 (77%)]\tLoss: 1.850190, mean accuracy last epoch: 0.739\n",
      "Train Epoch 9 [56320/69249 (81%)]\tLoss: 1.848658, mean accuracy last epoch: 0.739\n",
      "Train Epoch 9 [58880/69249 (85%)]\tLoss: 1.880140, mean accuracy last epoch: 0.739\n",
      "Train Epoch 9 [61440/69249 (89%)]\tLoss: 1.860205, mean accuracy last epoch: 0.740\n",
      "Train Epoch 9 [64000/69249 (92%)]\tLoss: 1.839479, mean accuracy last epoch: 0.740\n",
      "Train Epoch 9 [66560/69249 (96%)]\tLoss: 1.893087, mean accuracy last epoch: 0.740\n",
      "Train Epoch 9 [34830/69249 (100%)]\tLoss: 1.912912, mean accuracy last epoch: 0.740\n",
      "Train Epoch 10 [0/69249 (0%)]\tLoss: 1.857988, mean accuracy last epoch: 0.740\n",
      "Train Epoch 10 [2560/69249 (4%)]\tLoss: 1.902416, mean accuracy last epoch: 0.740\n",
      "Train Epoch 10 [5120/69249 (7%)]\tLoss: 1.914905, mean accuracy last epoch: 0.741\n",
      "Train Epoch 10 [7680/69249 (11%)]\tLoss: 1.922498, mean accuracy last epoch: 0.741\n",
      "Train Epoch 10 [10240/69249 (15%)]\tLoss: 1.905780, mean accuracy last epoch: 0.741\n",
      "Train Epoch 10 [12800/69249 (18%)]\tLoss: 1.894941, mean accuracy last epoch: 0.741\n",
      "Train Epoch 10 [15360/69249 (22%)]\tLoss: 1.885733, mean accuracy last epoch: 0.741\n",
      "Train Epoch 10 [17920/69249 (26%)]\tLoss: 1.886665, mean accuracy last epoch: 0.742\n",
      "Train Epoch 10 [20480/69249 (30%)]\tLoss: 1.900798, mean accuracy last epoch: 0.742\n",
      "Train Epoch 10 [23040/69249 (33%)]\tLoss: 1.864775, mean accuracy last epoch: 0.742\n",
      "Train Epoch 10 [25600/69249 (37%)]\tLoss: 1.889626, mean accuracy last epoch: 0.742\n",
      "Train Epoch 10 [28160/69249 (41%)]\tLoss: 1.883017, mean accuracy last epoch: 0.742\n",
      "Train Epoch 10 [30720/69249 (44%)]\tLoss: 1.952615, mean accuracy last epoch: 0.743\n",
      "Train Epoch 10 [33280/69249 (48%)]\tLoss: 1.864662, mean accuracy last epoch: 0.743\n",
      "Train Epoch 10 [35840/69249 (52%)]\tLoss: 1.928471, mean accuracy last epoch: 0.743\n",
      "Train Epoch 10 [38400/69249 (55%)]\tLoss: 1.920985, mean accuracy last epoch: 0.743\n",
      "Train Epoch 10 [40960/69249 (59%)]\tLoss: 1.889126, mean accuracy last epoch: 0.743\n",
      "Train Epoch 10 [43520/69249 (63%)]\tLoss: 1.882924, mean accuracy last epoch: 0.743\n",
      "Train Epoch 10 [46080/69249 (66%)]\tLoss: 1.893015, mean accuracy last epoch: 0.744\n",
      "Train Epoch 10 [48640/69249 (70%)]\tLoss: 1.913284, mean accuracy last epoch: 0.744\n",
      "Train Epoch 10 [51200/69249 (74%)]\tLoss: 1.910826, mean accuracy last epoch: 0.744\n",
      "Train Epoch 10 [53760/69249 (77%)]\tLoss: 1.919267, mean accuracy last epoch: 0.744\n",
      "Train Epoch 10 [56320/69249 (81%)]\tLoss: 1.900816, mean accuracy last epoch: 0.744\n",
      "Train Epoch 10 [58880/69249 (85%)]\tLoss: 1.922735, mean accuracy last epoch: 0.744\n",
      "Train Epoch 10 [61440/69249 (89%)]\tLoss: 1.899280, mean accuracy last epoch: 0.745\n",
      "Train Epoch 10 [64000/69249 (92%)]\tLoss: 1.898013, mean accuracy last epoch: 0.745\n",
      "Train Epoch 10 [66560/69249 (96%)]\tLoss: 1.896903, mean accuracy last epoch: 0.745\n",
      "Train Epoch 10 [34830/69249 (100%)]\tLoss: 1.893772, mean accuracy last epoch: 0.745\n",
      "Train Epoch 11 [0/69249 (0%)]\tLoss: 1.871027, mean accuracy last epoch: 0.745\n",
      "Train Epoch 11 [2560/69249 (4%)]\tLoss: 1.903582, mean accuracy last epoch: 0.745\n",
      "Train Epoch 11 [5120/69249 (7%)]\tLoss: 1.849510, mean accuracy last epoch: 0.745\n",
      "Train Epoch 11 [7680/69249 (11%)]\tLoss: 1.886844, mean accuracy last epoch: 0.746\n",
      "Train Epoch 11 [10240/69249 (15%)]\tLoss: 1.892578, mean accuracy last epoch: 0.746\n",
      "Train Epoch 11 [12800/69249 (18%)]\tLoss: 1.897950, mean accuracy last epoch: 0.746\n",
      "Train Epoch 11 [15360/69249 (22%)]\tLoss: 1.904172, mean accuracy last epoch: 0.746\n",
      "Train Epoch 11 [17920/69249 (26%)]\tLoss: 1.904273, mean accuracy last epoch: 0.746\n",
      "Train Epoch 11 [20480/69249 (30%)]\tLoss: 1.942120, mean accuracy last epoch: 0.747\n",
      "Train Epoch 11 [23040/69249 (33%)]\tLoss: 1.891283, mean accuracy last epoch: 0.747\n",
      "Train Epoch 11 [25600/69249 (37%)]\tLoss: 1.884429, mean accuracy last epoch: 0.747\n",
      "Train Epoch 11 [28160/69249 (41%)]\tLoss: 1.847674, mean accuracy last epoch: 0.747\n",
      "Train Epoch 11 [30720/69249 (44%)]\tLoss: 1.893524, mean accuracy last epoch: 0.747\n",
      "Train Epoch 11 [33280/69249 (48%)]\tLoss: 1.880015, mean accuracy last epoch: 0.747\n",
      "Train Epoch 11 [35840/69249 (52%)]\tLoss: 1.899283, mean accuracy last epoch: 0.747\n",
      "Train Epoch 11 [38400/69249 (55%)]\tLoss: 1.907414, mean accuracy last epoch: 0.748\n",
      "Train Epoch 11 [40960/69249 (59%)]\tLoss: 1.896555, mean accuracy last epoch: 0.748\n",
      "Train Epoch 11 [43520/69249 (63%)]\tLoss: 1.895369, mean accuracy last epoch: 0.748\n",
      "Train Epoch 11 [46080/69249 (66%)]\tLoss: 1.900842, mean accuracy last epoch: 0.748\n",
      "Train Epoch 11 [48640/69249 (70%)]\tLoss: 1.896560, mean accuracy last epoch: 0.748\n",
      "Train Epoch 11 [51200/69249 (74%)]\tLoss: 1.934958, mean accuracy last epoch: 0.748\n",
      "Train Epoch 11 [53760/69249 (77%)]\tLoss: 1.907050, mean accuracy last epoch: 0.748\n",
      "Train Epoch 11 [56320/69249 (81%)]\tLoss: 1.877992, mean accuracy last epoch: 0.748\n",
      "Train Epoch 11 [58880/69249 (85%)]\tLoss: 1.907037, mean accuracy last epoch: 0.749\n",
      "Train Epoch 11 [61440/69249 (89%)]\tLoss: 1.875627, mean accuracy last epoch: 0.749\n",
      "Train Epoch 11 [64000/69249 (92%)]\tLoss: 1.871612, mean accuracy last epoch: 0.749\n",
      "Train Epoch 11 [66560/69249 (96%)]\tLoss: 1.910636, mean accuracy last epoch: 0.749\n",
      "Train Epoch 11 [34830/69249 (100%)]\tLoss: 1.846617, mean accuracy last epoch: 0.749\n",
      "Train Epoch 12 [0/69249 (0%)]\tLoss: 1.887643, mean accuracy last epoch: 0.749\n",
      "Train Epoch 12 [2560/69249 (4%)]\tLoss: 1.908599, mean accuracy last epoch: 0.749\n",
      "Train Epoch 12 [5120/69249 (7%)]\tLoss: 1.866342, mean accuracy last epoch: 0.750\n",
      "Train Epoch 12 [7680/69249 (11%)]\tLoss: 1.902388, mean accuracy last epoch: 0.750\n",
      "Train Epoch 12 [10240/69249 (15%)]\tLoss: 1.877567, mean accuracy last epoch: 0.750\n",
      "Train Epoch 12 [12800/69249 (18%)]\tLoss: 1.901232, mean accuracy last epoch: 0.750\n",
      "Train Epoch 12 [15360/69249 (22%)]\tLoss: 1.976347, mean accuracy last epoch: 0.750\n",
      "Train Epoch 12 [17920/69249 (26%)]\tLoss: 1.866240, mean accuracy last epoch: 0.750\n",
      "Train Epoch 12 [20480/69249 (30%)]\tLoss: 1.871467, mean accuracy last epoch: 0.750\n",
      "Train Epoch 12 [23040/69249 (33%)]\tLoss: 1.912576, mean accuracy last epoch: 0.750\n",
      "Train Epoch 12 [25600/69249 (37%)]\tLoss: 1.873719, mean accuracy last epoch: 0.751\n",
      "Train Epoch 12 [28160/69249 (41%)]\tLoss: 1.902677, mean accuracy last epoch: 0.751\n",
      "Train Epoch 12 [30720/69249 (44%)]\tLoss: 1.863010, mean accuracy last epoch: 0.751\n",
      "Train Epoch 12 [33280/69249 (48%)]\tLoss: 1.871209, mean accuracy last epoch: 0.751\n",
      "Train Epoch 12 [35840/69249 (52%)]\tLoss: 1.901583, mean accuracy last epoch: 0.751\n",
      "Train Epoch 12 [38400/69249 (55%)]\tLoss: 1.862126, mean accuracy last epoch: 0.751\n",
      "Train Epoch 12 [40960/69249 (59%)]\tLoss: 1.873583, mean accuracy last epoch: 0.751\n",
      "Train Epoch 12 [43520/69249 (63%)]\tLoss: 1.918072, mean accuracy last epoch: 0.751\n",
      "Train Epoch 12 [46080/69249 (66%)]\tLoss: 1.916892, mean accuracy last epoch: 0.752\n",
      "Train Epoch 12 [48640/69249 (70%)]\tLoss: 1.868850, mean accuracy last epoch: 0.752\n",
      "Train Epoch 12 [51200/69249 (74%)]\tLoss: 1.927117, mean accuracy last epoch: 0.752\n",
      "Train Epoch 12 [53760/69249 (77%)]\tLoss: 1.864445, mean accuracy last epoch: 0.752\n",
      "Train Epoch 12 [56320/69249 (81%)]\tLoss: 1.943831, mean accuracy last epoch: 0.752\n",
      "Train Epoch 12 [58880/69249 (85%)]\tLoss: 1.889024, mean accuracy last epoch: 0.752\n",
      "Train Epoch 12 [61440/69249 (89%)]\tLoss: 1.903761, mean accuracy last epoch: 0.752\n",
      "Train Epoch 12 [64000/69249 (92%)]\tLoss: 1.884809, mean accuracy last epoch: 0.752\n",
      "Train Epoch 12 [66560/69249 (96%)]\tLoss: 1.894211, mean accuracy last epoch: 0.753\n",
      "Train Epoch 12 [34830/69249 (100%)]\tLoss: 1.885573, mean accuracy last epoch: 0.753\n",
      "Train Epoch 13 [0/69249 (0%)]\tLoss: 1.877995, mean accuracy last epoch: 0.753\n",
      "Train Epoch 13 [2560/69249 (4%)]\tLoss: 1.900799, mean accuracy last epoch: 0.753\n",
      "Train Epoch 13 [5120/69249 (7%)]\tLoss: 1.889863, mean accuracy last epoch: 0.753\n",
      "Train Epoch 13 [7680/69249 (11%)]\tLoss: 1.900245, mean accuracy last epoch: 0.753\n",
      "Train Epoch 13 [10240/69249 (15%)]\tLoss: 1.928633, mean accuracy last epoch: 0.753\n",
      "Train Epoch 13 [12800/69249 (18%)]\tLoss: 1.887632, mean accuracy last epoch: 0.753\n",
      "Train Epoch 13 [15360/69249 (22%)]\tLoss: 1.893291, mean accuracy last epoch: 0.753\n",
      "Train Epoch 13 [17920/69249 (26%)]\tLoss: 1.875430, mean accuracy last epoch: 0.754\n",
      "Train Epoch 13 [20480/69249 (30%)]\tLoss: 1.881454, mean accuracy last epoch: 0.754\n",
      "Train Epoch 13 [23040/69249 (33%)]\tLoss: 1.936023, mean accuracy last epoch: 0.754\n",
      "Train Epoch 13 [25600/69249 (37%)]\tLoss: 1.955630, mean accuracy last epoch: 0.754\n",
      "Train Epoch 13 [28160/69249 (41%)]\tLoss: 1.905982, mean accuracy last epoch: 0.754\n",
      "Train Epoch 13 [30720/69249 (44%)]\tLoss: 1.909057, mean accuracy last epoch: 0.754\n",
      "Train Epoch 13 [33280/69249 (48%)]\tLoss: 1.891610, mean accuracy last epoch: 0.754\n",
      "Train Epoch 13 [35840/69249 (52%)]\tLoss: 1.894918, mean accuracy last epoch: 0.754\n",
      "Train Epoch 13 [38400/69249 (55%)]\tLoss: 1.870373, mean accuracy last epoch: 0.754\n",
      "Train Epoch 13 [40960/69249 (59%)]\tLoss: 1.862861, mean accuracy last epoch: 0.755\n",
      "Train Epoch 13 [43520/69249 (63%)]\tLoss: 1.876304, mean accuracy last epoch: 0.755\n",
      "Train Epoch 13 [46080/69249 (66%)]\tLoss: 1.883593, mean accuracy last epoch: 0.755\n",
      "Train Epoch 13 [48640/69249 (70%)]\tLoss: 1.893820, mean accuracy last epoch: 0.755\n",
      "Train Epoch 13 [51200/69249 (74%)]\tLoss: 1.909258, mean accuracy last epoch: 0.755\n",
      "Train Epoch 13 [53760/69249 (77%)]\tLoss: 1.871731, mean accuracy last epoch: 0.755\n",
      "Train Epoch 13 [56320/69249 (81%)]\tLoss: 1.906516, mean accuracy last epoch: 0.755\n",
      "Train Epoch 13 [58880/69249 (85%)]\tLoss: 1.882197, mean accuracy last epoch: 0.755\n",
      "Train Epoch 13 [61440/69249 (89%)]\tLoss: 1.914626, mean accuracy last epoch: 0.755\n",
      "Train Epoch 13 [64000/69249 (92%)]\tLoss: 1.916850, mean accuracy last epoch: 0.755\n",
      "Train Epoch 13 [66560/69249 (96%)]\tLoss: 1.930158, mean accuracy last epoch: 0.756\n",
      "Train Epoch 13 [34830/69249 (100%)]\tLoss: 1.813981, mean accuracy last epoch: 0.756\n",
      "Train Epoch 14 [0/69249 (0%)]\tLoss: 1.896008, mean accuracy last epoch: 0.756\n",
      "Train Epoch 14 [2560/69249 (4%)]\tLoss: 1.846037, mean accuracy last epoch: 0.756\n",
      "Train Epoch 14 [5120/69249 (7%)]\tLoss: 1.932068, mean accuracy last epoch: 0.756\n",
      "Train Epoch 14 [7680/69249 (11%)]\tLoss: 1.870033, mean accuracy last epoch: 0.756\n",
      "Train Epoch 14 [10240/69249 (15%)]\tLoss: 1.938386, mean accuracy last epoch: 0.756\n",
      "Train Epoch 14 [12800/69249 (18%)]\tLoss: 1.911597, mean accuracy last epoch: 0.756\n",
      "Train Epoch 14 [15360/69249 (22%)]\tLoss: 1.954362, mean accuracy last epoch: 0.756\n",
      "Train Epoch 14 [17920/69249 (26%)]\tLoss: 1.897370, mean accuracy last epoch: 0.756\n",
      "Train Epoch 14 [20480/69249 (30%)]\tLoss: 1.877463, mean accuracy last epoch: 0.757\n",
      "Train Epoch 14 [23040/69249 (33%)]\tLoss: 1.900977, mean accuracy last epoch: 0.757\n",
      "Train Epoch 14 [25600/69249 (37%)]\tLoss: 1.885388, mean accuracy last epoch: 0.757\n",
      "Train Epoch 14 [28160/69249 (41%)]\tLoss: 1.918933, mean accuracy last epoch: 0.757\n",
      "Train Epoch 14 [30720/69249 (44%)]\tLoss: 1.848152, mean accuracy last epoch: 0.757\n",
      "Train Epoch 14 [33280/69249 (48%)]\tLoss: 1.902982, mean accuracy last epoch: 0.757\n",
      "Train Epoch 14 [35840/69249 (52%)]\tLoss: 1.892578, mean accuracy last epoch: 0.757\n",
      "Train Epoch 14 [38400/69249 (55%)]\tLoss: 1.934314, mean accuracy last epoch: 0.757\n",
      "Train Epoch 14 [40960/69249 (59%)]\tLoss: 1.885883, mean accuracy last epoch: 0.757\n",
      "Train Epoch 14 [43520/69249 (63%)]\tLoss: 1.883756, mean accuracy last epoch: 0.757\n",
      "Train Epoch 14 [46080/69249 (66%)]\tLoss: 1.888797, mean accuracy last epoch: 0.758\n",
      "Train Epoch 14 [48640/69249 (70%)]\tLoss: 1.923913, mean accuracy last epoch: 0.758\n",
      "Train Epoch 14 [51200/69249 (74%)]\tLoss: 1.924688, mean accuracy last epoch: 0.758\n",
      "Train Epoch 14 [53760/69249 (77%)]\tLoss: 1.870332, mean accuracy last epoch: 0.758\n",
      "Train Epoch 14 [56320/69249 (81%)]\tLoss: 1.868873, mean accuracy last epoch: 0.758\n",
      "Train Epoch 14 [58880/69249 (85%)]\tLoss: 1.914481, mean accuracy last epoch: 0.758\n",
      "Train Epoch 14 [61440/69249 (89%)]\tLoss: 1.853039, mean accuracy last epoch: 0.758\n",
      "Train Epoch 14 [64000/69249 (92%)]\tLoss: 1.923436, mean accuracy last epoch: 0.758\n",
      "Train Epoch 14 [66560/69249 (96%)]\tLoss: 1.896135, mean accuracy last epoch: 0.758\n",
      "Train Epoch 14 [34830/69249 (100%)]\tLoss: 1.915962, mean accuracy last epoch: 0.758\n",
      "Train Epoch 15 [0/69249 (0%)]\tLoss: 1.896878, mean accuracy last epoch: 0.758\n",
      "Train Epoch 15 [2560/69249 (4%)]\tLoss: 1.869998, mean accuracy last epoch: 0.758\n",
      "Train Epoch 15 [5120/69249 (7%)]\tLoss: 1.889776, mean accuracy last epoch: 0.759\n",
      "Train Epoch 15 [7680/69249 (11%)]\tLoss: 1.912151, mean accuracy last epoch: 0.759\n",
      "Train Epoch 15 [10240/69249 (15%)]\tLoss: 1.929507, mean accuracy last epoch: 0.759\n",
      "Train Epoch 15 [12800/69249 (18%)]\tLoss: 1.858719, mean accuracy last epoch: 0.759\n",
      "Train Epoch 15 [15360/69249 (22%)]\tLoss: 1.903131, mean accuracy last epoch: 0.759\n",
      "Train Epoch 15 [17920/69249 (26%)]\tLoss: 1.880154, mean accuracy last epoch: 0.759\n",
      "Train Epoch 15 [20480/69249 (30%)]\tLoss: 1.907022, mean accuracy last epoch: 0.759\n",
      "Train Epoch 15 [23040/69249 (33%)]\tLoss: 1.898437, mean accuracy last epoch: 0.759\n",
      "Train Epoch 15 [25600/69249 (37%)]\tLoss: 1.884872, mean accuracy last epoch: 0.759\n",
      "Train Epoch 15 [28160/69249 (41%)]\tLoss: 1.897509, mean accuracy last epoch: 0.759\n",
      "Train Epoch 15 [30720/69249 (44%)]\tLoss: 1.888007, mean accuracy last epoch: 0.760\n",
      "Train Epoch 15 [33280/69249 (48%)]\tLoss: 1.858576, mean accuracy last epoch: 0.760\n",
      "Train Epoch 15 [35840/69249 (52%)]\tLoss: 1.901390, mean accuracy last epoch: 0.760\n",
      "Train Epoch 15 [38400/69249 (55%)]\tLoss: 1.895250, mean accuracy last epoch: 0.760\n",
      "Train Epoch 15 [40960/69249 (59%)]\tLoss: 1.868896, mean accuracy last epoch: 0.760\n",
      "Train Epoch 15 [43520/69249 (63%)]\tLoss: 1.945729, mean accuracy last epoch: 0.760\n",
      "Train Epoch 15 [46080/69249 (66%)]\tLoss: 1.888909, mean accuracy last epoch: 0.760\n",
      "Train Epoch 15 [48640/69249 (70%)]\tLoss: 1.898593, mean accuracy last epoch: 0.760\n",
      "Train Epoch 15 [51200/69249 (74%)]\tLoss: 1.909568, mean accuracy last epoch: 0.760\n",
      "Train Epoch 15 [53760/69249 (77%)]\tLoss: 1.892457, mean accuracy last epoch: 0.760\n",
      "Train Epoch 15 [56320/69249 (81%)]\tLoss: 1.900622, mean accuracy last epoch: 0.760\n",
      "Train Epoch 15 [58880/69249 (85%)]\tLoss: 1.843959, mean accuracy last epoch: 0.760\n",
      "Train Epoch 15 [61440/69249 (89%)]\tLoss: 1.901879, mean accuracy last epoch: 0.760\n",
      "Train Epoch 15 [64000/69249 (92%)]\tLoss: 1.953402, mean accuracy last epoch: 0.761\n",
      "Train Epoch 15 [66560/69249 (96%)]\tLoss: 1.904188, mean accuracy last epoch: 0.761\n",
      "Train Epoch 15 [34830/69249 (100%)]\tLoss: 1.889436, mean accuracy last epoch: 0.761\n",
      "Train Epoch 16 [0/69249 (0%)]\tLoss: 1.848455, mean accuracy last epoch: 0.761\n",
      "Train Epoch 16 [2560/69249 (4%)]\tLoss: 1.914722, mean accuracy last epoch: 0.761\n",
      "Train Epoch 16 [5120/69249 (7%)]\tLoss: 1.912424, mean accuracy last epoch: 0.761\n",
      "Train Epoch 16 [7680/69249 (11%)]\tLoss: 1.884637, mean accuracy last epoch: 0.761\n",
      "Train Epoch 16 [10240/69249 (15%)]\tLoss: 1.872504, mean accuracy last epoch: 0.761\n",
      "Train Epoch 16 [12800/69249 (18%)]\tLoss: 1.900992, mean accuracy last epoch: 0.761\n",
      "Train Epoch 16 [15360/69249 (22%)]\tLoss: 1.903275, mean accuracy last epoch: 0.761\n",
      "Train Epoch 16 [17920/69249 (26%)]\tLoss: 1.886099, mean accuracy last epoch: 0.761\n",
      "Train Epoch 16 [20480/69249 (30%)]\tLoss: 1.888136, mean accuracy last epoch: 0.761\n",
      "Train Epoch 16 [23040/69249 (33%)]\tLoss: 1.866209, mean accuracy last epoch: 0.761\n",
      "Train Epoch 16 [25600/69249 (37%)]\tLoss: 1.876966, mean accuracy last epoch: 0.762\n",
      "Train Epoch 16 [28160/69249 (41%)]\tLoss: 1.901567, mean accuracy last epoch: 0.762\n",
      "Train Epoch 16 [30720/69249 (44%)]\tLoss: 1.928641, mean accuracy last epoch: 0.762\n",
      "Train Epoch 16 [33280/69249 (48%)]\tLoss: 1.890569, mean accuracy last epoch: 0.762\n",
      "Train Epoch 16 [35840/69249 (52%)]\tLoss: 1.867304, mean accuracy last epoch: 0.762\n",
      "Train Epoch 16 [38400/69249 (55%)]\tLoss: 1.910515, mean accuracy last epoch: 0.762\n",
      "Train Epoch 16 [40960/69249 (59%)]\tLoss: 1.904366, mean accuracy last epoch: 0.762\n",
      "Train Epoch 16 [43520/69249 (63%)]\tLoss: 1.868367, mean accuracy last epoch: 0.762\n",
      "Train Epoch 16 [46080/69249 (66%)]\tLoss: 1.893099, mean accuracy last epoch: 0.762\n",
      "Train Epoch 16 [48640/69249 (70%)]\tLoss: 1.894251, mean accuracy last epoch: 0.762\n",
      "Train Epoch 16 [51200/69249 (74%)]\tLoss: 1.852823, mean accuracy last epoch: 0.762\n",
      "Train Epoch 16 [53760/69249 (77%)]\tLoss: 1.894828, mean accuracy last epoch: 0.762\n",
      "Train Epoch 16 [56320/69249 (81%)]\tLoss: 1.917868, mean accuracy last epoch: 0.762\n",
      "Train Epoch 16 [58880/69249 (85%)]\tLoss: 1.892681, mean accuracy last epoch: 0.763\n",
      "Train Epoch 16 [61440/69249 (89%)]\tLoss: 1.876908, mean accuracy last epoch: 0.763\n",
      "Train Epoch 16 [64000/69249 (92%)]\tLoss: 1.915843, mean accuracy last epoch: 0.763\n",
      "Train Epoch 16 [66560/69249 (96%)]\tLoss: 1.882833, mean accuracy last epoch: 0.763\n",
      "Train Epoch 16 [34830/69249 (100%)]\tLoss: 1.924227, mean accuracy last epoch: 0.763\n",
      "Train Epoch 17 [0/69249 (0%)]\tLoss: 1.899834, mean accuracy last epoch: 0.763\n",
      "Train Epoch 17 [2560/69249 (4%)]\tLoss: 1.925819, mean accuracy last epoch: 0.763\n",
      "Train Epoch 17 [5120/69249 (7%)]\tLoss: 1.914071, mean accuracy last epoch: 0.763\n",
      "Train Epoch 17 [7680/69249 (11%)]\tLoss: 1.885591, mean accuracy last epoch: 0.763\n",
      "Train Epoch 17 [10240/69249 (15%)]\tLoss: 1.884000, mean accuracy last epoch: 0.763\n",
      "Train Epoch 17 [12800/69249 (18%)]\tLoss: 1.857671, mean accuracy last epoch: 0.763\n",
      "Train Epoch 17 [15360/69249 (22%)]\tLoss: 1.897311, mean accuracy last epoch: 0.763\n",
      "Train Epoch 17 [17920/69249 (26%)]\tLoss: 1.863099, mean accuracy last epoch: 0.763\n",
      "Train Epoch 17 [20480/69249 (30%)]\tLoss: 1.924749, mean accuracy last epoch: 0.763\n",
      "Train Epoch 17 [23040/69249 (33%)]\tLoss: 1.976267, mean accuracy last epoch: 0.763\n",
      "Train Epoch 17 [25600/69249 (37%)]\tLoss: 1.902463, mean accuracy last epoch: 0.764\n",
      "Train Epoch 17 [28160/69249 (41%)]\tLoss: 1.908161, mean accuracy last epoch: 0.764\n",
      "Train Epoch 17 [30720/69249 (44%)]\tLoss: 1.908289, mean accuracy last epoch: 0.764\n",
      "Train Epoch 17 [33280/69249 (48%)]\tLoss: 1.876855, mean accuracy last epoch: 0.764\n",
      "Train Epoch 17 [35840/69249 (52%)]\tLoss: 1.905833, mean accuracy last epoch: 0.764\n",
      "Train Epoch 17 [38400/69249 (55%)]\tLoss: 1.916620, mean accuracy last epoch: 0.764\n",
      "Train Epoch 17 [40960/69249 (59%)]\tLoss: 1.908957, mean accuracy last epoch: 0.764\n",
      "Train Epoch 17 [43520/69249 (63%)]\tLoss: 1.880428, mean accuracy last epoch: 0.764\n",
      "Train Epoch 17 [46080/69249 (66%)]\tLoss: 1.845205, mean accuracy last epoch: 0.764\n",
      "Train Epoch 17 [48640/69249 (70%)]\tLoss: 1.870165, mean accuracy last epoch: 0.764\n",
      "Train Epoch 17 [51200/69249 (74%)]\tLoss: 1.866263, mean accuracy last epoch: 0.764\n",
      "Train Epoch 17 [53760/69249 (77%)]\tLoss: 1.880789, mean accuracy last epoch: 0.764\n",
      "Train Epoch 17 [56320/69249 (81%)]\tLoss: 1.867896, mean accuracy last epoch: 0.764\n",
      "Train Epoch 17 [58880/69249 (85%)]\tLoss: 1.842102, mean accuracy last epoch: 0.764\n",
      "Train Epoch 17 [61440/69249 (89%)]\tLoss: 1.936686, mean accuracy last epoch: 0.765\n",
      "Train Epoch 17 [64000/69249 (92%)]\tLoss: 1.871439, mean accuracy last epoch: 0.765\n",
      "Train Epoch 17 [66560/69249 (96%)]\tLoss: 1.892612, mean accuracy last epoch: 0.765\n",
      "Train Epoch 17 [34830/69249 (100%)]\tLoss: 1.920553, mean accuracy last epoch: 0.765\n",
      "Train Epoch 18 [0/69249 (0%)]\tLoss: 1.889430, mean accuracy last epoch: 0.765\n",
      "Train Epoch 18 [2560/69249 (4%)]\tLoss: 1.869555, mean accuracy last epoch: 0.765\n",
      "Train Epoch 18 [5120/69249 (7%)]\tLoss: 1.897527, mean accuracy last epoch: 0.765\n",
      "Train Epoch 18 [7680/69249 (11%)]\tLoss: 1.924057, mean accuracy last epoch: 0.765\n",
      "Train Epoch 18 [10240/69249 (15%)]\tLoss: 1.887081, mean accuracy last epoch: 0.765\n",
      "Train Epoch 18 [12800/69249 (18%)]\tLoss: 1.917806, mean accuracy last epoch: 0.765\n",
      "Train Epoch 18 [15360/69249 (22%)]\tLoss: 1.863732, mean accuracy last epoch: 0.765\n",
      "Train Epoch 18 [17920/69249 (26%)]\tLoss: 1.884225, mean accuracy last epoch: 0.765\n",
      "Train Epoch 18 [20480/69249 (30%)]\tLoss: 1.899925, mean accuracy last epoch: 0.765\n",
      "Train Epoch 18 [23040/69249 (33%)]\tLoss: 1.882438, mean accuracy last epoch: 0.765\n",
      "Train Epoch 18 [25600/69249 (37%)]\tLoss: 1.862883, mean accuracy last epoch: 0.765\n",
      "Train Epoch 18 [28160/69249 (41%)]\tLoss: 1.886932, mean accuracy last epoch: 0.765\n",
      "Train Epoch 18 [30720/69249 (44%)]\tLoss: 1.840951, mean accuracy last epoch: 0.765\n",
      "Train Epoch 18 [33280/69249 (48%)]\tLoss: 1.915247, mean accuracy last epoch: 0.766\n",
      "Train Epoch 18 [35840/69249 (52%)]\tLoss: 1.875513, mean accuracy last epoch: 0.766\n",
      "Train Epoch 18 [38400/69249 (55%)]\tLoss: 1.908661, mean accuracy last epoch: 0.766\n",
      "Train Epoch 18 [40960/69249 (59%)]\tLoss: 1.877301, mean accuracy last epoch: 0.766\n",
      "Train Epoch 18 [43520/69249 (63%)]\tLoss: 1.872530, mean accuracy last epoch: 0.766\n",
      "Train Epoch 18 [46080/69249 (66%)]\tLoss: 1.875053, mean accuracy last epoch: 0.766\n",
      "Train Epoch 18 [48640/69249 (70%)]\tLoss: 1.925786, mean accuracy last epoch: 0.766\n",
      "Train Epoch 18 [51200/69249 (74%)]\tLoss: 1.914329, mean accuracy last epoch: 0.766\n",
      "Train Epoch 18 [53760/69249 (77%)]\tLoss: 1.931276, mean accuracy last epoch: 0.766\n",
      "Train Epoch 18 [56320/69249 (81%)]\tLoss: 1.889085, mean accuracy last epoch: 0.766\n",
      "Train Epoch 18 [58880/69249 (85%)]\tLoss: 1.872920, mean accuracy last epoch: 0.766\n",
      "Train Epoch 18 [61440/69249 (89%)]\tLoss: 1.877752, mean accuracy last epoch: 0.766\n",
      "Train Epoch 18 [64000/69249 (92%)]\tLoss: 1.890876, mean accuracy last epoch: 0.766\n",
      "Train Epoch 18 [66560/69249 (96%)]\tLoss: 1.875223, mean accuracy last epoch: 0.766\n",
      "Train Epoch 18 [34830/69249 (100%)]\tLoss: 1.947268, mean accuracy last epoch: 0.766\n",
      "Train Epoch 19 [0/69249 (0%)]\tLoss: 1.905540, mean accuracy last epoch: 0.766\n",
      "Train Epoch 19 [2560/69249 (4%)]\tLoss: 1.897173, mean accuracy last epoch: 0.766\n",
      "Train Epoch 19 [5120/69249 (7%)]\tLoss: 1.897966, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [7680/69249 (11%)]\tLoss: 1.853283, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [10240/69249 (15%)]\tLoss: 1.913001, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [12800/69249 (18%)]\tLoss: 1.896749, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [15360/69249 (22%)]\tLoss: 1.900743, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [17920/69249 (26%)]\tLoss: 1.916309, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [20480/69249 (30%)]\tLoss: 1.895462, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [23040/69249 (33%)]\tLoss: 1.890276, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [25600/69249 (37%)]\tLoss: 1.889257, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [28160/69249 (41%)]\tLoss: 1.853994, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [30720/69249 (44%)]\tLoss: 1.901523, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [33280/69249 (48%)]\tLoss: 1.904376, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [35840/69249 (52%)]\tLoss: 1.874558, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [38400/69249 (55%)]\tLoss: 1.922767, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [40960/69249 (59%)]\tLoss: 1.863950, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [43520/69249 (63%)]\tLoss: 1.893964, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [46080/69249 (66%)]\tLoss: 1.925058, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [48640/69249 (70%)]\tLoss: 1.912931, mean accuracy last epoch: 0.767\n",
      "Train Epoch 19 [51200/69249 (74%)]\tLoss: 1.918143, mean accuracy last epoch: 0.768\n",
      "Train Epoch 19 [53760/69249 (77%)]\tLoss: 1.923501, mean accuracy last epoch: 0.768\n",
      "Train Epoch 19 [56320/69249 (81%)]\tLoss: 1.931925, mean accuracy last epoch: 0.768\n",
      "Train Epoch 19 [58880/69249 (85%)]\tLoss: 1.907833, mean accuracy last epoch: 0.768\n",
      "Train Epoch 19 [61440/69249 (89%)]\tLoss: 1.850857, mean accuracy last epoch: 0.768\n",
      "Train Epoch 19 [64000/69249 (92%)]\tLoss: 1.892513, mean accuracy last epoch: 0.768\n",
      "Train Epoch 19 [66560/69249 (96%)]\tLoss: 1.897279, mean accuracy last epoch: 0.768\n",
      "Train Epoch 19 [34830/69249 (100%)]\tLoss: 1.847218, mean accuracy last epoch: 0.768\n",
      "Train Epoch 20 [0/69249 (0%)]\tLoss: 1.887054, mean accuracy last epoch: 0.768\n",
      "Train Epoch 20 [2560/69249 (4%)]\tLoss: 1.896922, mean accuracy last epoch: 0.768\n",
      "Train Epoch 20 [5120/69249 (7%)]\tLoss: 1.888262, mean accuracy last epoch: 0.768\n",
      "Train Epoch 20 [7680/69249 (11%)]\tLoss: 1.898514, mean accuracy last epoch: 0.768\n",
      "Train Epoch 20 [10240/69249 (15%)]\tLoss: 1.879683, mean accuracy last epoch: 0.768\n",
      "Train Epoch 20 [12800/69249 (18%)]\tLoss: 1.938307, mean accuracy last epoch: 0.768\n",
      "Train Epoch 20 [15360/69249 (22%)]\tLoss: 1.859150, mean accuracy last epoch: 0.768\n",
      "Train Epoch 20 [17920/69249 (26%)]\tLoss: 1.894333, mean accuracy last epoch: 0.768\n",
      "Train Epoch 20 [20480/69249 (30%)]\tLoss: 1.867655, mean accuracy last epoch: 0.768\n",
      "Train Epoch 20 [23040/69249 (33%)]\tLoss: 1.870399, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [25600/69249 (37%)]\tLoss: 1.884876, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [28160/69249 (41%)]\tLoss: 1.922879, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [30720/69249 (44%)]\tLoss: 1.905883, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [33280/69249 (48%)]\tLoss: 1.891048, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [35840/69249 (52%)]\tLoss: 1.902176, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [38400/69249 (55%)]\tLoss: 1.856800, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [40960/69249 (59%)]\tLoss: 1.907694, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [43520/69249 (63%)]\tLoss: 1.924122, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [46080/69249 (66%)]\tLoss: 1.830060, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [48640/69249 (70%)]\tLoss: 1.876691, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [51200/69249 (74%)]\tLoss: 1.852373, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [53760/69249 (77%)]\tLoss: 1.886909, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [56320/69249 (81%)]\tLoss: 1.896433, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [58880/69249 (85%)]\tLoss: 1.883599, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [61440/69249 (89%)]\tLoss: 1.925645, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [64000/69249 (92%)]\tLoss: 1.873717, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [66560/69249 (96%)]\tLoss: 1.904381, mean accuracy last epoch: 0.769\n",
      "Train Epoch 20 [34830/69249 (100%)]\tLoss: 1.867465, mean accuracy last epoch: 0.769\n",
      "Train Epoch 21 [0/69249 (0%)]\tLoss: 1.821805, mean accuracy last epoch: 0.769\n",
      "Train Epoch 21 [2560/69249 (4%)]\tLoss: 1.894867, mean accuracy last epoch: 0.769\n",
      "Train Epoch 21 [5120/69249 (7%)]\tLoss: 1.857343, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [7680/69249 (11%)]\tLoss: 1.857524, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [10240/69249 (15%)]\tLoss: 1.861654, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [12800/69249 (18%)]\tLoss: 1.877793, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [15360/69249 (22%)]\tLoss: 1.915384, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [17920/69249 (26%)]\tLoss: 1.887102, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [20480/69249 (30%)]\tLoss: 1.913337, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [23040/69249 (33%)]\tLoss: 1.905856, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [25600/69249 (37%)]\tLoss: 1.887707, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [28160/69249 (41%)]\tLoss: 1.865103, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [30720/69249 (44%)]\tLoss: 1.875151, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [33280/69249 (48%)]\tLoss: 1.870004, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [35840/69249 (52%)]\tLoss: 1.870967, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [38400/69249 (55%)]\tLoss: 1.894030, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [40960/69249 (59%)]\tLoss: 1.890274, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [43520/69249 (63%)]\tLoss: 1.905523, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [46080/69249 (66%)]\tLoss: 1.897569, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [48640/69249 (70%)]\tLoss: 1.901971, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [51200/69249 (74%)]\tLoss: 1.892458, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [53760/69249 (77%)]\tLoss: 1.877136, mean accuracy last epoch: 0.770\n",
      "Train Epoch 21 [56320/69249 (81%)]\tLoss: 1.929910, mean accuracy last epoch: 0.771\n",
      "Train Epoch 21 [58880/69249 (85%)]\tLoss: 1.930431, mean accuracy last epoch: 0.771\n",
      "Train Epoch 21 [61440/69249 (89%)]\tLoss: 1.889846, mean accuracy last epoch: 0.771\n",
      "Train Epoch 21 [64000/69249 (92%)]\tLoss: 1.914607, mean accuracy last epoch: 0.771\n",
      "Train Epoch 21 [66560/69249 (96%)]\tLoss: 1.883173, mean accuracy last epoch: 0.771\n",
      "Train Epoch 21 [34830/69249 (100%)]\tLoss: 1.906188, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [0/69249 (0%)]\tLoss: 1.825559, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [2560/69249 (4%)]\tLoss: 1.890247, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [5120/69249 (7%)]\tLoss: 1.888035, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [7680/69249 (11%)]\tLoss: 1.887928, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [10240/69249 (15%)]\tLoss: 1.857718, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [12800/69249 (18%)]\tLoss: 1.859971, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [15360/69249 (22%)]\tLoss: 1.929224, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [17920/69249 (26%)]\tLoss: 1.903245, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [20480/69249 (30%)]\tLoss: 1.907151, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [23040/69249 (33%)]\tLoss: 1.910314, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [25600/69249 (37%)]\tLoss: 1.890511, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [28160/69249 (41%)]\tLoss: 1.899384, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [30720/69249 (44%)]\tLoss: 1.894626, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [33280/69249 (48%)]\tLoss: 1.885232, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [35840/69249 (52%)]\tLoss: 1.898765, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [38400/69249 (55%)]\tLoss: 1.875195, mean accuracy last epoch: 0.771\n",
      "Train Epoch 22 [40960/69249 (59%)]\tLoss: 1.845329, mean accuracy last epoch: 0.772\n",
      "Train Epoch 22 [43520/69249 (63%)]\tLoss: 1.889405, mean accuracy last epoch: 0.772\n",
      "Train Epoch 22 [46080/69249 (66%)]\tLoss: 1.890980, mean accuracy last epoch: 0.772\n",
      "Train Epoch 22 [48640/69249 (70%)]\tLoss: 1.907594, mean accuracy last epoch: 0.772\n",
      "Train Epoch 22 [51200/69249 (74%)]\tLoss: 1.873032, mean accuracy last epoch: 0.772\n",
      "Train Epoch 22 [53760/69249 (77%)]\tLoss: 1.884076, mean accuracy last epoch: 0.772\n",
      "Train Epoch 22 [56320/69249 (81%)]\tLoss: 1.935598, mean accuracy last epoch: 0.772\n",
      "Train Epoch 22 [58880/69249 (85%)]\tLoss: 1.921082, mean accuracy last epoch: 0.772\n",
      "Train Epoch 22 [61440/69249 (89%)]\tLoss: 1.900494, mean accuracy last epoch: 0.772\n",
      "Train Epoch 22 [64000/69249 (92%)]\tLoss: 1.862066, mean accuracy last epoch: 0.772\n",
      "Train Epoch 22 [66560/69249 (96%)]\tLoss: 1.888787, mean accuracy last epoch: 0.772\n",
      "Train Epoch 22 [34830/69249 (100%)]\tLoss: 1.919906, mean accuracy last epoch: 0.772\n",
      "Train Epoch 23 [0/69249 (0%)]\tLoss: 1.901692, mean accuracy last epoch: 0.772\n",
      "Train Epoch 23 [2560/69249 (4%)]\tLoss: 1.898793, mean accuracy last epoch: 0.772\n",
      "Train Epoch 23 [5120/69249 (7%)]\tLoss: 1.912381, mean accuracy last epoch: 0.772\n",
      "Train Epoch 23 [7680/69249 (11%)]\tLoss: 1.894768, mean accuracy last epoch: 0.772\n",
      "Train Epoch 23 [10240/69249 (15%)]\tLoss: 1.894752, mean accuracy last epoch: 0.772\n",
      "Train Epoch 23 [12800/69249 (18%)]\tLoss: 1.849169, mean accuracy last epoch: 0.772\n",
      "Train Epoch 23 [15360/69249 (22%)]\tLoss: 1.887988, mean accuracy last epoch: 0.772\n",
      "Train Epoch 23 [17920/69249 (26%)]\tLoss: 1.904992, mean accuracy last epoch: 0.772\n",
      "Train Epoch 23 [20480/69249 (30%)]\tLoss: 1.879814, mean accuracy last epoch: 0.772\n",
      "Train Epoch 23 [23040/69249 (33%)]\tLoss: 1.936866, mean accuracy last epoch: 0.772\n",
      "Train Epoch 23 [25600/69249 (37%)]\tLoss: 1.898033, mean accuracy last epoch: 0.772\n",
      "Train Epoch 23 [28160/69249 (41%)]\tLoss: 1.893321, mean accuracy last epoch: 0.772\n",
      "Train Epoch 23 [30720/69249 (44%)]\tLoss: 1.895215, mean accuracy last epoch: 0.773\n",
      "Train Epoch 23 [33280/69249 (48%)]\tLoss: 1.857965, mean accuracy last epoch: 0.773\n",
      "Train Epoch 23 [35840/69249 (52%)]\tLoss: 1.932233, mean accuracy last epoch: 0.773\n",
      "Train Epoch 23 [38400/69249 (55%)]\tLoss: 1.853073, mean accuracy last epoch: 0.773\n",
      "Train Epoch 23 [40960/69249 (59%)]\tLoss: 1.903103, mean accuracy last epoch: 0.773\n",
      "Train Epoch 23 [43520/69249 (63%)]\tLoss: 1.907963, mean accuracy last epoch: 0.773\n",
      "Train Epoch 23 [46080/69249 (66%)]\tLoss: 1.932804, mean accuracy last epoch: 0.773\n",
      "Train Epoch 23 [48640/69249 (70%)]\tLoss: 1.926074, mean accuracy last epoch: 0.773\n",
      "Train Epoch 23 [51200/69249 (74%)]\tLoss: 1.860298, mean accuracy last epoch: 0.773\n",
      "Train Epoch 23 [53760/69249 (77%)]\tLoss: 1.887121, mean accuracy last epoch: 0.773\n",
      "Train Epoch 23 [56320/69249 (81%)]\tLoss: 1.869647, mean accuracy last epoch: 0.773\n",
      "Train Epoch 23 [58880/69249 (85%)]\tLoss: 1.905345, mean accuracy last epoch: 0.773\n",
      "Train Epoch 23 [61440/69249 (89%)]\tLoss: 1.882308, mean accuracy last epoch: 0.773\n",
      "Train Epoch 23 [64000/69249 (92%)]\tLoss: 1.886852, mean accuracy last epoch: 0.773\n",
      "Train Epoch 23 [66560/69249 (96%)]\tLoss: 1.868529, mean accuracy last epoch: 0.773\n",
      "Train Epoch 23 [34830/69249 (100%)]\tLoss: 1.977969, mean accuracy last epoch: 0.773\n",
      "Train Epoch 24 [0/69249 (0%)]\tLoss: 1.867283, mean accuracy last epoch: 0.773\n",
      "Train Epoch 24 [2560/69249 (4%)]\tLoss: 1.904555, mean accuracy last epoch: 0.773\n",
      "Train Epoch 24 [5120/69249 (7%)]\tLoss: 1.842486, mean accuracy last epoch: 0.773\n",
      "Train Epoch 24 [7680/69249 (11%)]\tLoss: 1.914148, mean accuracy last epoch: 0.773\n",
      "Train Epoch 24 [10240/69249 (15%)]\tLoss: 1.887953, mean accuracy last epoch: 0.773\n",
      "Train Epoch 24 [12800/69249 (18%)]\tLoss: 1.875363, mean accuracy last epoch: 0.773\n",
      "Train Epoch 24 [15360/69249 (22%)]\tLoss: 1.889189, mean accuracy last epoch: 0.773\n",
      "Train Epoch 24 [17920/69249 (26%)]\tLoss: 1.940137, mean accuracy last epoch: 0.773\n",
      "Train Epoch 24 [20480/69249 (30%)]\tLoss: 1.854313, mean accuracy last epoch: 0.773\n",
      "Train Epoch 24 [23040/69249 (33%)]\tLoss: 1.899800, mean accuracy last epoch: 0.773\n",
      "Train Epoch 24 [25600/69249 (37%)]\tLoss: 1.882706, mean accuracy last epoch: 0.773\n",
      "Train Epoch 24 [28160/69249 (41%)]\tLoss: 1.949768, mean accuracy last epoch: 0.773\n",
      "Train Epoch 24 [30720/69249 (44%)]\tLoss: 1.879404, mean accuracy last epoch: 0.774\n",
      "Train Epoch 24 [33280/69249 (48%)]\tLoss: 1.858547, mean accuracy last epoch: 0.774\n",
      "Train Epoch 24 [35840/69249 (52%)]\tLoss: 1.917892, mean accuracy last epoch: 0.774\n",
      "Train Epoch 24 [38400/69249 (55%)]\tLoss: 1.893142, mean accuracy last epoch: 0.774\n",
      "Train Epoch 24 [40960/69249 (59%)]\tLoss: 1.848499, mean accuracy last epoch: 0.774\n",
      "Train Epoch 24 [43520/69249 (63%)]\tLoss: 1.917146, mean accuracy last epoch: 0.774\n",
      "Train Epoch 24 [46080/69249 (66%)]\tLoss: 1.888852, mean accuracy last epoch: 0.774\n",
      "Train Epoch 24 [48640/69249 (70%)]\tLoss: 1.924446, mean accuracy last epoch: 0.774\n",
      "Train Epoch 24 [51200/69249 (74%)]\tLoss: 1.882243, mean accuracy last epoch: 0.774\n",
      "Train Epoch 24 [53760/69249 (77%)]\tLoss: 1.878777, mean accuracy last epoch: 0.774\n",
      "Train Epoch 24 [56320/69249 (81%)]\tLoss: 1.945662, mean accuracy last epoch: 0.774\n",
      "Train Epoch 24 [58880/69249 (85%)]\tLoss: 1.919035, mean accuracy last epoch: 0.774\n",
      "Train Epoch 24 [61440/69249 (89%)]\tLoss: 1.876948, mean accuracy last epoch: 0.774\n",
      "Train Epoch 24 [64000/69249 (92%)]\tLoss: 1.918446, mean accuracy last epoch: 0.774\n",
      "Train Epoch 24 [66560/69249 (96%)]\tLoss: 1.860728, mean accuracy last epoch: 0.774\n",
      "Train Epoch 24 [34830/69249 (100%)]\tLoss: 1.776518, mean accuracy last epoch: 0.774\n",
      "Train Epoch 25 [0/69249 (0%)]\tLoss: 1.849269, mean accuracy last epoch: 0.774\n",
      "Train Epoch 25 [2560/69249 (4%)]\tLoss: 1.895265, mean accuracy last epoch: 0.774\n",
      "Train Epoch 25 [5120/69249 (7%)]\tLoss: 1.869759, mean accuracy last epoch: 0.774\n",
      "Train Epoch 25 [7680/69249 (11%)]\tLoss: 1.886036, mean accuracy last epoch: 0.774\n",
      "Train Epoch 25 [10240/69249 (15%)]\tLoss: 1.868353, mean accuracy last epoch: 0.774\n",
      "Train Epoch 25 [12800/69249 (18%)]\tLoss: 1.867936, mean accuracy last epoch: 0.774\n",
      "Train Epoch 25 [15360/69249 (22%)]\tLoss: 1.891548, mean accuracy last epoch: 0.774\n",
      "Train Epoch 25 [17920/69249 (26%)]\tLoss: 1.866173, mean accuracy last epoch: 0.774\n",
      "Train Epoch 25 [20480/69249 (30%)]\tLoss: 1.868146, mean accuracy last epoch: 0.774\n",
      "Train Epoch 25 [23040/69249 (33%)]\tLoss: 1.894670, mean accuracy last epoch: 0.774\n",
      "Train Epoch 25 [25600/69249 (37%)]\tLoss: 1.877844, mean accuracy last epoch: 0.774\n",
      "Train Epoch 25 [28160/69249 (41%)]\tLoss: 1.917177, mean accuracy last epoch: 0.774\n",
      "Train Epoch 25 [30720/69249 (44%)]\tLoss: 1.837330, mean accuracy last epoch: 0.775\n",
      "Train Epoch 25 [33280/69249 (48%)]\tLoss: 1.887608, mean accuracy last epoch: 0.775\n",
      "Train Epoch 25 [35840/69249 (52%)]\tLoss: 1.904624, mean accuracy last epoch: 0.775\n",
      "Train Epoch 25 [38400/69249 (55%)]\tLoss: 1.922784, mean accuracy last epoch: 0.775\n",
      "Train Epoch 25 [40960/69249 (59%)]\tLoss: 1.842632, mean accuracy last epoch: 0.775\n",
      "Train Epoch 25 [43520/69249 (63%)]\tLoss: 1.917668, mean accuracy last epoch: 0.775\n",
      "Train Epoch 25 [46080/69249 (66%)]\tLoss: 1.945848, mean accuracy last epoch: 0.775\n",
      "Train Epoch 25 [48640/69249 (70%)]\tLoss: 1.892109, mean accuracy last epoch: 0.775\n",
      "Train Epoch 25 [51200/69249 (74%)]\tLoss: 1.891001, mean accuracy last epoch: 0.775\n",
      "Train Epoch 25 [53760/69249 (77%)]\tLoss: 1.902214, mean accuracy last epoch: 0.775\n",
      "Train Epoch 25 [56320/69249 (81%)]\tLoss: 1.924965, mean accuracy last epoch: 0.775\n",
      "Train Epoch 25 [58880/69249 (85%)]\tLoss: 1.899547, mean accuracy last epoch: 0.775\n",
      "Train Epoch 25 [61440/69249 (89%)]\tLoss: 1.883407, mean accuracy last epoch: 0.775\n",
      "Train Epoch 25 [64000/69249 (92%)]\tLoss: 1.877391, mean accuracy last epoch: 0.775\n",
      "Train Epoch 25 [66560/69249 (96%)]\tLoss: 1.891975, mean accuracy last epoch: 0.775\n",
      "Train Epoch 25 [34830/69249 (100%)]\tLoss: 1.840139, mean accuracy last epoch: 0.775\n",
      "Train Epoch 26 [0/69249 (0%)]\tLoss: 1.936105, mean accuracy last epoch: 0.775\n",
      "Train Epoch 26 [2560/69249 (4%)]\tLoss: 1.886358, mean accuracy last epoch: 0.775\n",
      "Train Epoch 26 [5120/69249 (7%)]\tLoss: 1.899436, mean accuracy last epoch: 0.775\n",
      "Train Epoch 26 [7680/69249 (11%)]\tLoss: 1.887835, mean accuracy last epoch: 0.775\n",
      "Train Epoch 26 [10240/69249 (15%)]\tLoss: 1.861935, mean accuracy last epoch: 0.775\n",
      "Train Epoch 26 [12800/69249 (18%)]\tLoss: 1.854444, mean accuracy last epoch: 0.775\n",
      "Train Epoch 26 [15360/69249 (22%)]\tLoss: 1.856005, mean accuracy last epoch: 0.775\n",
      "Train Epoch 26 [17920/69249 (26%)]\tLoss: 1.850081, mean accuracy last epoch: 0.775\n",
      "Train Epoch 26 [20480/69249 (30%)]\tLoss: 1.906366, mean accuracy last epoch: 0.775\n",
      "Train Epoch 26 [23040/69249 (33%)]\tLoss: 1.856426, mean accuracy last epoch: 0.775\n",
      "Train Epoch 26 [25600/69249 (37%)]\tLoss: 1.894584, mean accuracy last epoch: 0.775\n",
      "Train Epoch 26 [28160/69249 (41%)]\tLoss: 1.912151, mean accuracy last epoch: 0.775\n",
      "Train Epoch 26 [30720/69249 (44%)]\tLoss: 1.920063, mean accuracy last epoch: 0.775\n",
      "Train Epoch 26 [33280/69249 (48%)]\tLoss: 1.847634, mean accuracy last epoch: 0.775\n",
      "Train Epoch 26 [35840/69249 (52%)]\tLoss: 1.868122, mean accuracy last epoch: 0.776\n",
      "Train Epoch 26 [38400/69249 (55%)]\tLoss: 1.843916, mean accuracy last epoch: 0.776\n",
      "Train Epoch 26 [40960/69249 (59%)]\tLoss: 1.926671, mean accuracy last epoch: 0.776\n",
      "Train Epoch 26 [43520/69249 (63%)]\tLoss: 1.879606, mean accuracy last epoch: 0.776\n",
      "Train Epoch 26 [46080/69249 (66%)]\tLoss: 1.915502, mean accuracy last epoch: 0.776\n",
      "Train Epoch 26 [48640/69249 (70%)]\tLoss: 1.897855, mean accuracy last epoch: 0.776\n",
      "Train Epoch 26 [51200/69249 (74%)]\tLoss: 1.904479, mean accuracy last epoch: 0.776\n",
      "Train Epoch 26 [53760/69249 (77%)]\tLoss: 1.896441, mean accuracy last epoch: 0.776\n",
      "Train Epoch 26 [56320/69249 (81%)]\tLoss: 1.927781, mean accuracy last epoch: 0.776\n",
      "Train Epoch 26 [58880/69249 (85%)]\tLoss: 1.914102, mean accuracy last epoch: 0.776\n",
      "Train Epoch 26 [61440/69249 (89%)]\tLoss: 1.887179, mean accuracy last epoch: 0.776\n",
      "Train Epoch 26 [64000/69249 (92%)]\tLoss: 1.890812, mean accuracy last epoch: 0.776\n",
      "Train Epoch 26 [66560/69249 (96%)]\tLoss: 1.884682, mean accuracy last epoch: 0.776\n",
      "Train Epoch 26 [34830/69249 (100%)]\tLoss: 1.840660, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [0/69249 (0%)]\tLoss: 1.890983, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [2560/69249 (4%)]\tLoss: 1.874952, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [5120/69249 (7%)]\tLoss: 1.853999, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [7680/69249 (11%)]\tLoss: 1.940184, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [10240/69249 (15%)]\tLoss: 1.881247, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [12800/69249 (18%)]\tLoss: 1.864802, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [15360/69249 (22%)]\tLoss: 1.881244, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [17920/69249 (26%)]\tLoss: 1.901994, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [20480/69249 (30%)]\tLoss: 1.884124, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [23040/69249 (33%)]\tLoss: 1.883437, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [25600/69249 (37%)]\tLoss: 1.890368, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [28160/69249 (41%)]\tLoss: 1.870487, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [30720/69249 (44%)]\tLoss: 1.926995, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [33280/69249 (48%)]\tLoss: 1.938491, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [35840/69249 (52%)]\tLoss: 1.841185, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [38400/69249 (55%)]\tLoss: 1.872359, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [40960/69249 (59%)]\tLoss: 1.909853, mean accuracy last epoch: 0.776\n",
      "Train Epoch 27 [43520/69249 (63%)]\tLoss: 1.885655, mean accuracy last epoch: 0.777\n",
      "Train Epoch 27 [46080/69249 (66%)]\tLoss: 1.869735, mean accuracy last epoch: 0.777\n",
      "Train Epoch 27 [48640/69249 (70%)]\tLoss: 1.841341, mean accuracy last epoch: 0.777\n",
      "Train Epoch 27 [51200/69249 (74%)]\tLoss: 1.902789, mean accuracy last epoch: 0.777\n",
      "Train Epoch 27 [53760/69249 (77%)]\tLoss: 1.865493, mean accuracy last epoch: 0.777\n",
      "Train Epoch 27 [56320/69249 (81%)]\tLoss: 1.874146, mean accuracy last epoch: 0.777\n",
      "Train Epoch 27 [58880/69249 (85%)]\tLoss: 1.920870, mean accuracy last epoch: 0.777\n",
      "Train Epoch 27 [61440/69249 (89%)]\tLoss: 1.907818, mean accuracy last epoch: 0.777\n",
      "Train Epoch 27 [64000/69249 (92%)]\tLoss: 1.888327, mean accuracy last epoch: 0.777\n",
      "Train Epoch 27 [66560/69249 (96%)]\tLoss: 1.898481, mean accuracy last epoch: 0.777\n",
      "Train Epoch 27 [34830/69249 (100%)]\tLoss: 1.865091, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [0/69249 (0%)]\tLoss: 1.912803, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [2560/69249 (4%)]\tLoss: 1.873729, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [5120/69249 (7%)]\tLoss: 1.901057, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [7680/69249 (11%)]\tLoss: 1.881613, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [10240/69249 (15%)]\tLoss: 1.907901, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [12800/69249 (18%)]\tLoss: 1.850883, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [15360/69249 (22%)]\tLoss: 1.897449, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [17920/69249 (26%)]\tLoss: 1.879329, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [20480/69249 (30%)]\tLoss: 1.903146, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [23040/69249 (33%)]\tLoss: 1.881522, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [25600/69249 (37%)]\tLoss: 1.913668, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [28160/69249 (41%)]\tLoss: 1.876968, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [30720/69249 (44%)]\tLoss: 1.898062, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [33280/69249 (48%)]\tLoss: 1.887783, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [35840/69249 (52%)]\tLoss: 1.872672, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [38400/69249 (55%)]\tLoss: 1.893496, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [40960/69249 (59%)]\tLoss: 1.921215, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [43520/69249 (63%)]\tLoss: 1.920707, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [46080/69249 (66%)]\tLoss: 1.866158, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [48640/69249 (70%)]\tLoss: 1.891152, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [51200/69249 (74%)]\tLoss: 1.903587, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [53760/69249 (77%)]\tLoss: 1.835431, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [56320/69249 (81%)]\tLoss: 1.881769, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [58880/69249 (85%)]\tLoss: 1.941147, mean accuracy last epoch: 0.777\n",
      "Train Epoch 28 [61440/69249 (89%)]\tLoss: 1.927385, mean accuracy last epoch: 0.778\n",
      "Train Epoch 28 [64000/69249 (92%)]\tLoss: 1.874100, mean accuracy last epoch: 0.778\n",
      "Train Epoch 28 [66560/69249 (96%)]\tLoss: 1.889694, mean accuracy last epoch: 0.778\n",
      "Train Epoch 28 [34830/69249 (100%)]\tLoss: 1.839446, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [0/69249 (0%)]\tLoss: 1.915373, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [2560/69249 (4%)]\tLoss: 1.896006, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [5120/69249 (7%)]\tLoss: 1.855725, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [7680/69249 (11%)]\tLoss: 1.904732, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [10240/69249 (15%)]\tLoss: 1.871482, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [12800/69249 (18%)]\tLoss: 1.885053, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [15360/69249 (22%)]\tLoss: 1.907233, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [17920/69249 (26%)]\tLoss: 1.880046, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [20480/69249 (30%)]\tLoss: 1.875582, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [23040/69249 (33%)]\tLoss: 1.859934, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [25600/69249 (37%)]\tLoss: 1.905800, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [28160/69249 (41%)]\tLoss: 1.898371, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [30720/69249 (44%)]\tLoss: 1.892434, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [33280/69249 (48%)]\tLoss: 1.948657, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [35840/69249 (52%)]\tLoss: 1.922505, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [38400/69249 (55%)]\tLoss: 1.846184, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [40960/69249 (59%)]\tLoss: 1.862935, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [43520/69249 (63%)]\tLoss: 1.870377, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [46080/69249 (66%)]\tLoss: 1.899422, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [48640/69249 (70%)]\tLoss: 1.876408, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [51200/69249 (74%)]\tLoss: 1.918353, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [53760/69249 (77%)]\tLoss: 1.907742, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [56320/69249 (81%)]\tLoss: 1.843889, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [58880/69249 (85%)]\tLoss: 1.899449, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [61440/69249 (89%)]\tLoss: 1.845710, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [64000/69249 (92%)]\tLoss: 1.922001, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [66560/69249 (96%)]\tLoss: 1.892788, mean accuracy last epoch: 0.778\n",
      "Train Epoch 29 [34830/69249 (100%)]\tLoss: 1.819393, mean accuracy last epoch: 0.778\n",
      "Train Epoch 30 [0/69249 (0%)]\tLoss: 1.893867, mean accuracy last epoch: 0.778\n",
      "Train Epoch 30 [2560/69249 (4%)]\tLoss: 1.856891, mean accuracy last epoch: 0.778\n",
      "Train Epoch 30 [5120/69249 (7%)]\tLoss: 1.930539, mean accuracy last epoch: 0.778\n",
      "Train Epoch 30 [7680/69249 (11%)]\tLoss: 1.915771, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [10240/69249 (15%)]\tLoss: 1.874465, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [12800/69249 (18%)]\tLoss: 1.860252, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [15360/69249 (22%)]\tLoss: 1.887431, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [17920/69249 (26%)]\tLoss: 1.902917, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [20480/69249 (30%)]\tLoss: 1.895092, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [23040/69249 (33%)]\tLoss: 1.942123, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [25600/69249 (37%)]\tLoss: 1.871371, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [28160/69249 (41%)]\tLoss: 1.911530, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [30720/69249 (44%)]\tLoss: 1.888205, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [33280/69249 (48%)]\tLoss: 1.851598, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [35840/69249 (52%)]\tLoss: 1.857875, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [38400/69249 (55%)]\tLoss: 1.867587, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [40960/69249 (59%)]\tLoss: 1.887859, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [43520/69249 (63%)]\tLoss: 1.916852, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [46080/69249 (66%)]\tLoss: 1.886293, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [48640/69249 (70%)]\tLoss: 1.925443, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [51200/69249 (74%)]\tLoss: 1.866276, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [53760/69249 (77%)]\tLoss: 1.841758, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [56320/69249 (81%)]\tLoss: 1.880711, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [58880/69249 (85%)]\tLoss: 1.917869, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [61440/69249 (89%)]\tLoss: 1.895260, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [64000/69249 (92%)]\tLoss: 1.886460, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [66560/69249 (96%)]\tLoss: 1.905645, mean accuracy last epoch: 0.779\n",
      "Train Epoch 30 [34830/69249 (100%)]\tLoss: 1.885436, mean accuracy last epoch: 0.779\n",
      "Train Epoch 31 [0/69249 (0%)]\tLoss: 1.858992, mean accuracy last epoch: 0.779\n",
      "Train Epoch 31 [2560/69249 (4%)]\tLoss: 1.871037, mean accuracy last epoch: 0.779\n",
      "Train Epoch 31 [5120/69249 (7%)]\tLoss: 1.935691, mean accuracy last epoch: 0.779\n",
      "Train Epoch 31 [7680/69249 (11%)]\tLoss: 1.878026, mean accuracy last epoch: 0.779\n",
      "Train Epoch 31 [10240/69249 (15%)]\tLoss: 1.868339, mean accuracy last epoch: 0.779\n",
      "Train Epoch 31 [12800/69249 (18%)]\tLoss: 1.869850, mean accuracy last epoch: 0.779\n",
      "Train Epoch 31 [15360/69249 (22%)]\tLoss: 1.898369, mean accuracy last epoch: 0.779\n",
      "Train Epoch 31 [17920/69249 (26%)]\tLoss: 1.834053, mean accuracy last epoch: 0.779\n",
      "Train Epoch 31 [20480/69249 (30%)]\tLoss: 1.902054, mean accuracy last epoch: 0.779\n",
      "Train Epoch 31 [23040/69249 (33%)]\tLoss: 1.896175, mean accuracy last epoch: 0.779\n",
      "Train Epoch 31 [25600/69249 (37%)]\tLoss: 1.896021, mean accuracy last epoch: 0.779\n",
      "Train Epoch 31 [28160/69249 (41%)]\tLoss: 1.890840, mean accuracy last epoch: 0.779\n",
      "Train Epoch 31 [30720/69249 (44%)]\tLoss: 1.853033, mean accuracy last epoch: 0.780\n",
      "Train Epoch 31 [33280/69249 (48%)]\tLoss: 1.855541, mean accuracy last epoch: 0.780\n",
      "Train Epoch 31 [35840/69249 (52%)]\tLoss: 1.905690, mean accuracy last epoch: 0.780\n",
      "Train Epoch 31 [38400/69249 (55%)]\tLoss: 1.891435, mean accuracy last epoch: 0.780\n",
      "Train Epoch 31 [40960/69249 (59%)]\tLoss: 1.910430, mean accuracy last epoch: 0.780\n",
      "Train Epoch 31 [43520/69249 (63%)]\tLoss: 1.902331, mean accuracy last epoch: 0.780\n",
      "Train Epoch 31 [46080/69249 (66%)]\tLoss: 1.928978, mean accuracy last epoch: 0.780\n",
      "Train Epoch 31 [48640/69249 (70%)]\tLoss: 1.868986, mean accuracy last epoch: 0.780\n",
      "Train Epoch 31 [51200/69249 (74%)]\tLoss: 1.889723, mean accuracy last epoch: 0.780\n",
      "Train Epoch 31 [53760/69249 (77%)]\tLoss: 1.884397, mean accuracy last epoch: 0.780\n",
      "Train Epoch 31 [56320/69249 (81%)]\tLoss: 1.916532, mean accuracy last epoch: 0.780\n",
      "Train Epoch 31 [58880/69249 (85%)]\tLoss: 1.877308, mean accuracy last epoch: 0.780\n",
      "Train Epoch 31 [61440/69249 (89%)]\tLoss: 1.907375, mean accuracy last epoch: 0.780\n",
      "Train Epoch 31 [64000/69249 (92%)]\tLoss: 1.937778, mean accuracy last epoch: 0.780\n",
      "Train Epoch 31 [66560/69249 (96%)]\tLoss: 1.914120, mean accuracy last epoch: 0.780\n",
      "Train Epoch 31 [34830/69249 (100%)]\tLoss: 1.894716, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [0/69249 (0%)]\tLoss: 1.886723, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [2560/69249 (4%)]\tLoss: 1.873593, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [5120/69249 (7%)]\tLoss: 1.870652, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [7680/69249 (11%)]\tLoss: 1.876117, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [10240/69249 (15%)]\tLoss: 1.824978, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [12800/69249 (18%)]\tLoss: 1.855577, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [15360/69249 (22%)]\tLoss: 1.878770, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [17920/69249 (26%)]\tLoss: 1.876756, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [20480/69249 (30%)]\tLoss: 1.911561, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [23040/69249 (33%)]\tLoss: 1.909953, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [25600/69249 (37%)]\tLoss: 1.913155, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [28160/69249 (41%)]\tLoss: 1.925024, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [30720/69249 (44%)]\tLoss: 1.895166, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [33280/69249 (48%)]\tLoss: 1.911680, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [35840/69249 (52%)]\tLoss: 1.923945, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [38400/69249 (55%)]\tLoss: 1.929933, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [40960/69249 (59%)]\tLoss: 1.911061, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [43520/69249 (63%)]\tLoss: 1.945569, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [46080/69249 (66%)]\tLoss: 1.892820, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [48640/69249 (70%)]\tLoss: 1.923980, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [51200/69249 (74%)]\tLoss: 1.899639, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [53760/69249 (77%)]\tLoss: 1.847945, mean accuracy last epoch: 0.780\n",
      "Train Epoch 32 [56320/69249 (81%)]\tLoss: 1.881263, mean accuracy last epoch: 0.781\n",
      "Train Epoch 32 [58880/69249 (85%)]\tLoss: 1.914852, mean accuracy last epoch: 0.781\n",
      "Train Epoch 32 [61440/69249 (89%)]\tLoss: 1.915748, mean accuracy last epoch: 0.781\n",
      "Train Epoch 32 [64000/69249 (92%)]\tLoss: 1.870572, mean accuracy last epoch: 0.781\n",
      "Train Epoch 32 [66560/69249 (96%)]\tLoss: 1.909490, mean accuracy last epoch: 0.781\n",
      "Train Epoch 32 [34830/69249 (100%)]\tLoss: 1.921314, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [0/69249 (0%)]\tLoss: 1.915268, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [2560/69249 (4%)]\tLoss: 1.879655, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [5120/69249 (7%)]\tLoss: 1.877340, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [7680/69249 (11%)]\tLoss: 1.904141, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [10240/69249 (15%)]\tLoss: 1.857927, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [12800/69249 (18%)]\tLoss: 1.925093, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [15360/69249 (22%)]\tLoss: 1.915341, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [17920/69249 (26%)]\tLoss: 1.895412, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [20480/69249 (30%)]\tLoss: 1.905441, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [23040/69249 (33%)]\tLoss: 1.848137, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [25600/69249 (37%)]\tLoss: 1.883176, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [28160/69249 (41%)]\tLoss: 1.895078, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [30720/69249 (44%)]\tLoss: 1.889115, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [33280/69249 (48%)]\tLoss: 1.926064, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [35840/69249 (52%)]\tLoss: 1.859618, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [38400/69249 (55%)]\tLoss: 1.892861, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [40960/69249 (59%)]\tLoss: 1.884297, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [43520/69249 (63%)]\tLoss: 1.921631, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [46080/69249 (66%)]\tLoss: 1.891778, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [48640/69249 (70%)]\tLoss: 1.868470, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [51200/69249 (74%)]\tLoss: 1.895086, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [53760/69249 (77%)]\tLoss: 1.887715, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [56320/69249 (81%)]\tLoss: 1.883801, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [58880/69249 (85%)]\tLoss: 1.914263, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [61440/69249 (89%)]\tLoss: 1.894205, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [64000/69249 (92%)]\tLoss: 1.838746, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [66560/69249 (96%)]\tLoss: 1.860589, mean accuracy last epoch: 0.781\n",
      "Train Epoch 33 [34830/69249 (100%)]\tLoss: 1.904094, mean accuracy last epoch: 0.781\n",
      "Train Epoch 34 [0/69249 (0%)]\tLoss: 1.877440, mean accuracy last epoch: 0.781\n",
      "Train Epoch 34 [2560/69249 (4%)]\tLoss: 1.867854, mean accuracy last epoch: 0.781\n",
      "Train Epoch 34 [5120/69249 (7%)]\tLoss: 1.882335, mean accuracy last epoch: 0.781\n",
      "Train Epoch 34 [7680/69249 (11%)]\tLoss: 1.860071, mean accuracy last epoch: 0.781\n",
      "Train Epoch 34 [10240/69249 (15%)]\tLoss: 1.822732, mean accuracy last epoch: 0.781\n",
      "Train Epoch 34 [12800/69249 (18%)]\tLoss: 1.873906, mean accuracy last epoch: 0.781\n",
      "Train Epoch 34 [15360/69249 (22%)]\tLoss: 1.896040, mean accuracy last epoch: 0.781\n",
      "Train Epoch 34 [17920/69249 (26%)]\tLoss: 1.885778, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [20480/69249 (30%)]\tLoss: 1.916288, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [23040/69249 (33%)]\tLoss: 1.871996, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [25600/69249 (37%)]\tLoss: 1.884070, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [28160/69249 (41%)]\tLoss: 1.853451, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [30720/69249 (44%)]\tLoss: 1.885903, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [33280/69249 (48%)]\tLoss: 1.846755, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [35840/69249 (52%)]\tLoss: 1.900361, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [38400/69249 (55%)]\tLoss: 1.885469, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [40960/69249 (59%)]\tLoss: 1.912826, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [43520/69249 (63%)]\tLoss: 1.921146, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [46080/69249 (66%)]\tLoss: 1.915123, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [48640/69249 (70%)]\tLoss: 1.906971, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [51200/69249 (74%)]\tLoss: 1.878899, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [53760/69249 (77%)]\tLoss: 1.896431, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [56320/69249 (81%)]\tLoss: 1.906373, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [58880/69249 (85%)]\tLoss: 1.849138, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [61440/69249 (89%)]\tLoss: 1.855421, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [64000/69249 (92%)]\tLoss: 1.887299, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [66560/69249 (96%)]\tLoss: 1.891955, mean accuracy last epoch: 0.782\n",
      "Train Epoch 34 [34830/69249 (100%)]\tLoss: 1.882472, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [0/69249 (0%)]\tLoss: 1.880697, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [2560/69249 (4%)]\tLoss: 1.889748, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [5120/69249 (7%)]\tLoss: 1.897054, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [7680/69249 (11%)]\tLoss: 1.937804, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [10240/69249 (15%)]\tLoss: 1.892440, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [12800/69249 (18%)]\tLoss: 1.883677, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [15360/69249 (22%)]\tLoss: 1.907203, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [17920/69249 (26%)]\tLoss: 1.903385, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [20480/69249 (30%)]\tLoss: 1.873654, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [23040/69249 (33%)]\tLoss: 1.891469, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [25600/69249 (37%)]\tLoss: 1.894581, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [28160/69249 (41%)]\tLoss: 1.888048, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [30720/69249 (44%)]\tLoss: 1.876406, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [33280/69249 (48%)]\tLoss: 1.879486, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [35840/69249 (52%)]\tLoss: 1.839926, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [38400/69249 (55%)]\tLoss: 1.895015, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [40960/69249 (59%)]\tLoss: 1.911123, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [43520/69249 (63%)]\tLoss: 1.903647, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [46080/69249 (66%)]\tLoss: 1.873249, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [48640/69249 (70%)]\tLoss: 1.914114, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [51200/69249 (74%)]\tLoss: 1.920334, mean accuracy last epoch: 0.782\n",
      "Train Epoch 35 [53760/69249 (77%)]\tLoss: 1.921723, mean accuracy last epoch: 0.783\n",
      "Train Epoch 35 [56320/69249 (81%)]\tLoss: 1.880998, mean accuracy last epoch: 0.783\n",
      "Train Epoch 35 [58880/69249 (85%)]\tLoss: 1.852594, mean accuracy last epoch: 0.783\n",
      "Train Epoch 35 [61440/69249 (89%)]\tLoss: 1.910373, mean accuracy last epoch: 0.783\n",
      "Train Epoch 35 [64000/69249 (92%)]\tLoss: 1.858001, mean accuracy last epoch: 0.783\n",
      "Train Epoch 35 [66560/69249 (96%)]\tLoss: 1.905992, mean accuracy last epoch: 0.783\n",
      "Train Epoch 35 [34830/69249 (100%)]\tLoss: 1.899701, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [0/69249 (0%)]\tLoss: 1.863566, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [2560/69249 (4%)]\tLoss: 1.916433, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [5120/69249 (7%)]\tLoss: 1.872668, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [7680/69249 (11%)]\tLoss: 1.851087, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [10240/69249 (15%)]\tLoss: 1.853490, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [12800/69249 (18%)]\tLoss: 1.878698, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [15360/69249 (22%)]\tLoss: 1.896992, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [17920/69249 (26%)]\tLoss: 1.850912, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [20480/69249 (30%)]\tLoss: 1.928017, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [23040/69249 (33%)]\tLoss: 1.861130, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [25600/69249 (37%)]\tLoss: 1.889413, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [28160/69249 (41%)]\tLoss: 1.868910, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [30720/69249 (44%)]\tLoss: 1.872901, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [33280/69249 (48%)]\tLoss: 1.875558, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [35840/69249 (52%)]\tLoss: 1.853864, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [38400/69249 (55%)]\tLoss: 1.915017, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [40960/69249 (59%)]\tLoss: 1.880838, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [43520/69249 (63%)]\tLoss: 1.844676, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [46080/69249 (66%)]\tLoss: 1.908260, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [48640/69249 (70%)]\tLoss: 1.884923, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [51200/69249 (74%)]\tLoss: 1.895970, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [53760/69249 (77%)]\tLoss: 1.895937, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [56320/69249 (81%)]\tLoss: 1.881368, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [58880/69249 (85%)]\tLoss: 1.858064, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [61440/69249 (89%)]\tLoss: 1.909922, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [64000/69249 (92%)]\tLoss: 1.855293, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [66560/69249 (96%)]\tLoss: 1.861385, mean accuracy last epoch: 0.783\n",
      "Train Epoch 36 [34830/69249 (100%)]\tLoss: 1.941204, mean accuracy last epoch: 0.783\n",
      "Train Epoch 37 [0/69249 (0%)]\tLoss: 1.886254, mean accuracy last epoch: 0.783\n",
      "Train Epoch 37 [2560/69249 (4%)]\tLoss: 1.876423, mean accuracy last epoch: 0.783\n",
      "Train Epoch 37 [5120/69249 (7%)]\tLoss: 1.883914, mean accuracy last epoch: 0.783\n",
      "Train Epoch 37 [7680/69249 (11%)]\tLoss: 1.932004, mean accuracy last epoch: 0.783\n",
      "Train Epoch 37 [10240/69249 (15%)]\tLoss: 1.906469, mean accuracy last epoch: 0.783\n",
      "Train Epoch 37 [12800/69249 (18%)]\tLoss: 1.904882, mean accuracy last epoch: 0.783\n",
      "Train Epoch 37 [15360/69249 (22%)]\tLoss: 1.915197, mean accuracy last epoch: 0.783\n",
      "Train Epoch 37 [17920/69249 (26%)]\tLoss: 1.873439, mean accuracy last epoch: 0.783\n",
      "Train Epoch 37 [20480/69249 (30%)]\tLoss: 1.836925, mean accuracy last epoch: 0.783\n",
      "Train Epoch 37 [23040/69249 (33%)]\tLoss: 1.866856, mean accuracy last epoch: 0.783\n",
      "Train Epoch 37 [25600/69249 (37%)]\tLoss: 1.897807, mean accuracy last epoch: 0.783\n",
      "Train Epoch 37 [28160/69249 (41%)]\tLoss: 1.849304, mean accuracy last epoch: 0.783\n",
      "Train Epoch 37 [30720/69249 (44%)]\tLoss: 1.865800, mean accuracy last epoch: 0.784\n",
      "Train Epoch 37 [33280/69249 (48%)]\tLoss: 1.937811, mean accuracy last epoch: 0.784\n",
      "Train Epoch 37 [35840/69249 (52%)]\tLoss: 1.889397, mean accuracy last epoch: 0.784\n",
      "Train Epoch 37 [38400/69249 (55%)]\tLoss: 1.933527, mean accuracy last epoch: 0.784\n",
      "Train Epoch 37 [40960/69249 (59%)]\tLoss: 1.875686, mean accuracy last epoch: 0.784\n",
      "Train Epoch 37 [43520/69249 (63%)]\tLoss: 1.871264, mean accuracy last epoch: 0.784\n",
      "Train Epoch 37 [46080/69249 (66%)]\tLoss: 1.869016, mean accuracy last epoch: 0.784\n",
      "Train Epoch 37 [48640/69249 (70%)]\tLoss: 1.862166, mean accuracy last epoch: 0.784\n",
      "Train Epoch 37 [51200/69249 (74%)]\tLoss: 1.906944, mean accuracy last epoch: 0.784\n",
      "Train Epoch 37 [53760/69249 (77%)]\tLoss: 1.896742, mean accuracy last epoch: 0.784\n",
      "Train Epoch 37 [56320/69249 (81%)]\tLoss: 1.890793, mean accuracy last epoch: 0.784\n",
      "Train Epoch 37 [58880/69249 (85%)]\tLoss: 1.863814, mean accuracy last epoch: 0.784\n",
      "Train Epoch 37 [61440/69249 (89%)]\tLoss: 1.871145, mean accuracy last epoch: 0.784\n",
      "Train Epoch 37 [64000/69249 (92%)]\tLoss: 1.893068, mean accuracy last epoch: 0.784\n",
      "Train Epoch 37 [66560/69249 (96%)]\tLoss: 1.909589, mean accuracy last epoch: 0.784\n",
      "Train Epoch 37 [34830/69249 (100%)]\tLoss: 1.826330, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [0/69249 (0%)]\tLoss: 1.886837, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [2560/69249 (4%)]\tLoss: 1.866788, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [5120/69249 (7%)]\tLoss: 1.904948, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [7680/69249 (11%)]\tLoss: 1.895138, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [10240/69249 (15%)]\tLoss: 1.918830, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [12800/69249 (18%)]\tLoss: 1.851394, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [15360/69249 (22%)]\tLoss: 1.913953, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [17920/69249 (26%)]\tLoss: 1.872662, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [20480/69249 (30%)]\tLoss: 1.869644, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [23040/69249 (33%)]\tLoss: 1.899030, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [25600/69249 (37%)]\tLoss: 1.908677, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [28160/69249 (41%)]\tLoss: 1.877137, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [30720/69249 (44%)]\tLoss: 1.910334, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [33280/69249 (48%)]\tLoss: 1.882636, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [35840/69249 (52%)]\tLoss: 1.897731, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [38400/69249 (55%)]\tLoss: 1.897922, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [40960/69249 (59%)]\tLoss: 1.901247, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [43520/69249 (63%)]\tLoss: 1.900771, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [46080/69249 (66%)]\tLoss: 1.914653, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [48640/69249 (70%)]\tLoss: 1.882355, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [51200/69249 (74%)]\tLoss: 1.829262, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [53760/69249 (77%)]\tLoss: 1.892443, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [56320/69249 (81%)]\tLoss: 1.880482, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [58880/69249 (85%)]\tLoss: 1.853068, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [61440/69249 (89%)]\tLoss: 1.853302, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [64000/69249 (92%)]\tLoss: 1.924946, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [66560/69249 (96%)]\tLoss: 1.900793, mean accuracy last epoch: 0.784\n",
      "Train Epoch 38 [34830/69249 (100%)]\tLoss: 1.873180, mean accuracy last epoch: 0.784\n",
      "Train Epoch 39 [0/69249 (0%)]\tLoss: 1.871825, mean accuracy last epoch: 0.784\n",
      "Train Epoch 39 [2560/69249 (4%)]\tLoss: 1.910851, mean accuracy last epoch: 0.784\n",
      "Train Epoch 39 [5120/69249 (7%)]\tLoss: 1.931524, mean accuracy last epoch: 0.784\n",
      "Train Epoch 39 [7680/69249 (11%)]\tLoss: 1.915662, mean accuracy last epoch: 0.784\n",
      "Train Epoch 39 [10240/69249 (15%)]\tLoss: 1.868095, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [12800/69249 (18%)]\tLoss: 1.869959, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [15360/69249 (22%)]\tLoss: 1.902137, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [17920/69249 (26%)]\tLoss: 1.887064, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [20480/69249 (30%)]\tLoss: 1.893943, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [23040/69249 (33%)]\tLoss: 1.881525, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [25600/69249 (37%)]\tLoss: 1.894703, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [28160/69249 (41%)]\tLoss: 1.894912, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [30720/69249 (44%)]\tLoss: 1.890259, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [33280/69249 (48%)]\tLoss: 1.923945, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [35840/69249 (52%)]\tLoss: 1.890408, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [38400/69249 (55%)]\tLoss: 1.901981, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [40960/69249 (59%)]\tLoss: 1.863082, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [43520/69249 (63%)]\tLoss: 1.883422, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [46080/69249 (66%)]\tLoss: 1.885311, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [48640/69249 (70%)]\tLoss: 1.868546, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [51200/69249 (74%)]\tLoss: 1.890452, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [53760/69249 (77%)]\tLoss: 1.886043, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [56320/69249 (81%)]\tLoss: 1.860487, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [58880/69249 (85%)]\tLoss: 1.905288, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [61440/69249 (89%)]\tLoss: 1.872677, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [64000/69249 (92%)]\tLoss: 1.870041, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [66560/69249 (96%)]\tLoss: 1.903948, mean accuracy last epoch: 0.785\n",
      "Train Epoch 39 [34830/69249 (100%)]\tLoss: 1.858323, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [0/69249 (0%)]\tLoss: 1.878760, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [2560/69249 (4%)]\tLoss: 1.902735, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [5120/69249 (7%)]\tLoss: 1.843432, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [7680/69249 (11%)]\tLoss: 1.879867, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [10240/69249 (15%)]\tLoss: 1.857260, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [12800/69249 (18%)]\tLoss: 1.915057, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [15360/69249 (22%)]\tLoss: 1.926090, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [17920/69249 (26%)]\tLoss: 1.925904, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [20480/69249 (30%)]\tLoss: 1.860327, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [23040/69249 (33%)]\tLoss: 1.841359, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [25600/69249 (37%)]\tLoss: 1.909580, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [28160/69249 (41%)]\tLoss: 1.908245, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [30720/69249 (44%)]\tLoss: 1.856259, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [33280/69249 (48%)]\tLoss: 1.879728, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [35840/69249 (52%)]\tLoss: 1.886417, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [38400/69249 (55%)]\tLoss: 1.877954, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [40960/69249 (59%)]\tLoss: 1.901160, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [43520/69249 (63%)]\tLoss: 1.915550, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [46080/69249 (66%)]\tLoss: 1.879989, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [48640/69249 (70%)]\tLoss: 1.912552, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [51200/69249 (74%)]\tLoss: 1.902535, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [53760/69249 (77%)]\tLoss: 1.890121, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [56320/69249 (81%)]\tLoss: 1.895799, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [58880/69249 (85%)]\tLoss: 1.911015, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [61440/69249 (89%)]\tLoss: 1.866917, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [64000/69249 (92%)]\tLoss: 1.924486, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [66560/69249 (96%)]\tLoss: 1.887373, mean accuracy last epoch: 0.785\n",
      "Train Epoch 40 [34830/69249 (100%)]\tLoss: 1.873974, mean accuracy last epoch: 0.785\n",
      "Train Epoch 41 [0/69249 (0%)]\tLoss: 1.855147, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [2560/69249 (4%)]\tLoss: 1.833722, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [5120/69249 (7%)]\tLoss: 1.943150, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [7680/69249 (11%)]\tLoss: 1.885542, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [10240/69249 (15%)]\tLoss: 1.904030, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [12800/69249 (18%)]\tLoss: 1.855819, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [15360/69249 (22%)]\tLoss: 1.860201, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [17920/69249 (26%)]\tLoss: 1.895332, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [20480/69249 (30%)]\tLoss: 1.865644, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [23040/69249 (33%)]\tLoss: 1.892548, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [25600/69249 (37%)]\tLoss: 1.870721, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [28160/69249 (41%)]\tLoss: 1.863979, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [30720/69249 (44%)]\tLoss: 1.910105, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [33280/69249 (48%)]\tLoss: 1.865266, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [35840/69249 (52%)]\tLoss: 1.867853, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [38400/69249 (55%)]\tLoss: 1.888629, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [40960/69249 (59%)]\tLoss: 1.867415, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [43520/69249 (63%)]\tLoss: 1.887972, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [46080/69249 (66%)]\tLoss: 1.849602, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [48640/69249 (70%)]\tLoss: 1.891978, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [51200/69249 (74%)]\tLoss: 1.867534, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [53760/69249 (77%)]\tLoss: 1.936798, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [56320/69249 (81%)]\tLoss: 1.886595, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [58880/69249 (85%)]\tLoss: 1.901344, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [61440/69249 (89%)]\tLoss: 1.897018, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [64000/69249 (92%)]\tLoss: 1.874700, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [66560/69249 (96%)]\tLoss: 1.849810, mean accuracy last epoch: 0.786\n",
      "Train Epoch 41 [34830/69249 (100%)]\tLoss: 1.914143, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [0/69249 (0%)]\tLoss: 1.875780, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [2560/69249 (4%)]\tLoss: 1.885782, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [5120/69249 (7%)]\tLoss: 1.897811, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [7680/69249 (11%)]\tLoss: 1.847493, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [10240/69249 (15%)]\tLoss: 1.850611, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [12800/69249 (18%)]\tLoss: 1.911811, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [15360/69249 (22%)]\tLoss: 1.895561, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [17920/69249 (26%)]\tLoss: 1.941010, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [20480/69249 (30%)]\tLoss: 1.917171, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [23040/69249 (33%)]\tLoss: 1.871689, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [25600/69249 (37%)]\tLoss: 1.909306, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [28160/69249 (41%)]\tLoss: 1.913342, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [30720/69249 (44%)]\tLoss: 1.888970, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [33280/69249 (48%)]\tLoss: 1.897822, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [35840/69249 (52%)]\tLoss: 1.898030, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [38400/69249 (55%)]\tLoss: 1.848357, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [40960/69249 (59%)]\tLoss: 1.869625, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [43520/69249 (63%)]\tLoss: 1.921292, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [46080/69249 (66%)]\tLoss: 1.901094, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [48640/69249 (70%)]\tLoss: 1.901355, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [51200/69249 (74%)]\tLoss: 1.864982, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [53760/69249 (77%)]\tLoss: 1.897037, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [56320/69249 (81%)]\tLoss: 1.903854, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [58880/69249 (85%)]\tLoss: 1.881198, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [61440/69249 (89%)]\tLoss: 1.893672, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [64000/69249 (92%)]\tLoss: 1.870682, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [66560/69249 (96%)]\tLoss: 1.884691, mean accuracy last epoch: 0.786\n",
      "Train Epoch 42 [34830/69249 (100%)]\tLoss: 1.866651, mean accuracy last epoch: 0.786\n",
      "Train Epoch 43 [0/69249 (0%)]\tLoss: 1.865743, mean accuracy last epoch: 0.786\n",
      "Train Epoch 43 [2560/69249 (4%)]\tLoss: 1.874282, mean accuracy last epoch: 0.786\n",
      "Train Epoch 43 [5120/69249 (7%)]\tLoss: 1.859255, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [7680/69249 (11%)]\tLoss: 1.839419, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [10240/69249 (15%)]\tLoss: 1.901529, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [12800/69249 (18%)]\tLoss: 1.903604, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [15360/69249 (22%)]\tLoss: 1.873177, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [17920/69249 (26%)]\tLoss: 1.938843, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [20480/69249 (30%)]\tLoss: 1.870545, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [23040/69249 (33%)]\tLoss: 1.878422, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [25600/69249 (37%)]\tLoss: 1.878206, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [28160/69249 (41%)]\tLoss: 1.863286, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [30720/69249 (44%)]\tLoss: 1.871725, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [33280/69249 (48%)]\tLoss: 1.862238, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [35840/69249 (52%)]\tLoss: 1.926479, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [38400/69249 (55%)]\tLoss: 1.869312, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [40960/69249 (59%)]\tLoss: 1.873940, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [43520/69249 (63%)]\tLoss: 1.894847, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [46080/69249 (66%)]\tLoss: 1.915404, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [48640/69249 (70%)]\tLoss: 1.881522, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [51200/69249 (74%)]\tLoss: 1.873569, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [53760/69249 (77%)]\tLoss: 1.887967, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [56320/69249 (81%)]\tLoss: 1.888570, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [58880/69249 (85%)]\tLoss: 1.899462, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [61440/69249 (89%)]\tLoss: 1.865221, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [64000/69249 (92%)]\tLoss: 1.836560, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [66560/69249 (96%)]\tLoss: 1.891670, mean accuracy last epoch: 0.787\n",
      "Train Epoch 43 [34830/69249 (100%)]\tLoss: 1.829678, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [0/69249 (0%)]\tLoss: 1.891380, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [2560/69249 (4%)]\tLoss: 1.890172, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [5120/69249 (7%)]\tLoss: 1.881685, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [7680/69249 (11%)]\tLoss: 1.861702, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [10240/69249 (15%)]\tLoss: 1.861251, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [12800/69249 (18%)]\tLoss: 1.902673, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [15360/69249 (22%)]\tLoss: 1.887415, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [17920/69249 (26%)]\tLoss: 1.867698, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [20480/69249 (30%)]\tLoss: 1.902311, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [23040/69249 (33%)]\tLoss: 1.915740, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [25600/69249 (37%)]\tLoss: 1.890101, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [28160/69249 (41%)]\tLoss: 1.857616, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [30720/69249 (44%)]\tLoss: 1.884700, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [33280/69249 (48%)]\tLoss: 1.909504, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [35840/69249 (52%)]\tLoss: 1.837840, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [38400/69249 (55%)]\tLoss: 1.860248, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [40960/69249 (59%)]\tLoss: 1.909389, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [43520/69249 (63%)]\tLoss: 1.886830, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [46080/69249 (66%)]\tLoss: 1.865505, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [48640/69249 (70%)]\tLoss: 1.888159, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [51200/69249 (74%)]\tLoss: 1.888880, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [53760/69249 (77%)]\tLoss: 1.866117, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [56320/69249 (81%)]\tLoss: 1.894446, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [58880/69249 (85%)]\tLoss: 1.917741, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [61440/69249 (89%)]\tLoss: 1.892184, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [64000/69249 (92%)]\tLoss: 1.870431, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [66560/69249 (96%)]\tLoss: 1.882993, mean accuracy last epoch: 0.787\n",
      "Train Epoch 44 [34830/69249 (100%)]\tLoss: 1.875490, mean accuracy last epoch: 0.787\n",
      "Train Epoch 45 [0/69249 (0%)]\tLoss: 1.907162, mean accuracy last epoch: 0.787\n",
      "Train Epoch 45 [2560/69249 (4%)]\tLoss: 1.904606, mean accuracy last epoch: 0.787\n",
      "Train Epoch 45 [5120/69249 (7%)]\tLoss: 1.906140, mean accuracy last epoch: 0.787\n",
      "Train Epoch 45 [7680/69249 (11%)]\tLoss: 1.926273, mean accuracy last epoch: 0.787\n",
      "Train Epoch 45 [10240/69249 (15%)]\tLoss: 1.844948, mean accuracy last epoch: 0.787\n",
      "Train Epoch 45 [12800/69249 (18%)]\tLoss: 1.943163, mean accuracy last epoch: 0.787\n",
      "Train Epoch 45 [15360/69249 (22%)]\tLoss: 1.924760, mean accuracy last epoch: 0.787\n",
      "Train Epoch 45 [17920/69249 (26%)]\tLoss: 1.906555, mean accuracy last epoch: 0.787\n",
      "Train Epoch 45 [20480/69249 (30%)]\tLoss: 1.873121, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [23040/69249 (33%)]\tLoss: 1.839692, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [25600/69249 (37%)]\tLoss: 1.856068, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [28160/69249 (41%)]\tLoss: 1.847567, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [30720/69249 (44%)]\tLoss: 1.835495, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [33280/69249 (48%)]\tLoss: 1.819595, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [35840/69249 (52%)]\tLoss: 1.902528, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [38400/69249 (55%)]\tLoss: 1.887154, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [40960/69249 (59%)]\tLoss: 1.876563, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [43520/69249 (63%)]\tLoss: 1.841272, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [46080/69249 (66%)]\tLoss: 1.896930, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [48640/69249 (70%)]\tLoss: 1.897817, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [51200/69249 (74%)]\tLoss: 1.899532, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [53760/69249 (77%)]\tLoss: 1.881304, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [56320/69249 (81%)]\tLoss: 1.938971, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [58880/69249 (85%)]\tLoss: 1.876188, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [61440/69249 (89%)]\tLoss: 1.843311, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [64000/69249 (92%)]\tLoss: 1.880281, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [66560/69249 (96%)]\tLoss: 1.905381, mean accuracy last epoch: 0.788\n",
      "Train Epoch 45 [34830/69249 (100%)]\tLoss: 1.877884, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [0/69249 (0%)]\tLoss: 1.889488, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [2560/69249 (4%)]\tLoss: 1.895577, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [5120/69249 (7%)]\tLoss: 1.821541, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [7680/69249 (11%)]\tLoss: 1.865687, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [10240/69249 (15%)]\tLoss: 1.899493, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [12800/69249 (18%)]\tLoss: 1.921824, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [15360/69249 (22%)]\tLoss: 1.864686, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [17920/69249 (26%)]\tLoss: 1.923754, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [20480/69249 (30%)]\tLoss: 1.889420, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [23040/69249 (33%)]\tLoss: 1.850452, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [25600/69249 (37%)]\tLoss: 1.900242, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [28160/69249 (41%)]\tLoss: 1.885073, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [30720/69249 (44%)]\tLoss: 1.881562, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [33280/69249 (48%)]\tLoss: 1.848158, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [35840/69249 (52%)]\tLoss: 1.866308, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [38400/69249 (55%)]\tLoss: 1.872846, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [40960/69249 (59%)]\tLoss: 1.906200, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [43520/69249 (63%)]\tLoss: 1.904374, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [46080/69249 (66%)]\tLoss: 1.905125, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [48640/69249 (70%)]\tLoss: 1.880011, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [51200/69249 (74%)]\tLoss: 1.883350, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [53760/69249 (77%)]\tLoss: 1.883922, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [56320/69249 (81%)]\tLoss: 1.944345, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [58880/69249 (85%)]\tLoss: 1.887117, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [61440/69249 (89%)]\tLoss: 1.859350, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [64000/69249 (92%)]\tLoss: 1.912824, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [66560/69249 (96%)]\tLoss: 1.924823, mean accuracy last epoch: 0.788\n",
      "Train Epoch 46 [34830/69249 (100%)]\tLoss: 1.883121, mean accuracy last epoch: 0.788\n",
      "Train Epoch 47 [0/69249 (0%)]\tLoss: 1.904380, mean accuracy last epoch: 0.788\n",
      "Train Epoch 47 [2560/69249 (4%)]\tLoss: 1.863254, mean accuracy last epoch: 0.788\n",
      "Train Epoch 47 [5120/69249 (7%)]\tLoss: 1.867294, mean accuracy last epoch: 0.788\n",
      "Train Epoch 47 [7680/69249 (11%)]\tLoss: 1.865793, mean accuracy last epoch: 0.788\n",
      "Train Epoch 47 [10240/69249 (15%)]\tLoss: 1.881300, mean accuracy last epoch: 0.788\n",
      "Train Epoch 47 [12800/69249 (18%)]\tLoss: 1.882837, mean accuracy last epoch: 0.788\n",
      "Train Epoch 47 [15360/69249 (22%)]\tLoss: 1.901129, mean accuracy last epoch: 0.788\n",
      "Train Epoch 47 [17920/69249 (26%)]\tLoss: 1.930303, mean accuracy last epoch: 0.788\n",
      "Train Epoch 47 [20480/69249 (30%)]\tLoss: 1.888787, mean accuracy last epoch: 0.788\n",
      "Train Epoch 47 [23040/69249 (33%)]\tLoss: 1.837474, mean accuracy last epoch: 0.788\n",
      "Train Epoch 47 [25600/69249 (37%)]\tLoss: 1.924822, mean accuracy last epoch: 0.788\n",
      "Train Epoch 47 [28160/69249 (41%)]\tLoss: 1.896378, mean accuracy last epoch: 0.788\n",
      "Train Epoch 47 [30720/69249 (44%)]\tLoss: 1.882634, mean accuracy last epoch: 0.788\n",
      "Train Epoch 47 [33280/69249 (48%)]\tLoss: 1.893547, mean accuracy last epoch: 0.788\n",
      "Train Epoch 47 [35840/69249 (52%)]\tLoss: 1.855165, mean accuracy last epoch: 0.788\n",
      "Train Epoch 47 [38400/69249 (55%)]\tLoss: 1.869863, mean accuracy last epoch: 0.789\n",
      "Train Epoch 47 [40960/69249 (59%)]\tLoss: 1.895054, mean accuracy last epoch: 0.789\n",
      "Train Epoch 47 [43520/69249 (63%)]\tLoss: 1.869714, mean accuracy last epoch: 0.789\n",
      "Train Epoch 47 [46080/69249 (66%)]\tLoss: 1.868387, mean accuracy last epoch: 0.789\n",
      "Train Epoch 47 [48640/69249 (70%)]\tLoss: 1.882870, mean accuracy last epoch: 0.789\n",
      "Train Epoch 47 [51200/69249 (74%)]\tLoss: 1.899731, mean accuracy last epoch: 0.789\n",
      "Train Epoch 47 [53760/69249 (77%)]\tLoss: 1.899678, mean accuracy last epoch: 0.789\n",
      "Train Epoch 47 [56320/69249 (81%)]\tLoss: 1.876239, mean accuracy last epoch: 0.789\n",
      "Train Epoch 47 [58880/69249 (85%)]\tLoss: 1.894661, mean accuracy last epoch: 0.789\n",
      "Train Epoch 47 [61440/69249 (89%)]\tLoss: 1.828760, mean accuracy last epoch: 0.789\n",
      "Train Epoch 47 [64000/69249 (92%)]\tLoss: 1.856204, mean accuracy last epoch: 0.789\n",
      "Train Epoch 47 [66560/69249 (96%)]\tLoss: 1.862063, mean accuracy last epoch: 0.789\n",
      "Train Epoch 47 [34830/69249 (100%)]\tLoss: 1.875154, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [0/69249 (0%)]\tLoss: 1.861825, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [2560/69249 (4%)]\tLoss: 1.859784, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [5120/69249 (7%)]\tLoss: 1.904576, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [7680/69249 (11%)]\tLoss: 1.863188, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [10240/69249 (15%)]\tLoss: 1.896980, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [12800/69249 (18%)]\tLoss: 1.861821, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [15360/69249 (22%)]\tLoss: 1.875614, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [17920/69249 (26%)]\tLoss: 1.872040, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [20480/69249 (30%)]\tLoss: 1.847314, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [23040/69249 (33%)]\tLoss: 1.860974, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [25600/69249 (37%)]\tLoss: 1.883797, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [28160/69249 (41%)]\tLoss: 1.882442, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [30720/69249 (44%)]\tLoss: 1.846515, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [33280/69249 (48%)]\tLoss: 1.880602, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [35840/69249 (52%)]\tLoss: 1.883896, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [38400/69249 (55%)]\tLoss: 1.889534, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [40960/69249 (59%)]\tLoss: 1.911747, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [43520/69249 (63%)]\tLoss: 1.891988, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [46080/69249 (66%)]\tLoss: 1.841311, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [48640/69249 (70%)]\tLoss: 1.876930, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [51200/69249 (74%)]\tLoss: 1.899058, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [53760/69249 (77%)]\tLoss: 1.864538, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [56320/69249 (81%)]\tLoss: 1.881373, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [58880/69249 (85%)]\tLoss: 1.893641, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [61440/69249 (89%)]\tLoss: 1.872114, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [64000/69249 (92%)]\tLoss: 1.915463, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [66560/69249 (96%)]\tLoss: 1.900120, mean accuracy last epoch: 0.789\n",
      "Train Epoch 48 [34830/69249 (100%)]\tLoss: 1.946746, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [0/69249 (0%)]\tLoss: 1.887985, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [2560/69249 (4%)]\tLoss: 1.848682, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [5120/69249 (7%)]\tLoss: 1.861305, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [7680/69249 (11%)]\tLoss: 1.855523, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [10240/69249 (15%)]\tLoss: 1.871289, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [12800/69249 (18%)]\tLoss: 1.869370, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [15360/69249 (22%)]\tLoss: 1.852021, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [17920/69249 (26%)]\tLoss: 1.886027, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [20480/69249 (30%)]\tLoss: 1.907613, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [23040/69249 (33%)]\tLoss: 1.865443, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [25600/69249 (37%)]\tLoss: 1.844693, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [28160/69249 (41%)]\tLoss: 1.872124, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [30720/69249 (44%)]\tLoss: 1.850517, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [33280/69249 (48%)]\tLoss: 1.850020, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [35840/69249 (52%)]\tLoss: 1.901775, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [38400/69249 (55%)]\tLoss: 1.885394, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [40960/69249 (59%)]\tLoss: 1.862434, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [43520/69249 (63%)]\tLoss: 1.900330, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [46080/69249 (66%)]\tLoss: 1.917259, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [48640/69249 (70%)]\tLoss: 1.885852, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [51200/69249 (74%)]\tLoss: 1.855114, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [53760/69249 (77%)]\tLoss: 1.853723, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [56320/69249 (81%)]\tLoss: 1.869881, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [58880/69249 (85%)]\tLoss: 1.883350, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [61440/69249 (89%)]\tLoss: 1.901729, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [64000/69249 (92%)]\tLoss: 1.942926, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [66560/69249 (96%)]\tLoss: 1.880691, mean accuracy last epoch: 0.789\n",
      "Train Epoch 49 [34830/69249 (100%)]\tLoss: 1.944659, mean accuracy last epoch: 0.789\n",
      "Train Epoch 50 [0/69249 (0%)]\tLoss: 1.881082, mean accuracy last epoch: 0.789\n",
      "Train Epoch 50 [2560/69249 (4%)]\tLoss: 1.890195, mean accuracy last epoch: 0.789\n",
      "Train Epoch 50 [5120/69249 (7%)]\tLoss: 1.935934, mean accuracy last epoch: 0.789\n",
      "Train Epoch 50 [7680/69249 (11%)]\tLoss: 1.863959, mean accuracy last epoch: 0.789\n",
      "Train Epoch 50 [10240/69249 (15%)]\tLoss: 1.887701, mean accuracy last epoch: 0.789\n",
      "Train Epoch 50 [12800/69249 (18%)]\tLoss: 1.930778, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [15360/69249 (22%)]\tLoss: 1.868786, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [17920/69249 (26%)]\tLoss: 1.880803, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [20480/69249 (30%)]\tLoss: 1.865525, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [23040/69249 (33%)]\tLoss: 1.898167, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [25600/69249 (37%)]\tLoss: 1.861437, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [28160/69249 (41%)]\tLoss: 1.891914, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [30720/69249 (44%)]\tLoss: 1.871975, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [33280/69249 (48%)]\tLoss: 1.881060, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [35840/69249 (52%)]\tLoss: 1.908595, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [38400/69249 (55%)]\tLoss: 1.877111, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [40960/69249 (59%)]\tLoss: 1.870111, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [43520/69249 (63%)]\tLoss: 1.857232, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [46080/69249 (66%)]\tLoss: 1.838049, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [48640/69249 (70%)]\tLoss: 1.877826, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [51200/69249 (74%)]\tLoss: 1.853179, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [53760/69249 (77%)]\tLoss: 1.912899, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [56320/69249 (81%)]\tLoss: 1.881673, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [58880/69249 (85%)]\tLoss: 1.882151, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [61440/69249 (89%)]\tLoss: 1.908262, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [64000/69249 (92%)]\tLoss: 1.881057, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [66560/69249 (96%)]\tLoss: 1.873245, mean accuracy last epoch: 0.790\n",
      "Train Epoch 50 [34830/69249 (100%)]\tLoss: 1.879716, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [0/69249 (0%)]\tLoss: 1.889850, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [2560/69249 (4%)]\tLoss: 1.908629, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [5120/69249 (7%)]\tLoss: 1.849957, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [7680/69249 (11%)]\tLoss: 1.896115, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [10240/69249 (15%)]\tLoss: 1.905029, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [12800/69249 (18%)]\tLoss: 1.885265, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [15360/69249 (22%)]\tLoss: 1.865224, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [17920/69249 (26%)]\tLoss: 1.943592, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [20480/69249 (30%)]\tLoss: 1.916508, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [23040/69249 (33%)]\tLoss: 1.931863, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [25600/69249 (37%)]\tLoss: 1.868137, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [28160/69249 (41%)]\tLoss: 1.870097, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [30720/69249 (44%)]\tLoss: 1.857362, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [33280/69249 (48%)]\tLoss: 1.897981, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [35840/69249 (52%)]\tLoss: 1.908685, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [38400/69249 (55%)]\tLoss: 1.924284, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [40960/69249 (59%)]\tLoss: 1.900200, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [43520/69249 (63%)]\tLoss: 1.869681, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [46080/69249 (66%)]\tLoss: 1.860592, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [48640/69249 (70%)]\tLoss: 1.866704, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [51200/69249 (74%)]\tLoss: 1.857466, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [53760/69249 (77%)]\tLoss: 1.856486, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [56320/69249 (81%)]\tLoss: 1.892349, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [58880/69249 (85%)]\tLoss: 1.877743, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [61440/69249 (89%)]\tLoss: 1.911036, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [64000/69249 (92%)]\tLoss: 1.885131, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [66560/69249 (96%)]\tLoss: 1.898208, mean accuracy last epoch: 0.790\n",
      "Train Epoch 51 [34830/69249 (100%)]\tLoss: 1.874762, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [0/69249 (0%)]\tLoss: 1.864684, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [2560/69249 (4%)]\tLoss: 1.906552, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [5120/69249 (7%)]\tLoss: 1.884452, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [7680/69249 (11%)]\tLoss: 1.852870, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [10240/69249 (15%)]\tLoss: 1.865583, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [12800/69249 (18%)]\tLoss: 1.880589, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [15360/69249 (22%)]\tLoss: 1.863417, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [17920/69249 (26%)]\tLoss: 1.882992, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [20480/69249 (30%)]\tLoss: 1.855088, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [23040/69249 (33%)]\tLoss: 1.892988, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [25600/69249 (37%)]\tLoss: 1.860982, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [28160/69249 (41%)]\tLoss: 1.876148, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [30720/69249 (44%)]\tLoss: 1.892258, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [33280/69249 (48%)]\tLoss: 1.895318, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [35840/69249 (52%)]\tLoss: 1.920175, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [38400/69249 (55%)]\tLoss: 1.861215, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [40960/69249 (59%)]\tLoss: 1.886658, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [43520/69249 (63%)]\tLoss: 1.858145, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [46080/69249 (66%)]\tLoss: 1.903596, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [48640/69249 (70%)]\tLoss: 1.841646, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [51200/69249 (74%)]\tLoss: 1.877365, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [53760/69249 (77%)]\tLoss: 1.841944, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [56320/69249 (81%)]\tLoss: 1.889428, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [58880/69249 (85%)]\tLoss: 1.883424, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [61440/69249 (89%)]\tLoss: 1.876123, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [64000/69249 (92%)]\tLoss: 1.869136, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [66560/69249 (96%)]\tLoss: 1.875787, mean accuracy last epoch: 0.790\n",
      "Train Epoch 52 [34830/69249 (100%)]\tLoss: 1.954296, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [0/69249 (0%)]\tLoss: 1.881979, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [2560/69249 (4%)]\tLoss: 1.897222, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [5120/69249 (7%)]\tLoss: 1.874796, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [7680/69249 (11%)]\tLoss: 1.884893, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [10240/69249 (15%)]\tLoss: 1.816935, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [12800/69249 (18%)]\tLoss: 1.846693, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [15360/69249 (22%)]\tLoss: 1.877701, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [17920/69249 (26%)]\tLoss: 1.898043, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [20480/69249 (30%)]\tLoss: 1.898298, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [23040/69249 (33%)]\tLoss: 1.868210, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [25600/69249 (37%)]\tLoss: 1.835450, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [28160/69249 (41%)]\tLoss: 1.877282, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [30720/69249 (44%)]\tLoss: 1.909806, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [33280/69249 (48%)]\tLoss: 1.850332, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [35840/69249 (52%)]\tLoss: 1.856880, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [38400/69249 (55%)]\tLoss: 1.896317, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [40960/69249 (59%)]\tLoss: 1.905994, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [43520/69249 (63%)]\tLoss: 1.872158, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [46080/69249 (66%)]\tLoss: 1.877029, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [48640/69249 (70%)]\tLoss: 1.923396, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [51200/69249 (74%)]\tLoss: 1.856638, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [53760/69249 (77%)]\tLoss: 1.898438, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [56320/69249 (81%)]\tLoss: 1.920278, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [58880/69249 (85%)]\tLoss: 1.860274, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [61440/69249 (89%)]\tLoss: 1.883852, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [64000/69249 (92%)]\tLoss: 1.829423, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [66560/69249 (96%)]\tLoss: 1.872648, mean accuracy last epoch: 0.791\n",
      "Train Epoch 53 [34830/69249 (100%)]\tLoss: 1.861834, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [0/69249 (0%)]\tLoss: 1.919378, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [2560/69249 (4%)]\tLoss: 1.888773, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [5120/69249 (7%)]\tLoss: 1.937365, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [7680/69249 (11%)]\tLoss: 1.890640, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [10240/69249 (15%)]\tLoss: 1.891415, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [12800/69249 (18%)]\tLoss: 1.929933, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [15360/69249 (22%)]\tLoss: 1.876729, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [17920/69249 (26%)]\tLoss: 1.890010, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [20480/69249 (30%)]\tLoss: 1.848712, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [23040/69249 (33%)]\tLoss: 1.839002, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [25600/69249 (37%)]\tLoss: 1.832280, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [28160/69249 (41%)]\tLoss: 1.924041, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [30720/69249 (44%)]\tLoss: 1.870992, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [33280/69249 (48%)]\tLoss: 1.898701, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [35840/69249 (52%)]\tLoss: 1.824695, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [38400/69249 (55%)]\tLoss: 1.894259, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [40960/69249 (59%)]\tLoss: 1.872359, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [43520/69249 (63%)]\tLoss: 1.885683, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [46080/69249 (66%)]\tLoss: 1.871270, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [48640/69249 (70%)]\tLoss: 1.877829, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [51200/69249 (74%)]\tLoss: 1.887735, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [53760/69249 (77%)]\tLoss: 1.883618, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [56320/69249 (81%)]\tLoss: 1.875291, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [58880/69249 (85%)]\tLoss: 1.907311, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [61440/69249 (89%)]\tLoss: 1.862441, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [64000/69249 (92%)]\tLoss: 1.925877, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [66560/69249 (96%)]\tLoss: 1.902363, mean accuracy last epoch: 0.791\n",
      "Train Epoch 54 [34830/69249 (100%)]\tLoss: 1.889092, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [0/69249 (0%)]\tLoss: 1.919149, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [2560/69249 (4%)]\tLoss: 1.868613, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [5120/69249 (7%)]\tLoss: 1.896725, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [7680/69249 (11%)]\tLoss: 1.899495, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [10240/69249 (15%)]\tLoss: 1.892262, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [12800/69249 (18%)]\tLoss: 1.884431, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [15360/69249 (22%)]\tLoss: 1.860893, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [17920/69249 (26%)]\tLoss: 1.875219, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [20480/69249 (30%)]\tLoss: 1.867085, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [23040/69249 (33%)]\tLoss: 1.873738, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [25600/69249 (37%)]\tLoss: 1.868569, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [28160/69249 (41%)]\tLoss: 1.850710, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [30720/69249 (44%)]\tLoss: 1.898945, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [33280/69249 (48%)]\tLoss: 1.887674, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [35840/69249 (52%)]\tLoss: 1.872691, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [38400/69249 (55%)]\tLoss: 1.883625, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [40960/69249 (59%)]\tLoss: 1.897903, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [43520/69249 (63%)]\tLoss: 1.875289, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [46080/69249 (66%)]\tLoss: 1.888891, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [48640/69249 (70%)]\tLoss: 1.874601, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [51200/69249 (74%)]\tLoss: 1.880671, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [53760/69249 (77%)]\tLoss: 1.849110, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [56320/69249 (81%)]\tLoss: 1.856561, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [58880/69249 (85%)]\tLoss: 1.869212, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [61440/69249 (89%)]\tLoss: 1.875154, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [64000/69249 (92%)]\tLoss: 1.903984, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [66560/69249 (96%)]\tLoss: 1.902509, mean accuracy last epoch: 0.791\n",
      "Train Epoch 55 [34830/69249 (100%)]\tLoss: 1.941427, mean accuracy last epoch: 0.791\n",
      "Train Epoch 56 [0/69249 (0%)]\tLoss: 1.879460, mean accuracy last epoch: 0.791\n",
      "Train Epoch 56 [2560/69249 (4%)]\tLoss: 1.893874, mean accuracy last epoch: 0.791\n",
      "Train Epoch 56 [5120/69249 (7%)]\tLoss: 1.864913, mean accuracy last epoch: 0.791\n",
      "Train Epoch 56 [7680/69249 (11%)]\tLoss: 1.866035, mean accuracy last epoch: 0.791\n",
      "Train Epoch 56 [10240/69249 (15%)]\tLoss: 1.869497, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [12800/69249 (18%)]\tLoss: 1.881560, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [15360/69249 (22%)]\tLoss: 1.887062, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [17920/69249 (26%)]\tLoss: 1.874515, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [20480/69249 (30%)]\tLoss: 1.865830, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [23040/69249 (33%)]\tLoss: 1.852368, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [25600/69249 (37%)]\tLoss: 1.884436, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [28160/69249 (41%)]\tLoss: 1.916113, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [30720/69249 (44%)]\tLoss: 1.886865, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [33280/69249 (48%)]\tLoss: 1.867137, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [35840/69249 (52%)]\tLoss: 1.860660, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [38400/69249 (55%)]\tLoss: 1.859234, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [40960/69249 (59%)]\tLoss: 1.853246, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [43520/69249 (63%)]\tLoss: 1.871411, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [46080/69249 (66%)]\tLoss: 1.874620, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [48640/69249 (70%)]\tLoss: 1.860513, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [51200/69249 (74%)]\tLoss: 1.897691, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [53760/69249 (77%)]\tLoss: 1.845570, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [56320/69249 (81%)]\tLoss: 1.901360, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [58880/69249 (85%)]\tLoss: 1.891473, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [61440/69249 (89%)]\tLoss: 1.881497, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [64000/69249 (92%)]\tLoss: 1.894804, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [66560/69249 (96%)]\tLoss: 1.865790, mean accuracy last epoch: 0.792\n",
      "Train Epoch 56 [34830/69249 (100%)]\tLoss: 1.828864, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [0/69249 (0%)]\tLoss: 1.885667, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [2560/69249 (4%)]\tLoss: 1.891631, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [5120/69249 (7%)]\tLoss: 1.882272, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [7680/69249 (11%)]\tLoss: 1.871864, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [10240/69249 (15%)]\tLoss: 1.895437, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [12800/69249 (18%)]\tLoss: 1.848714, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [15360/69249 (22%)]\tLoss: 1.857615, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [17920/69249 (26%)]\tLoss: 1.882914, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [20480/69249 (30%)]\tLoss: 1.889963, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [23040/69249 (33%)]\tLoss: 1.877612, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [25600/69249 (37%)]\tLoss: 1.910996, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [28160/69249 (41%)]\tLoss: 1.859751, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [30720/69249 (44%)]\tLoss: 1.874774, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [33280/69249 (48%)]\tLoss: 1.837166, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [35840/69249 (52%)]\tLoss: 1.873494, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [38400/69249 (55%)]\tLoss: 1.846519, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [40960/69249 (59%)]\tLoss: 1.911613, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [43520/69249 (63%)]\tLoss: 1.862474, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [46080/69249 (66%)]\tLoss: 1.866529, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [48640/69249 (70%)]\tLoss: 1.890337, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [51200/69249 (74%)]\tLoss: 1.893952, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [53760/69249 (77%)]\tLoss: 1.866618, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [56320/69249 (81%)]\tLoss: 1.879157, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [58880/69249 (85%)]\tLoss: 1.927448, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [61440/69249 (89%)]\tLoss: 1.931455, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [64000/69249 (92%)]\tLoss: 1.924755, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [66560/69249 (96%)]\tLoss: 1.900980, mean accuracy last epoch: 0.792\n",
      "Train Epoch 57 [34830/69249 (100%)]\tLoss: 1.907080, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [0/69249 (0%)]\tLoss: 1.859257, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [2560/69249 (4%)]\tLoss: 1.892121, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [5120/69249 (7%)]\tLoss: 1.888095, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [7680/69249 (11%)]\tLoss: 1.893776, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [10240/69249 (15%)]\tLoss: 1.892785, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [12800/69249 (18%)]\tLoss: 1.899904, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [15360/69249 (22%)]\tLoss: 1.892179, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [17920/69249 (26%)]\tLoss: 1.890119, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [20480/69249 (30%)]\tLoss: 1.873579, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [23040/69249 (33%)]\tLoss: 1.895151, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [25600/69249 (37%)]\tLoss: 1.900211, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [28160/69249 (41%)]\tLoss: 1.854029, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [30720/69249 (44%)]\tLoss: 1.890916, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [33280/69249 (48%)]\tLoss: 1.897450, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [35840/69249 (52%)]\tLoss: 1.850110, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [38400/69249 (55%)]\tLoss: 1.857632, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [40960/69249 (59%)]\tLoss: 1.860448, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [43520/69249 (63%)]\tLoss: 1.877783, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [46080/69249 (66%)]\tLoss: 1.872356, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [48640/69249 (70%)]\tLoss: 1.872563, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [51200/69249 (74%)]\tLoss: 1.930015, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [53760/69249 (77%)]\tLoss: 1.888768, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [56320/69249 (81%)]\tLoss: 1.841169, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [58880/69249 (85%)]\tLoss: 1.900639, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [61440/69249 (89%)]\tLoss: 1.876904, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [64000/69249 (92%)]\tLoss: 1.900887, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [66560/69249 (96%)]\tLoss: 1.872391, mean accuracy last epoch: 0.792\n",
      "Train Epoch 58 [34830/69249 (100%)]\tLoss: 1.827312, mean accuracy last epoch: 0.792\n",
      "Train Epoch 59 [0/69249 (0%)]\tLoss: 1.885966, mean accuracy last epoch: 0.792\n",
      "Train Epoch 59 [2560/69249 (4%)]\tLoss: 1.872549, mean accuracy last epoch: 0.792\n",
      "Train Epoch 59 [5120/69249 (7%)]\tLoss: 1.862149, mean accuracy last epoch: 0.792\n",
      "Train Epoch 59 [7680/69249 (11%)]\tLoss: 1.877721, mean accuracy last epoch: 0.792\n",
      "Train Epoch 59 [10240/69249 (15%)]\tLoss: 1.889731, mean accuracy last epoch: 0.792\n",
      "Train Epoch 59 [12800/69249 (18%)]\tLoss: 1.870954, mean accuracy last epoch: 0.792\n",
      "Train Epoch 59 [15360/69249 (22%)]\tLoss: 1.859176, mean accuracy last epoch: 0.792\n",
      "Train Epoch 59 [17920/69249 (26%)]\tLoss: 1.903962, mean accuracy last epoch: 0.792\n",
      "Train Epoch 59 [20480/69249 (30%)]\tLoss: 1.899264, mean accuracy last epoch: 0.792\n",
      "Train Epoch 59 [23040/69249 (33%)]\tLoss: 1.859484, mean accuracy last epoch: 0.792\n",
      "Train Epoch 59 [25600/69249 (37%)]\tLoss: 1.857730, mean accuracy last epoch: 0.792\n",
      "Train Epoch 59 [28160/69249 (41%)]\tLoss: 1.901219, mean accuracy last epoch: 0.792\n",
      "Train Epoch 59 [30720/69249 (44%)]\tLoss: 1.866362, mean accuracy last epoch: 0.792\n",
      "Train Epoch 59 [33280/69249 (48%)]\tLoss: 1.902048, mean accuracy last epoch: 0.793\n",
      "Train Epoch 59 [35840/69249 (52%)]\tLoss: 1.849352, mean accuracy last epoch: 0.793\n",
      "Train Epoch 59 [38400/69249 (55%)]\tLoss: 1.902621, mean accuracy last epoch: 0.793\n",
      "Train Epoch 59 [40960/69249 (59%)]\tLoss: 1.867173, mean accuracy last epoch: 0.793\n",
      "Train Epoch 59 [43520/69249 (63%)]\tLoss: 1.872906, mean accuracy last epoch: 0.793\n",
      "Train Epoch 59 [46080/69249 (66%)]\tLoss: 1.883569, mean accuracy last epoch: 0.793\n",
      "Train Epoch 59 [48640/69249 (70%)]\tLoss: 1.891953, mean accuracy last epoch: 0.793\n",
      "Train Epoch 59 [51200/69249 (74%)]\tLoss: 1.883427, mean accuracy last epoch: 0.793\n",
      "Train Epoch 59 [53760/69249 (77%)]\tLoss: 1.859132, mean accuracy last epoch: 0.793\n",
      "Train Epoch 59 [56320/69249 (81%)]\tLoss: 1.877395, mean accuracy last epoch: 0.793\n",
      "Train Epoch 59 [58880/69249 (85%)]\tLoss: 1.859137, mean accuracy last epoch: 0.793\n",
      "Train Epoch 59 [61440/69249 (89%)]\tLoss: 1.895389, mean accuracy last epoch: 0.793\n",
      "Train Epoch 59 [64000/69249 (92%)]\tLoss: 1.887496, mean accuracy last epoch: 0.793\n",
      "Train Epoch 59 [66560/69249 (96%)]\tLoss: 1.874877, mean accuracy last epoch: 0.793\n",
      "Train Epoch 59 [34830/69249 (100%)]\tLoss: 1.918836, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [0/69249 (0%)]\tLoss: 1.874387, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [2560/69249 (4%)]\tLoss: 1.895411, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [5120/69249 (7%)]\tLoss: 1.876354, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [7680/69249 (11%)]\tLoss: 1.891023, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [10240/69249 (15%)]\tLoss: 1.888397, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [12800/69249 (18%)]\tLoss: 1.862888, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [15360/69249 (22%)]\tLoss: 1.869351, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [17920/69249 (26%)]\tLoss: 1.857882, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [20480/69249 (30%)]\tLoss: 1.921952, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [23040/69249 (33%)]\tLoss: 1.903592, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [25600/69249 (37%)]\tLoss: 1.872622, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [28160/69249 (41%)]\tLoss: 1.903412, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [30720/69249 (44%)]\tLoss: 1.859171, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [33280/69249 (48%)]\tLoss: 1.874369, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [35840/69249 (52%)]\tLoss: 1.915799, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [38400/69249 (55%)]\tLoss: 1.852463, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [40960/69249 (59%)]\tLoss: 1.859447, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [43520/69249 (63%)]\tLoss: 1.907131, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [46080/69249 (66%)]\tLoss: 1.861655, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [48640/69249 (70%)]\tLoss: 1.951352, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [51200/69249 (74%)]\tLoss: 1.870966, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [53760/69249 (77%)]\tLoss: 1.858957, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [56320/69249 (81%)]\tLoss: 1.880401, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [58880/69249 (85%)]\tLoss: 1.907875, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [61440/69249 (89%)]\tLoss: 1.907912, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [64000/69249 (92%)]\tLoss: 1.884330, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [66560/69249 (96%)]\tLoss: 1.861060, mean accuracy last epoch: 0.793\n",
      "Train Epoch 60 [34830/69249 (100%)]\tLoss: 1.883175, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [0/69249 (0%)]\tLoss: 1.825467, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [2560/69249 (4%)]\tLoss: 1.884613, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [5120/69249 (7%)]\tLoss: 1.892830, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [7680/69249 (11%)]\tLoss: 1.895445, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [10240/69249 (15%)]\tLoss: 1.895345, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [12800/69249 (18%)]\tLoss: 1.881868, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [15360/69249 (22%)]\tLoss: 1.860632, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [17920/69249 (26%)]\tLoss: 1.907833, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [20480/69249 (30%)]\tLoss: 1.894869, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [23040/69249 (33%)]\tLoss: 1.911937, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [25600/69249 (37%)]\tLoss: 1.888872, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [28160/69249 (41%)]\tLoss: 1.881154, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [30720/69249 (44%)]\tLoss: 1.903797, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [33280/69249 (48%)]\tLoss: 1.871153, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [35840/69249 (52%)]\tLoss: 1.892144, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [38400/69249 (55%)]\tLoss: 1.892171, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [40960/69249 (59%)]\tLoss: 1.836561, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [43520/69249 (63%)]\tLoss: 1.859607, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [46080/69249 (66%)]\tLoss: 1.871625, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [48640/69249 (70%)]\tLoss: 1.858178, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [51200/69249 (74%)]\tLoss: 1.881017, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [53760/69249 (77%)]\tLoss: 1.902907, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [56320/69249 (81%)]\tLoss: 1.864922, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [58880/69249 (85%)]\tLoss: 1.900152, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [61440/69249 (89%)]\tLoss: 1.889027, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [64000/69249 (92%)]\tLoss: 1.874147, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [66560/69249 (96%)]\tLoss: 1.939351, mean accuracy last epoch: 0.793\n",
      "Train Epoch 61 [34830/69249 (100%)]\tLoss: 1.897977, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [0/69249 (0%)]\tLoss: 1.868428, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [2560/69249 (4%)]\tLoss: 1.857713, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [5120/69249 (7%)]\tLoss: 1.879735, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [7680/69249 (11%)]\tLoss: 1.845062, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [10240/69249 (15%)]\tLoss: 1.874669, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [12800/69249 (18%)]\tLoss: 1.837623, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [15360/69249 (22%)]\tLoss: 1.865031, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [17920/69249 (26%)]\tLoss: 1.875962, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [20480/69249 (30%)]\tLoss: 1.891213, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [23040/69249 (33%)]\tLoss: 1.903686, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [25600/69249 (37%)]\tLoss: 1.897173, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [28160/69249 (41%)]\tLoss: 1.866032, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [30720/69249 (44%)]\tLoss: 1.838547, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [33280/69249 (48%)]\tLoss: 1.857648, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [35840/69249 (52%)]\tLoss: 1.871508, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [38400/69249 (55%)]\tLoss: 1.893281, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [40960/69249 (59%)]\tLoss: 1.868533, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [43520/69249 (63%)]\tLoss: 1.899784, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [46080/69249 (66%)]\tLoss: 1.873744, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [48640/69249 (70%)]\tLoss: 1.877180, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [51200/69249 (74%)]\tLoss: 1.880840, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [53760/69249 (77%)]\tLoss: 1.845649, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [56320/69249 (81%)]\tLoss: 1.884825, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [58880/69249 (85%)]\tLoss: 1.866411, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [61440/69249 (89%)]\tLoss: 1.882476, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [64000/69249 (92%)]\tLoss: 1.871137, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [66560/69249 (96%)]\tLoss: 1.856957, mean accuracy last epoch: 0.793\n",
      "Train Epoch 62 [34830/69249 (100%)]\tLoss: 1.905476, mean accuracy last epoch: 0.793\n",
      "Train Epoch 63 [0/69249 (0%)]\tLoss: 1.864444, mean accuracy last epoch: 0.793\n",
      "Train Epoch 63 [2560/69249 (4%)]\tLoss: 1.903272, mean accuracy last epoch: 0.793\n",
      "Train Epoch 63 [5120/69249 (7%)]\tLoss: 1.872957, mean accuracy last epoch: 0.793\n",
      "Train Epoch 63 [7680/69249 (11%)]\tLoss: 1.846516, mean accuracy last epoch: 0.793\n",
      "Train Epoch 63 [10240/69249 (15%)]\tLoss: 1.905084, mean accuracy last epoch: 0.793\n",
      "Train Epoch 63 [12800/69249 (18%)]\tLoss: 1.851042, mean accuracy last epoch: 0.793\n",
      "Train Epoch 63 [15360/69249 (22%)]\tLoss: 1.892316, mean accuracy last epoch: 0.793\n",
      "Train Epoch 63 [17920/69249 (26%)]\tLoss: 1.862717, mean accuracy last epoch: 0.793\n",
      "Train Epoch 63 [20480/69249 (30%)]\tLoss: 1.842048, mean accuracy last epoch: 0.793\n",
      "Train Epoch 63 [23040/69249 (33%)]\tLoss: 1.872273, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [25600/69249 (37%)]\tLoss: 1.899011, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [28160/69249 (41%)]\tLoss: 1.919273, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [30720/69249 (44%)]\tLoss: 1.913007, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [33280/69249 (48%)]\tLoss: 1.881480, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [35840/69249 (52%)]\tLoss: 1.896534, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [38400/69249 (55%)]\tLoss: 1.872092, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [40960/69249 (59%)]\tLoss: 1.877272, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [43520/69249 (63%)]\tLoss: 1.916931, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [46080/69249 (66%)]\tLoss: 1.853263, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [48640/69249 (70%)]\tLoss: 1.865753, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [51200/69249 (74%)]\tLoss: 1.957879, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [53760/69249 (77%)]\tLoss: 1.888355, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [56320/69249 (81%)]\tLoss: 1.872578, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [58880/69249 (85%)]\tLoss: 1.869639, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [61440/69249 (89%)]\tLoss: 1.894603, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [64000/69249 (92%)]\tLoss: 1.887970, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [66560/69249 (96%)]\tLoss: 1.870561, mean accuracy last epoch: 0.794\n",
      "Train Epoch 63 [34830/69249 (100%)]\tLoss: 1.828600, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [0/69249 (0%)]\tLoss: 1.872749, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [2560/69249 (4%)]\tLoss: 1.853270, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [5120/69249 (7%)]\tLoss: 1.887577, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [7680/69249 (11%)]\tLoss: 1.893531, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [10240/69249 (15%)]\tLoss: 1.905483, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [12800/69249 (18%)]\tLoss: 1.897748, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [15360/69249 (22%)]\tLoss: 1.882774, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [17920/69249 (26%)]\tLoss: 1.874726, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [20480/69249 (30%)]\tLoss: 1.860707, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [23040/69249 (33%)]\tLoss: 1.833193, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [25600/69249 (37%)]\tLoss: 1.878479, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [28160/69249 (41%)]\tLoss: 1.880484, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [30720/69249 (44%)]\tLoss: 1.910223, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [33280/69249 (48%)]\tLoss: 1.904464, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [35840/69249 (52%)]\tLoss: 1.861469, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [38400/69249 (55%)]\tLoss: 1.888502, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [40960/69249 (59%)]\tLoss: 1.876792, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [43520/69249 (63%)]\tLoss: 1.861765, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [46080/69249 (66%)]\tLoss: 1.868289, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [48640/69249 (70%)]\tLoss: 1.881534, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [51200/69249 (74%)]\tLoss: 1.871109, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [53760/69249 (77%)]\tLoss: 1.868926, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [56320/69249 (81%)]\tLoss: 1.900003, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [58880/69249 (85%)]\tLoss: 1.857289, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [61440/69249 (89%)]\tLoss: 1.876630, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [64000/69249 (92%)]\tLoss: 1.848390, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [66560/69249 (96%)]\tLoss: 1.870587, mean accuracy last epoch: 0.794\n",
      "Train Epoch 64 [34830/69249 (100%)]\tLoss: 1.928827, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [0/69249 (0%)]\tLoss: 1.865817, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [2560/69249 (4%)]\tLoss: 1.869540, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [5120/69249 (7%)]\tLoss: 1.860390, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [7680/69249 (11%)]\tLoss: 1.909421, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [10240/69249 (15%)]\tLoss: 1.869510, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [12800/69249 (18%)]\tLoss: 1.880536, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [15360/69249 (22%)]\tLoss: 1.883031, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [17920/69249 (26%)]\tLoss: 1.895857, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [20480/69249 (30%)]\tLoss: 1.874697, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [23040/69249 (33%)]\tLoss: 1.876960, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [25600/69249 (37%)]\tLoss: 1.901243, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [28160/69249 (41%)]\tLoss: 1.865656, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [30720/69249 (44%)]\tLoss: 1.896667, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [33280/69249 (48%)]\tLoss: 1.861015, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [35840/69249 (52%)]\tLoss: 1.859989, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [38400/69249 (55%)]\tLoss: 1.901552, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [40960/69249 (59%)]\tLoss: 1.865595, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [43520/69249 (63%)]\tLoss: 1.848799, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [46080/69249 (66%)]\tLoss: 1.876704, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [48640/69249 (70%)]\tLoss: 1.871863, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [51200/69249 (74%)]\tLoss: 1.847334, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [53760/69249 (77%)]\tLoss: 1.841903, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [56320/69249 (81%)]\tLoss: 1.897133, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [58880/69249 (85%)]\tLoss: 1.905556, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [61440/69249 (89%)]\tLoss: 1.888248, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [64000/69249 (92%)]\tLoss: 1.841345, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [66560/69249 (96%)]\tLoss: 1.923371, mean accuracy last epoch: 0.794\n",
      "Train Epoch 65 [34830/69249 (100%)]\tLoss: 1.931855, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [0/69249 (0%)]\tLoss: 1.881359, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [2560/69249 (4%)]\tLoss: 1.885403, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [5120/69249 (7%)]\tLoss: 1.866443, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [7680/69249 (11%)]\tLoss: 1.848052, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [10240/69249 (15%)]\tLoss: 1.915589, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [12800/69249 (18%)]\tLoss: 1.837473, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [15360/69249 (22%)]\tLoss: 1.841289, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [17920/69249 (26%)]\tLoss: 1.850319, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [20480/69249 (30%)]\tLoss: 1.857918, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [23040/69249 (33%)]\tLoss: 1.883917, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [25600/69249 (37%)]\tLoss: 1.872905, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [28160/69249 (41%)]\tLoss: 1.883776, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [30720/69249 (44%)]\tLoss: 1.880740, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [33280/69249 (48%)]\tLoss: 1.887246, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [35840/69249 (52%)]\tLoss: 1.889875, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [38400/69249 (55%)]\tLoss: 1.896780, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [40960/69249 (59%)]\tLoss: 1.923397, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [43520/69249 (63%)]\tLoss: 1.845051, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [46080/69249 (66%)]\tLoss: 1.862222, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [48640/69249 (70%)]\tLoss: 1.847234, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [51200/69249 (74%)]\tLoss: 1.888497, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [53760/69249 (77%)]\tLoss: 1.826486, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [56320/69249 (81%)]\tLoss: 1.887008, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [58880/69249 (85%)]\tLoss: 1.870996, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [61440/69249 (89%)]\tLoss: 1.893288, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [64000/69249 (92%)]\tLoss: 1.935144, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [66560/69249 (96%)]\tLoss: 1.890932, mean accuracy last epoch: 0.794\n",
      "Train Epoch 66 [34830/69249 (100%)]\tLoss: 1.875111, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [0/69249 (0%)]\tLoss: 1.888762, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [2560/69249 (4%)]\tLoss: 1.908696, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [5120/69249 (7%)]\tLoss: 1.845170, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [7680/69249 (11%)]\tLoss: 1.859635, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [10240/69249 (15%)]\tLoss: 1.860255, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [12800/69249 (18%)]\tLoss: 1.871496, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [15360/69249 (22%)]\tLoss: 1.914201, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [17920/69249 (26%)]\tLoss: 1.890668, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [20480/69249 (30%)]\tLoss: 1.886303, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [23040/69249 (33%)]\tLoss: 1.850788, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [25600/69249 (37%)]\tLoss: 1.880885, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [28160/69249 (41%)]\tLoss: 1.849716, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [30720/69249 (44%)]\tLoss: 1.935276, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [33280/69249 (48%)]\tLoss: 1.814427, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [35840/69249 (52%)]\tLoss: 1.877209, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [38400/69249 (55%)]\tLoss: 1.894022, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [40960/69249 (59%)]\tLoss: 1.880926, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [43520/69249 (63%)]\tLoss: 1.866595, mean accuracy last epoch: 0.794\n",
      "Train Epoch 67 [46080/69249 (66%)]\tLoss: 1.900125, mean accuracy last epoch: 0.795\n",
      "Train Epoch 67 [48640/69249 (70%)]\tLoss: 1.887147, mean accuracy last epoch: 0.795\n",
      "Train Epoch 67 [51200/69249 (74%)]\tLoss: 1.880369, mean accuracy last epoch: 0.795\n",
      "Train Epoch 67 [53760/69249 (77%)]\tLoss: 1.900125, mean accuracy last epoch: 0.795\n",
      "Train Epoch 67 [56320/69249 (81%)]\tLoss: 1.919040, mean accuracy last epoch: 0.795\n",
      "Train Epoch 67 [58880/69249 (85%)]\tLoss: 1.870098, mean accuracy last epoch: 0.795\n",
      "Train Epoch 67 [61440/69249 (89%)]\tLoss: 1.861766, mean accuracy last epoch: 0.795\n",
      "Train Epoch 67 [64000/69249 (92%)]\tLoss: 1.915933, mean accuracy last epoch: 0.795\n",
      "Train Epoch 67 [66560/69249 (96%)]\tLoss: 1.906285, mean accuracy last epoch: 0.795\n",
      "Train Epoch 67 [34830/69249 (100%)]\tLoss: 1.883278, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [0/69249 (0%)]\tLoss: 1.884630, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [2560/69249 (4%)]\tLoss: 1.894793, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [5120/69249 (7%)]\tLoss: 1.886403, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [7680/69249 (11%)]\tLoss: 1.878989, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [10240/69249 (15%)]\tLoss: 1.890350, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [12800/69249 (18%)]\tLoss: 1.875494, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [15360/69249 (22%)]\tLoss: 1.880108, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [17920/69249 (26%)]\tLoss: 1.886985, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [20480/69249 (30%)]\tLoss: 1.855296, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [23040/69249 (33%)]\tLoss: 1.881970, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [25600/69249 (37%)]\tLoss: 1.901790, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [28160/69249 (41%)]\tLoss: 1.844085, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [30720/69249 (44%)]\tLoss: 1.866829, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [33280/69249 (48%)]\tLoss: 1.887707, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [35840/69249 (52%)]\tLoss: 1.897154, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [38400/69249 (55%)]\tLoss: 1.855358, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [40960/69249 (59%)]\tLoss: 1.839285, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [43520/69249 (63%)]\tLoss: 1.888891, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [46080/69249 (66%)]\tLoss: 1.872622, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [48640/69249 (70%)]\tLoss: 1.865067, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [51200/69249 (74%)]\tLoss: 1.861821, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [53760/69249 (77%)]\tLoss: 1.882601, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [56320/69249 (81%)]\tLoss: 1.910281, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [58880/69249 (85%)]\tLoss: 1.879285, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [61440/69249 (89%)]\tLoss: 1.880586, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [64000/69249 (92%)]\tLoss: 1.855067, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [66560/69249 (96%)]\tLoss: 1.869508, mean accuracy last epoch: 0.795\n",
      "Train Epoch 68 [34830/69249 (100%)]\tLoss: 1.882804, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [0/69249 (0%)]\tLoss: 1.853046, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [2560/69249 (4%)]\tLoss: 1.878135, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [5120/69249 (7%)]\tLoss: 1.887719, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [7680/69249 (11%)]\tLoss: 1.844474, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [10240/69249 (15%)]\tLoss: 1.879780, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [12800/69249 (18%)]\tLoss: 1.899645, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [15360/69249 (22%)]\tLoss: 1.900091, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [17920/69249 (26%)]\tLoss: 1.871089, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [20480/69249 (30%)]\tLoss: 1.865996, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [23040/69249 (33%)]\tLoss: 1.894449, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [25600/69249 (37%)]\tLoss: 1.901077, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [28160/69249 (41%)]\tLoss: 1.862776, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [30720/69249 (44%)]\tLoss: 1.865922, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [33280/69249 (48%)]\tLoss: 1.884134, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [35840/69249 (52%)]\tLoss: 1.876436, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [38400/69249 (55%)]\tLoss: 1.877280, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [40960/69249 (59%)]\tLoss: 1.870722, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [43520/69249 (63%)]\tLoss: 1.884955, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [46080/69249 (66%)]\tLoss: 1.915133, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [48640/69249 (70%)]\tLoss: 1.841837, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [51200/69249 (74%)]\tLoss: 1.864824, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [53760/69249 (77%)]\tLoss: 1.873141, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [56320/69249 (81%)]\tLoss: 1.896235, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [58880/69249 (85%)]\tLoss: 1.901432, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [61440/69249 (89%)]\tLoss: 1.857717, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [64000/69249 (92%)]\tLoss: 1.950371, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [66560/69249 (96%)]\tLoss: 1.888498, mean accuracy last epoch: 0.795\n",
      "Train Epoch 69 [34830/69249 (100%)]\tLoss: 1.897354, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [0/69249 (0%)]\tLoss: 1.902161, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [2560/69249 (4%)]\tLoss: 1.911092, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [5120/69249 (7%)]\tLoss: 1.875589, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [7680/69249 (11%)]\tLoss: 1.831176, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [10240/69249 (15%)]\tLoss: 1.864010, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [12800/69249 (18%)]\tLoss: 1.850716, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [15360/69249 (22%)]\tLoss: 1.896476, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [17920/69249 (26%)]\tLoss: 1.923685, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [20480/69249 (30%)]\tLoss: 1.868384, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [23040/69249 (33%)]\tLoss: 1.886473, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [25600/69249 (37%)]\tLoss: 1.876046, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [28160/69249 (41%)]\tLoss: 1.884839, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [30720/69249 (44%)]\tLoss: 1.918166, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [33280/69249 (48%)]\tLoss: 1.876689, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [35840/69249 (52%)]\tLoss: 1.847504, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [38400/69249 (55%)]\tLoss: 1.880870, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [40960/69249 (59%)]\tLoss: 1.893162, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [43520/69249 (63%)]\tLoss: 1.866649, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [46080/69249 (66%)]\tLoss: 1.870923, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [48640/69249 (70%)]\tLoss: 1.889528, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [51200/69249 (74%)]\tLoss: 1.882413, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [53760/69249 (77%)]\tLoss: 1.885705, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [56320/69249 (81%)]\tLoss: 1.856857, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [58880/69249 (85%)]\tLoss: 1.868743, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [61440/69249 (89%)]\tLoss: 1.872374, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [64000/69249 (92%)]\tLoss: 1.883171, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [66560/69249 (96%)]\tLoss: 1.881497, mean accuracy last epoch: 0.795\n",
      "Train Epoch 70 [34830/69249 (100%)]\tLoss: 1.905517, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [0/69249 (0%)]\tLoss: 1.925968, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [2560/69249 (4%)]\tLoss: 1.911404, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [5120/69249 (7%)]\tLoss: 1.941761, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [7680/69249 (11%)]\tLoss: 1.876565, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [10240/69249 (15%)]\tLoss: 1.851021, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [12800/69249 (18%)]\tLoss: 1.899452, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [15360/69249 (22%)]\tLoss: 1.858309, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [17920/69249 (26%)]\tLoss: 1.872534, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [20480/69249 (30%)]\tLoss: 1.900386, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [23040/69249 (33%)]\tLoss: 1.869499, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [25600/69249 (37%)]\tLoss: 1.928038, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [28160/69249 (41%)]\tLoss: 1.883744, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [30720/69249 (44%)]\tLoss: 1.869400, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [33280/69249 (48%)]\tLoss: 1.833666, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [35840/69249 (52%)]\tLoss: 1.896274, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [38400/69249 (55%)]\tLoss: 1.878631, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [40960/69249 (59%)]\tLoss: 1.892344, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [43520/69249 (63%)]\tLoss: 1.868029, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [46080/69249 (66%)]\tLoss: 1.814088, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [48640/69249 (70%)]\tLoss: 1.893912, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [51200/69249 (74%)]\tLoss: 1.893454, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [53760/69249 (77%)]\tLoss: 1.865923, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [56320/69249 (81%)]\tLoss: 1.882711, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [58880/69249 (85%)]\tLoss: 1.907637, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [61440/69249 (89%)]\tLoss: 1.891553, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [64000/69249 (92%)]\tLoss: 1.890781, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [66560/69249 (96%)]\tLoss: 1.871092, mean accuracy last epoch: 0.795\n",
      "Train Epoch 71 [34830/69249 (100%)]\tLoss: 1.851931, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [0/69249 (0%)]\tLoss: 1.893185, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [2560/69249 (4%)]\tLoss: 1.895972, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [5120/69249 (7%)]\tLoss: 1.882659, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [7680/69249 (11%)]\tLoss: 1.903657, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [10240/69249 (15%)]\tLoss: 1.868960, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [12800/69249 (18%)]\tLoss: 1.891629, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [15360/69249 (22%)]\tLoss: 1.859691, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [17920/69249 (26%)]\tLoss: 1.864531, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [20480/69249 (30%)]\tLoss: 1.887944, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [23040/69249 (33%)]\tLoss: 1.912319, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [25600/69249 (37%)]\tLoss: 1.848742, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [28160/69249 (41%)]\tLoss: 1.867595, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [30720/69249 (44%)]\tLoss: 1.855596, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [33280/69249 (48%)]\tLoss: 1.855973, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [35840/69249 (52%)]\tLoss: 1.888792, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [38400/69249 (55%)]\tLoss: 1.905650, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [40960/69249 (59%)]\tLoss: 1.898276, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [43520/69249 (63%)]\tLoss: 1.903397, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [46080/69249 (66%)]\tLoss: 1.851109, mean accuracy last epoch: 0.795\n",
      "Train Epoch 72 [48640/69249 (70%)]\tLoss: 1.909195, mean accuracy last epoch: 0.796\n",
      "Train Epoch 72 [51200/69249 (74%)]\tLoss: 1.887870, mean accuracy last epoch: 0.796\n",
      "Train Epoch 72 [53760/69249 (77%)]\tLoss: 1.880743, mean accuracy last epoch: 0.796\n",
      "Train Epoch 72 [56320/69249 (81%)]\tLoss: 1.834429, mean accuracy last epoch: 0.796\n",
      "Train Epoch 72 [58880/69249 (85%)]\tLoss: 1.872526, mean accuracy last epoch: 0.796\n",
      "Train Epoch 72 [61440/69249 (89%)]\tLoss: 1.911548, mean accuracy last epoch: 0.796\n",
      "Train Epoch 72 [64000/69249 (92%)]\tLoss: 1.891963, mean accuracy last epoch: 0.796\n",
      "Train Epoch 72 [66560/69249 (96%)]\tLoss: 1.826301, mean accuracy last epoch: 0.796\n",
      "Train Epoch 72 [34830/69249 (100%)]\tLoss: 1.958245, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [0/69249 (0%)]\tLoss: 1.861626, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [2560/69249 (4%)]\tLoss: 1.869380, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [5120/69249 (7%)]\tLoss: 1.911377, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [7680/69249 (11%)]\tLoss: 1.879736, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [10240/69249 (15%)]\tLoss: 1.818163, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [12800/69249 (18%)]\tLoss: 1.886305, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [15360/69249 (22%)]\tLoss: 1.893458, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [17920/69249 (26%)]\tLoss: 1.941778, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [20480/69249 (30%)]\tLoss: 1.892840, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [23040/69249 (33%)]\tLoss: 1.872980, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [25600/69249 (37%)]\tLoss: 1.853055, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [28160/69249 (41%)]\tLoss: 1.897242, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [30720/69249 (44%)]\tLoss: 1.895016, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [33280/69249 (48%)]\tLoss: 1.873486, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [35840/69249 (52%)]\tLoss: 1.851959, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [38400/69249 (55%)]\tLoss: 1.884404, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [40960/69249 (59%)]\tLoss: 1.882262, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [43520/69249 (63%)]\tLoss: 1.845290, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [46080/69249 (66%)]\tLoss: 1.877852, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [48640/69249 (70%)]\tLoss: 1.888737, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [51200/69249 (74%)]\tLoss: 1.877052, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [53760/69249 (77%)]\tLoss: 1.895894, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [56320/69249 (81%)]\tLoss: 1.888088, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [58880/69249 (85%)]\tLoss: 1.888452, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [61440/69249 (89%)]\tLoss: 1.906872, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [64000/69249 (92%)]\tLoss: 1.877993, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [66560/69249 (96%)]\tLoss: 1.864820, mean accuracy last epoch: 0.796\n",
      "Train Epoch 73 [34830/69249 (100%)]\tLoss: 1.856702, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [0/69249 (0%)]\tLoss: 1.907828, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [2560/69249 (4%)]\tLoss: 1.874337, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [5120/69249 (7%)]\tLoss: 1.841160, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [7680/69249 (11%)]\tLoss: 1.874484, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [10240/69249 (15%)]\tLoss: 1.890041, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [12800/69249 (18%)]\tLoss: 1.861449, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [15360/69249 (22%)]\tLoss: 1.889829, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [17920/69249 (26%)]\tLoss: 1.872575, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [20480/69249 (30%)]\tLoss: 1.885419, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [23040/69249 (33%)]\tLoss: 1.869022, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [25600/69249 (37%)]\tLoss: 1.889993, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [28160/69249 (41%)]\tLoss: 1.876139, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [30720/69249 (44%)]\tLoss: 1.897498, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [33280/69249 (48%)]\tLoss: 1.859832, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [35840/69249 (52%)]\tLoss: 1.888654, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [38400/69249 (55%)]\tLoss: 1.878092, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [40960/69249 (59%)]\tLoss: 1.925607, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [43520/69249 (63%)]\tLoss: 1.850593, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [46080/69249 (66%)]\tLoss: 1.865485, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [48640/69249 (70%)]\tLoss: 1.888335, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [51200/69249 (74%)]\tLoss: 1.879890, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [53760/69249 (77%)]\tLoss: 1.837843, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [56320/69249 (81%)]\tLoss: 1.860694, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [58880/69249 (85%)]\tLoss: 1.860713, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [61440/69249 (89%)]\tLoss: 1.895271, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [64000/69249 (92%)]\tLoss: 1.847114, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [66560/69249 (96%)]\tLoss: 1.863794, mean accuracy last epoch: 0.796\n",
      "Train Epoch 74 [34830/69249 (100%)]\tLoss: 1.890289, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [0/69249 (0%)]\tLoss: 1.879423, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [2560/69249 (4%)]\tLoss: 1.900018, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [5120/69249 (7%)]\tLoss: 1.916847, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [7680/69249 (11%)]\tLoss: 1.907782, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [10240/69249 (15%)]\tLoss: 1.860536, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [12800/69249 (18%)]\tLoss: 1.845506, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [15360/69249 (22%)]\tLoss: 1.862345, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [17920/69249 (26%)]\tLoss: 1.846955, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [20480/69249 (30%)]\tLoss: 1.892988, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [23040/69249 (33%)]\tLoss: 1.896197, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [25600/69249 (37%)]\tLoss: 1.860845, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [28160/69249 (41%)]\tLoss: 1.852040, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [30720/69249 (44%)]\tLoss: 1.918977, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [33280/69249 (48%)]\tLoss: 1.895670, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [35840/69249 (52%)]\tLoss: 1.852645, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [38400/69249 (55%)]\tLoss: 1.867783, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [40960/69249 (59%)]\tLoss: 1.876986, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [43520/69249 (63%)]\tLoss: 1.867126, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [46080/69249 (66%)]\tLoss: 1.923409, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [48640/69249 (70%)]\tLoss: 1.853055, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [51200/69249 (74%)]\tLoss: 1.889540, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [53760/69249 (77%)]\tLoss: 1.868380, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [56320/69249 (81%)]\tLoss: 1.853812, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [58880/69249 (85%)]\tLoss: 1.879745, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [61440/69249 (89%)]\tLoss: 1.849382, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [64000/69249 (92%)]\tLoss: 1.853036, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [66560/69249 (96%)]\tLoss: 1.914337, mean accuracy last epoch: 0.796\n",
      "Train Epoch 75 [34830/69249 (100%)]\tLoss: 1.930646, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [0/69249 (0%)]\tLoss: 1.880235, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [2560/69249 (4%)]\tLoss: 1.863939, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [5120/69249 (7%)]\tLoss: 1.951893, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [7680/69249 (11%)]\tLoss: 1.870053, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [10240/69249 (15%)]\tLoss: 1.867643, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [12800/69249 (18%)]\tLoss: 1.878930, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [15360/69249 (22%)]\tLoss: 1.960465, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [17920/69249 (26%)]\tLoss: 1.905510, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [20480/69249 (30%)]\tLoss: 1.872915, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [23040/69249 (33%)]\tLoss: 1.868346, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [25600/69249 (37%)]\tLoss: 1.860617, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [28160/69249 (41%)]\tLoss: 1.849035, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [30720/69249 (44%)]\tLoss: 1.886078, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [33280/69249 (48%)]\tLoss: 1.837468, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [35840/69249 (52%)]\tLoss: 1.865027, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [38400/69249 (55%)]\tLoss: 1.861011, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [40960/69249 (59%)]\tLoss: 1.911830, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [43520/69249 (63%)]\tLoss: 1.878973, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [46080/69249 (66%)]\tLoss: 1.904709, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [48640/69249 (70%)]\tLoss: 1.881333, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [51200/69249 (74%)]\tLoss: 1.868301, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [53760/69249 (77%)]\tLoss: 1.841903, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [56320/69249 (81%)]\tLoss: 1.868950, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [58880/69249 (85%)]\tLoss: 1.908060, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [61440/69249 (89%)]\tLoss: 1.872494, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [64000/69249 (92%)]\tLoss: 1.899839, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [66560/69249 (96%)]\tLoss: 1.891181, mean accuracy last epoch: 0.796\n",
      "Train Epoch 76 [34830/69249 (100%)]\tLoss: 1.890587, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [0/69249 (0%)]\tLoss: 1.867093, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [2560/69249 (4%)]\tLoss: 1.883987, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [5120/69249 (7%)]\tLoss: 1.913564, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [7680/69249 (11%)]\tLoss: 1.877468, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [10240/69249 (15%)]\tLoss: 1.900256, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [12800/69249 (18%)]\tLoss: 1.866149, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [15360/69249 (22%)]\tLoss: 1.835108, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [17920/69249 (26%)]\tLoss: 1.856335, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [20480/69249 (30%)]\tLoss: 1.849192, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [23040/69249 (33%)]\tLoss: 1.934723, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [25600/69249 (37%)]\tLoss: 1.857210, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [28160/69249 (41%)]\tLoss: 1.854400, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [30720/69249 (44%)]\tLoss: 1.860962, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [33280/69249 (48%)]\tLoss: 1.921408, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [35840/69249 (52%)]\tLoss: 1.863554, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [38400/69249 (55%)]\tLoss: 1.870087, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [40960/69249 (59%)]\tLoss: 1.864763, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [43520/69249 (63%)]\tLoss: 1.893001, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [46080/69249 (66%)]\tLoss: 1.902844, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [48640/69249 (70%)]\tLoss: 1.883106, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [51200/69249 (74%)]\tLoss: 1.907688, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [53760/69249 (77%)]\tLoss: 1.871359, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [56320/69249 (81%)]\tLoss: 1.888978, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [58880/69249 (85%)]\tLoss: 1.879854, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [61440/69249 (89%)]\tLoss: 1.886445, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [64000/69249 (92%)]\tLoss: 1.853112, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [66560/69249 (96%)]\tLoss: 1.842109, mean accuracy last epoch: 0.796\n",
      "Train Epoch 77 [34830/69249 (100%)]\tLoss: 1.874323, mean accuracy last epoch: 0.796\n",
      "Train Epoch 78 [0/69249 (0%)]\tLoss: 1.841195, mean accuracy last epoch: 0.796\n",
      "Train Epoch 78 [2560/69249 (4%)]\tLoss: 1.935939, mean accuracy last epoch: 0.796\n",
      "Train Epoch 78 [5120/69249 (7%)]\tLoss: 1.872325, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [7680/69249 (11%)]\tLoss: 1.861737, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [10240/69249 (15%)]\tLoss: 1.895941, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [12800/69249 (18%)]\tLoss: 1.894220, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [15360/69249 (22%)]\tLoss: 1.916824, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [17920/69249 (26%)]\tLoss: 1.872674, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [20480/69249 (30%)]\tLoss: 1.905041, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [23040/69249 (33%)]\tLoss: 1.892631, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [25600/69249 (37%)]\tLoss: 1.872274, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [28160/69249 (41%)]\tLoss: 1.863558, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [30720/69249 (44%)]\tLoss: 1.869069, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [33280/69249 (48%)]\tLoss: 1.895969, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [35840/69249 (52%)]\tLoss: 1.888026, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [38400/69249 (55%)]\tLoss: 1.915241, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [40960/69249 (59%)]\tLoss: 1.926648, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [43520/69249 (63%)]\tLoss: 1.851819, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [46080/69249 (66%)]\tLoss: 1.856870, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [48640/69249 (70%)]\tLoss: 1.894565, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [51200/69249 (74%)]\tLoss: 1.876564, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [53760/69249 (77%)]\tLoss: 1.877703, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [56320/69249 (81%)]\tLoss: 1.865372, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [58880/69249 (85%)]\tLoss: 1.857239, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [61440/69249 (89%)]\tLoss: 1.864994, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [64000/69249 (92%)]\tLoss: 1.897882, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [66560/69249 (96%)]\tLoss: 1.895571, mean accuracy last epoch: 0.797\n",
      "Train Epoch 78 [34830/69249 (100%)]\tLoss: 1.882245, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [0/69249 (0%)]\tLoss: 1.870867, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [2560/69249 (4%)]\tLoss: 1.884398, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [5120/69249 (7%)]\tLoss: 1.864789, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [7680/69249 (11%)]\tLoss: 1.864645, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [10240/69249 (15%)]\tLoss: 1.916574, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [12800/69249 (18%)]\tLoss: 1.879666, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [15360/69249 (22%)]\tLoss: 1.851825, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [17920/69249 (26%)]\tLoss: 1.860294, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [20480/69249 (30%)]\tLoss: 1.864727, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [23040/69249 (33%)]\tLoss: 1.913819, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [25600/69249 (37%)]\tLoss: 1.888307, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [28160/69249 (41%)]\tLoss: 1.907775, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [30720/69249 (44%)]\tLoss: 1.927199, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [33280/69249 (48%)]\tLoss: 1.853889, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [35840/69249 (52%)]\tLoss: 1.884629, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [38400/69249 (55%)]\tLoss: 1.869074, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [40960/69249 (59%)]\tLoss: 1.862452, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [43520/69249 (63%)]\tLoss: 1.906985, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [46080/69249 (66%)]\tLoss: 1.869583, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [48640/69249 (70%)]\tLoss: 1.907635, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [51200/69249 (74%)]\tLoss: 1.873041, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [53760/69249 (77%)]\tLoss: 1.855240, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [56320/69249 (81%)]\tLoss: 1.872499, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [58880/69249 (85%)]\tLoss: 1.899431, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [61440/69249 (89%)]\tLoss: 1.873090, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [64000/69249 (92%)]\tLoss: 1.866330, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [66560/69249 (96%)]\tLoss: 1.889700, mean accuracy last epoch: 0.797\n",
      "Train Epoch 79 [34830/69249 (100%)]\tLoss: 1.867254, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [0/69249 (0%)]\tLoss: 1.868273, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [2560/69249 (4%)]\tLoss: 1.830583, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [5120/69249 (7%)]\tLoss: 1.855577, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [7680/69249 (11%)]\tLoss: 1.895796, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [10240/69249 (15%)]\tLoss: 1.889760, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [12800/69249 (18%)]\tLoss: 1.884008, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [15360/69249 (22%)]\tLoss: 1.896411, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [17920/69249 (26%)]\tLoss: 1.874384, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [20480/69249 (30%)]\tLoss: 1.902519, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [23040/69249 (33%)]\tLoss: 1.887335, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [25600/69249 (37%)]\tLoss: 1.919756, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [28160/69249 (41%)]\tLoss: 1.872195, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [30720/69249 (44%)]\tLoss: 1.861499, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [33280/69249 (48%)]\tLoss: 1.927042, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [35840/69249 (52%)]\tLoss: 1.872499, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [38400/69249 (55%)]\tLoss: 1.882670, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [40960/69249 (59%)]\tLoss: 1.864253, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [43520/69249 (63%)]\tLoss: 1.881144, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [46080/69249 (66%)]\tLoss: 1.858770, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [48640/69249 (70%)]\tLoss: 1.873545, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [51200/69249 (74%)]\tLoss: 1.879311, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [53760/69249 (77%)]\tLoss: 1.915227, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [56320/69249 (81%)]\tLoss: 1.857496, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [58880/69249 (85%)]\tLoss: 1.888234, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [61440/69249 (89%)]\tLoss: 1.894854, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [64000/69249 (92%)]\tLoss: 1.859588, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [66560/69249 (96%)]\tLoss: 1.876063, mean accuracy last epoch: 0.797\n",
      "Train Epoch 80 [34830/69249 (100%)]\tLoss: 1.921199, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [0/69249 (0%)]\tLoss: 1.875391, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [2560/69249 (4%)]\tLoss: 1.862761, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [5120/69249 (7%)]\tLoss: 1.868798, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [7680/69249 (11%)]\tLoss: 1.850757, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [10240/69249 (15%)]\tLoss: 1.857566, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [12800/69249 (18%)]\tLoss: 1.891787, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [15360/69249 (22%)]\tLoss: 1.893652, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [17920/69249 (26%)]\tLoss: 1.870660, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [20480/69249 (30%)]\tLoss: 1.897295, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [23040/69249 (33%)]\tLoss: 1.889846, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [25600/69249 (37%)]\tLoss: 1.870358, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [28160/69249 (41%)]\tLoss: 1.883427, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [30720/69249 (44%)]\tLoss: 1.866048, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [33280/69249 (48%)]\tLoss: 1.904076, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [35840/69249 (52%)]\tLoss: 1.899546, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [38400/69249 (55%)]\tLoss: 1.870976, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [40960/69249 (59%)]\tLoss: 1.899586, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [43520/69249 (63%)]\tLoss: 1.838251, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [46080/69249 (66%)]\tLoss: 1.868769, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [48640/69249 (70%)]\tLoss: 1.863771, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [51200/69249 (74%)]\tLoss: 1.829548, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [53760/69249 (77%)]\tLoss: 1.872206, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [56320/69249 (81%)]\tLoss: 1.888410, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [58880/69249 (85%)]\tLoss: 1.853751, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [61440/69249 (89%)]\tLoss: 1.840030, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [64000/69249 (92%)]\tLoss: 1.834865, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [66560/69249 (96%)]\tLoss: 1.888820, mean accuracy last epoch: 0.797\n",
      "Train Epoch 81 [34830/69249 (100%)]\tLoss: 1.864144, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [0/69249 (0%)]\tLoss: 1.821864, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [2560/69249 (4%)]\tLoss: 1.864358, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [5120/69249 (7%)]\tLoss: 1.895465, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [7680/69249 (11%)]\tLoss: 1.901875, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [10240/69249 (15%)]\tLoss: 1.916428, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [12800/69249 (18%)]\tLoss: 1.880299, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [15360/69249 (22%)]\tLoss: 1.888622, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [17920/69249 (26%)]\tLoss: 1.907461, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [20480/69249 (30%)]\tLoss: 1.872538, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [23040/69249 (33%)]\tLoss: 1.907288, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [25600/69249 (37%)]\tLoss: 1.876131, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [28160/69249 (41%)]\tLoss: 1.878775, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [30720/69249 (44%)]\tLoss: 1.880127, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [33280/69249 (48%)]\tLoss: 1.841309, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [35840/69249 (52%)]\tLoss: 1.888133, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [38400/69249 (55%)]\tLoss: 1.910916, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [40960/69249 (59%)]\tLoss: 1.897333, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [43520/69249 (63%)]\tLoss: 1.846619, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [46080/69249 (66%)]\tLoss: 1.881321, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [48640/69249 (70%)]\tLoss: 1.939176, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [51200/69249 (74%)]\tLoss: 1.921835, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [53760/69249 (77%)]\tLoss: 1.859781, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [56320/69249 (81%)]\tLoss: 1.872340, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [58880/69249 (85%)]\tLoss: 1.872320, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [61440/69249 (89%)]\tLoss: 1.891358, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [64000/69249 (92%)]\tLoss: 1.869346, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [66560/69249 (96%)]\tLoss: 1.918458, mean accuracy last epoch: 0.797\n",
      "Train Epoch 82 [34830/69249 (100%)]\tLoss: 1.906088, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [0/69249 (0%)]\tLoss: 1.904240, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [2560/69249 (4%)]\tLoss: 1.857161, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [5120/69249 (7%)]\tLoss: 1.856703, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [7680/69249 (11%)]\tLoss: 1.848121, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [10240/69249 (15%)]\tLoss: 1.902030, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [12800/69249 (18%)]\tLoss: 1.846359, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [15360/69249 (22%)]\tLoss: 1.832885, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [17920/69249 (26%)]\tLoss: 1.810452, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [20480/69249 (30%)]\tLoss: 1.846952, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [23040/69249 (33%)]\tLoss: 1.858114, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [25600/69249 (37%)]\tLoss: 1.861363, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [28160/69249 (41%)]\tLoss: 1.916052, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [30720/69249 (44%)]\tLoss: 1.854194, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [33280/69249 (48%)]\tLoss: 1.874821, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [35840/69249 (52%)]\tLoss: 1.879368, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [38400/69249 (55%)]\tLoss: 1.876285, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [40960/69249 (59%)]\tLoss: 1.906558, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [43520/69249 (63%)]\tLoss: 1.872854, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [46080/69249 (66%)]\tLoss: 1.886743, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [48640/69249 (70%)]\tLoss: 1.868233, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [51200/69249 (74%)]\tLoss: 1.929828, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [53760/69249 (77%)]\tLoss: 1.894882, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [56320/69249 (81%)]\tLoss: 1.857598, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [58880/69249 (85%)]\tLoss: 1.855796, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [61440/69249 (89%)]\tLoss: 1.876793, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [64000/69249 (92%)]\tLoss: 1.853330, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [66560/69249 (96%)]\tLoss: 1.865875, mean accuracy last epoch: 0.797\n",
      "Train Epoch 83 [34830/69249 (100%)]\tLoss: 1.882254, mean accuracy last epoch: 0.797\n",
      "Train Epoch 84 [0/69249 (0%)]\tLoss: 1.876303, mean accuracy last epoch: 0.797\n",
      "Train Epoch 84 [2560/69249 (4%)]\tLoss: 1.904647, mean accuracy last epoch: 0.797\n",
      "Train Epoch 84 [5120/69249 (7%)]\tLoss: 1.885055, mean accuracy last epoch: 0.797\n",
      "Train Epoch 84 [7680/69249 (11%)]\tLoss: 1.866208, mean accuracy last epoch: 0.797\n",
      "Train Epoch 84 [10240/69249 (15%)]\tLoss: 1.845096, mean accuracy last epoch: 0.797\n",
      "Train Epoch 84 [12800/69249 (18%)]\tLoss: 1.872659, mean accuracy last epoch: 0.797\n",
      "Train Epoch 84 [15360/69249 (22%)]\tLoss: 1.845077, mean accuracy last epoch: 0.797\n",
      "Train Epoch 84 [17920/69249 (26%)]\tLoss: 1.921842, mean accuracy last epoch: 0.797\n",
      "Train Epoch 84 [20480/69249 (30%)]\tLoss: 1.860896, mean accuracy last epoch: 0.797\n",
      "Train Epoch 84 [23040/69249 (33%)]\tLoss: 1.899725, mean accuracy last epoch: 0.797\n",
      "Train Epoch 84 [25600/69249 (37%)]\tLoss: 1.880708, mean accuracy last epoch: 0.797\n",
      "Train Epoch 84 [28160/69249 (41%)]\tLoss: 1.860744, mean accuracy last epoch: 0.798\n",
      "Train Epoch 84 [30720/69249 (44%)]\tLoss: 1.857105, mean accuracy last epoch: 0.798\n",
      "Train Epoch 84 [33280/69249 (48%)]\tLoss: 1.876514, mean accuracy last epoch: 0.798\n",
      "Train Epoch 84 [35840/69249 (52%)]\tLoss: 1.839042, mean accuracy last epoch: 0.798\n",
      "Train Epoch 84 [38400/69249 (55%)]\tLoss: 1.832344, mean accuracy last epoch: 0.798\n",
      "Train Epoch 84 [40960/69249 (59%)]\tLoss: 1.870415, mean accuracy last epoch: 0.798\n",
      "Train Epoch 84 [43520/69249 (63%)]\tLoss: 1.903723, mean accuracy last epoch: 0.798\n",
      "Train Epoch 84 [46080/69249 (66%)]\tLoss: 1.871970, mean accuracy last epoch: 0.798\n",
      "Train Epoch 84 [48640/69249 (70%)]\tLoss: 1.884423, mean accuracy last epoch: 0.798\n",
      "Train Epoch 84 [51200/69249 (74%)]\tLoss: 1.880157, mean accuracy last epoch: 0.798\n",
      "Train Epoch 84 [53760/69249 (77%)]\tLoss: 1.892138, mean accuracy last epoch: 0.798\n",
      "Train Epoch 84 [56320/69249 (81%)]\tLoss: 1.852300, mean accuracy last epoch: 0.798\n",
      "Train Epoch 84 [58880/69249 (85%)]\tLoss: 1.921855, mean accuracy last epoch: 0.798\n",
      "Train Epoch 84 [61440/69249 (89%)]\tLoss: 1.846006, mean accuracy last epoch: 0.798\n",
      "Train Epoch 84 [64000/69249 (92%)]\tLoss: 1.896074, mean accuracy last epoch: 0.798\n",
      "Train Epoch 84 [66560/69249 (96%)]\tLoss: 1.878131, mean accuracy last epoch: 0.798\n",
      "Train Epoch 84 [34830/69249 (100%)]\tLoss: 1.879374, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [0/69249 (0%)]\tLoss: 1.855182, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [2560/69249 (4%)]\tLoss: 1.861159, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [5120/69249 (7%)]\tLoss: 1.889087, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [7680/69249 (11%)]\tLoss: 1.875868, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [10240/69249 (15%)]\tLoss: 1.896079, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [12800/69249 (18%)]\tLoss: 1.874914, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [15360/69249 (22%)]\tLoss: 1.856985, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [17920/69249 (26%)]\tLoss: 1.899930, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [20480/69249 (30%)]\tLoss: 1.907870, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [23040/69249 (33%)]\tLoss: 1.845042, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [25600/69249 (37%)]\tLoss: 1.857643, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [28160/69249 (41%)]\tLoss: 1.856963, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [30720/69249 (44%)]\tLoss: 1.915999, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [33280/69249 (48%)]\tLoss: 1.889863, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [35840/69249 (52%)]\tLoss: 1.900287, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [38400/69249 (55%)]\tLoss: 1.855289, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [40960/69249 (59%)]\tLoss: 1.858049, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [43520/69249 (63%)]\tLoss: 1.891776, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [46080/69249 (66%)]\tLoss: 1.932750, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [48640/69249 (70%)]\tLoss: 1.859555, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [51200/69249 (74%)]\tLoss: 1.849435, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [53760/69249 (77%)]\tLoss: 1.853195, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [56320/69249 (81%)]\tLoss: 1.891670, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [58880/69249 (85%)]\tLoss: 1.917636, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [61440/69249 (89%)]\tLoss: 1.910816, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [64000/69249 (92%)]\tLoss: 1.859976, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [66560/69249 (96%)]\tLoss: 1.905464, mean accuracy last epoch: 0.798\n",
      "Train Epoch 85 [34830/69249 (100%)]\tLoss: 1.846838, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [0/69249 (0%)]\tLoss: 1.897109, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [2560/69249 (4%)]\tLoss: 1.878222, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [5120/69249 (7%)]\tLoss: 1.853228, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [7680/69249 (11%)]\tLoss: 1.867269, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [10240/69249 (15%)]\tLoss: 1.901648, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [12800/69249 (18%)]\tLoss: 1.880026, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [15360/69249 (22%)]\tLoss: 1.860691, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [17920/69249 (26%)]\tLoss: 1.845555, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [20480/69249 (30%)]\tLoss: 1.875258, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [23040/69249 (33%)]\tLoss: 1.905438, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [25600/69249 (37%)]\tLoss: 1.828687, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [28160/69249 (41%)]\tLoss: 1.907363, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [30720/69249 (44%)]\tLoss: 1.884082, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [33280/69249 (48%)]\tLoss: 1.891025, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [35840/69249 (52%)]\tLoss: 1.848570, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [38400/69249 (55%)]\tLoss: 1.877396, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [40960/69249 (59%)]\tLoss: 1.920068, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [43520/69249 (63%)]\tLoss: 1.857059, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [46080/69249 (66%)]\tLoss: 1.859577, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [48640/69249 (70%)]\tLoss: 1.904027, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [51200/69249 (74%)]\tLoss: 1.873148, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [53760/69249 (77%)]\tLoss: 1.848440, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [56320/69249 (81%)]\tLoss: 1.892814, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [58880/69249 (85%)]\tLoss: 1.891612, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [61440/69249 (89%)]\tLoss: 1.903054, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [64000/69249 (92%)]\tLoss: 1.880766, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [66560/69249 (96%)]\tLoss: 1.884879, mean accuracy last epoch: 0.798\n",
      "Train Epoch 86 [34830/69249 (100%)]\tLoss: 1.813630, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [0/69249 (0%)]\tLoss: 1.898509, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [2560/69249 (4%)]\tLoss: 1.853460, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [5120/69249 (7%)]\tLoss: 1.880752, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [7680/69249 (11%)]\tLoss: 1.885801, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [10240/69249 (15%)]\tLoss: 1.868550, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [12800/69249 (18%)]\tLoss: 1.863651, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [15360/69249 (22%)]\tLoss: 1.895374, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [17920/69249 (26%)]\tLoss: 1.868694, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [20480/69249 (30%)]\tLoss: 1.830717, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [23040/69249 (33%)]\tLoss: 1.843156, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [25600/69249 (37%)]\tLoss: 1.912869, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [28160/69249 (41%)]\tLoss: 1.860636, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [30720/69249 (44%)]\tLoss: 1.888521, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [33280/69249 (48%)]\tLoss: 1.904295, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [35840/69249 (52%)]\tLoss: 1.884115, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [38400/69249 (55%)]\tLoss: 1.887311, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [40960/69249 (59%)]\tLoss: 1.865614, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [43520/69249 (63%)]\tLoss: 1.915941, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [46080/69249 (66%)]\tLoss: 1.916306, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [48640/69249 (70%)]\tLoss: 1.869422, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [51200/69249 (74%)]\tLoss: 1.894367, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [53760/69249 (77%)]\tLoss: 1.903948, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [56320/69249 (81%)]\tLoss: 1.858228, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [58880/69249 (85%)]\tLoss: 1.891861, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [61440/69249 (89%)]\tLoss: 1.863400, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [64000/69249 (92%)]\tLoss: 1.934772, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [66560/69249 (96%)]\tLoss: 1.892670, mean accuracy last epoch: 0.798\n",
      "Train Epoch 87 [34830/69249 (100%)]\tLoss: 1.934769, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [0/69249 (0%)]\tLoss: 1.891901, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [2560/69249 (4%)]\tLoss: 1.900597, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [5120/69249 (7%)]\tLoss: 1.909073, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [7680/69249 (11%)]\tLoss: 1.881111, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [10240/69249 (15%)]\tLoss: 1.883627, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [12800/69249 (18%)]\tLoss: 1.841089, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [15360/69249 (22%)]\tLoss: 1.840593, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [17920/69249 (26%)]\tLoss: 1.885327, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [20480/69249 (30%)]\tLoss: 1.865400, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [23040/69249 (33%)]\tLoss: 1.872103, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [25600/69249 (37%)]\tLoss: 1.927831, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [28160/69249 (41%)]\tLoss: 1.873776, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [30720/69249 (44%)]\tLoss: 1.950470, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [33280/69249 (48%)]\tLoss: 1.830373, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [35840/69249 (52%)]\tLoss: 1.912139, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [38400/69249 (55%)]\tLoss: 1.874095, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [40960/69249 (59%)]\tLoss: 1.924080, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [43520/69249 (63%)]\tLoss: 1.949290, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [46080/69249 (66%)]\tLoss: 1.815470, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [48640/69249 (70%)]\tLoss: 1.876225, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [51200/69249 (74%)]\tLoss: 1.886549, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [53760/69249 (77%)]\tLoss: 1.894367, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [56320/69249 (81%)]\tLoss: 1.850841, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [58880/69249 (85%)]\tLoss: 1.859723, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [61440/69249 (89%)]\tLoss: 1.928516, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [64000/69249 (92%)]\tLoss: 1.872479, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [66560/69249 (96%)]\tLoss: 1.866353, mean accuracy last epoch: 0.798\n",
      "Train Epoch 88 [34830/69249 (100%)]\tLoss: 1.898928, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [0/69249 (0%)]\tLoss: 1.837323, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [2560/69249 (4%)]\tLoss: 1.893552, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [5120/69249 (7%)]\tLoss: 1.922013, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [7680/69249 (11%)]\tLoss: 1.878707, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [10240/69249 (15%)]\tLoss: 1.852944, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [12800/69249 (18%)]\tLoss: 1.827685, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [15360/69249 (22%)]\tLoss: 1.906864, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [17920/69249 (26%)]\tLoss: 1.872890, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [20480/69249 (30%)]\tLoss: 1.920758, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [23040/69249 (33%)]\tLoss: 1.896490, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [25600/69249 (37%)]\tLoss: 1.884782, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [28160/69249 (41%)]\tLoss: 1.855888, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [30720/69249 (44%)]\tLoss: 1.852962, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [33280/69249 (48%)]\tLoss: 1.898726, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [35840/69249 (52%)]\tLoss: 1.886708, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [38400/69249 (55%)]\tLoss: 1.869504, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [40960/69249 (59%)]\tLoss: 1.864490, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [43520/69249 (63%)]\tLoss: 1.895778, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [46080/69249 (66%)]\tLoss: 1.847545, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [48640/69249 (70%)]\tLoss: 1.900689, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [51200/69249 (74%)]\tLoss: 1.892484, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [53760/69249 (77%)]\tLoss: 1.860588, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [56320/69249 (81%)]\tLoss: 1.875342, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [58880/69249 (85%)]\tLoss: 1.860941, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [61440/69249 (89%)]\tLoss: 1.898982, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [64000/69249 (92%)]\tLoss: 1.888521, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [66560/69249 (96%)]\tLoss: 1.869261, mean accuracy last epoch: 0.798\n",
      "Train Epoch 89 [34830/69249 (100%)]\tLoss: 1.856831, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [0/69249 (0%)]\tLoss: 1.905236, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [2560/69249 (4%)]\tLoss: 1.907920, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [5120/69249 (7%)]\tLoss: 1.879652, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [7680/69249 (11%)]\tLoss: 1.859728, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [10240/69249 (15%)]\tLoss: 1.872150, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [12800/69249 (18%)]\tLoss: 1.872573, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [15360/69249 (22%)]\tLoss: 1.888928, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [17920/69249 (26%)]\tLoss: 1.888234, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [20480/69249 (30%)]\tLoss: 1.876277, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [23040/69249 (33%)]\tLoss: 1.893253, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [25600/69249 (37%)]\tLoss: 1.904016, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [28160/69249 (41%)]\tLoss: 1.892084, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [30720/69249 (44%)]\tLoss: 1.856995, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [33280/69249 (48%)]\tLoss: 1.875871, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [35840/69249 (52%)]\tLoss: 1.896348, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [38400/69249 (55%)]\tLoss: 1.881055, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [40960/69249 (59%)]\tLoss: 1.910091, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [43520/69249 (63%)]\tLoss: 1.867477, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [46080/69249 (66%)]\tLoss: 1.883137, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [48640/69249 (70%)]\tLoss: 1.876202, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [51200/69249 (74%)]\tLoss: 1.898892, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [53760/69249 (77%)]\tLoss: 1.891800, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [56320/69249 (81%)]\tLoss: 1.914083, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [58880/69249 (85%)]\tLoss: 1.856347, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [61440/69249 (89%)]\tLoss: 1.888476, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [64000/69249 (92%)]\tLoss: 1.872595, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [66560/69249 (96%)]\tLoss: 1.890194, mean accuracy last epoch: 0.798\n",
      "Train Epoch 90 [34830/69249 (100%)]\tLoss: 1.856566, mean accuracy last epoch: 0.798\n",
      "Train Epoch 91 [0/69249 (0%)]\tLoss: 1.892123, mean accuracy last epoch: 0.798\n",
      "Train Epoch 91 [2560/69249 (4%)]\tLoss: 1.902819, mean accuracy last epoch: 0.798\n",
      "Train Epoch 91 [5120/69249 (7%)]\tLoss: 1.865667, mean accuracy last epoch: 0.798\n",
      "Train Epoch 91 [7680/69249 (11%)]\tLoss: 1.914817, mean accuracy last epoch: 0.798\n",
      "Train Epoch 91 [10240/69249 (15%)]\tLoss: 1.884489, mean accuracy last epoch: 0.798\n",
      "Train Epoch 91 [12800/69249 (18%)]\tLoss: 1.888329, mean accuracy last epoch: 0.798\n",
      "Train Epoch 91 [15360/69249 (22%)]\tLoss: 1.854352, mean accuracy last epoch: 0.798\n",
      "Train Epoch 91 [17920/69249 (26%)]\tLoss: 1.892652, mean accuracy last epoch: 0.798\n",
      "Train Epoch 91 [20480/69249 (30%)]\tLoss: 1.899271, mean accuracy last epoch: 0.798\n",
      "Train Epoch 91 [23040/69249 (33%)]\tLoss: 1.842693, mean accuracy last epoch: 0.798\n",
      "Train Epoch 91 [25600/69249 (37%)]\tLoss: 1.866490, mean accuracy last epoch: 0.798\n",
      "Train Epoch 91 [28160/69249 (41%)]\tLoss: 1.893967, mean accuracy last epoch: 0.798\n",
      "Train Epoch 91 [30720/69249 (44%)]\tLoss: 1.860512, mean accuracy last epoch: 0.798\n",
      "Train Epoch 91 [33280/69249 (48%)]\tLoss: 1.915675, mean accuracy last epoch: 0.799\n",
      "Train Epoch 91 [35840/69249 (52%)]\tLoss: 1.916968, mean accuracy last epoch: 0.799\n",
      "Train Epoch 91 [38400/69249 (55%)]\tLoss: 1.906006, mean accuracy last epoch: 0.799\n",
      "Train Epoch 91 [40960/69249 (59%)]\tLoss: 1.899175, mean accuracy last epoch: 0.799\n",
      "Train Epoch 91 [43520/69249 (63%)]\tLoss: 1.883484, mean accuracy last epoch: 0.799\n",
      "Train Epoch 91 [46080/69249 (66%)]\tLoss: 1.841527, mean accuracy last epoch: 0.799\n",
      "Train Epoch 91 [48640/69249 (70%)]\tLoss: 1.873526, mean accuracy last epoch: 0.799\n",
      "Train Epoch 91 [51200/69249 (74%)]\tLoss: 1.876508, mean accuracy last epoch: 0.799\n",
      "Train Epoch 91 [53760/69249 (77%)]\tLoss: 1.896773, mean accuracy last epoch: 0.799\n",
      "Train Epoch 91 [56320/69249 (81%)]\tLoss: 1.875878, mean accuracy last epoch: 0.799\n",
      "Train Epoch 91 [58880/69249 (85%)]\tLoss: 1.864808, mean accuracy last epoch: 0.799\n",
      "Train Epoch 91 [61440/69249 (89%)]\tLoss: 1.873867, mean accuracy last epoch: 0.799\n",
      "Train Epoch 91 [64000/69249 (92%)]\tLoss: 1.849450, mean accuracy last epoch: 0.799\n",
      "Train Epoch 91 [66560/69249 (96%)]\tLoss: 1.870901, mean accuracy last epoch: 0.799\n",
      "Train Epoch 91 [34830/69249 (100%)]\tLoss: 1.938637, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [0/69249 (0%)]\tLoss: 1.893630, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [2560/69249 (4%)]\tLoss: 1.840897, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [5120/69249 (7%)]\tLoss: 1.902572, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [7680/69249 (11%)]\tLoss: 1.854934, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [10240/69249 (15%)]\tLoss: 1.880286, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [12800/69249 (18%)]\tLoss: 1.916102, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [15360/69249 (22%)]\tLoss: 1.907722, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [17920/69249 (26%)]\tLoss: 1.899469, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [20480/69249 (30%)]\tLoss: 1.875623, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [23040/69249 (33%)]\tLoss: 1.853443, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [25600/69249 (37%)]\tLoss: 1.831156, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [28160/69249 (41%)]\tLoss: 1.872263, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [30720/69249 (44%)]\tLoss: 1.911472, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [33280/69249 (48%)]\tLoss: 1.893966, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [35840/69249 (52%)]\tLoss: 1.878074, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [38400/69249 (55%)]\tLoss: 1.849130, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [40960/69249 (59%)]\tLoss: 1.872549, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [43520/69249 (63%)]\tLoss: 1.904724, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [46080/69249 (66%)]\tLoss: 1.851389, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [48640/69249 (70%)]\tLoss: 1.897745, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [51200/69249 (74%)]\tLoss: 1.856436, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [53760/69249 (77%)]\tLoss: 1.905649, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [56320/69249 (81%)]\tLoss: 1.881819, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [58880/69249 (85%)]\tLoss: 1.886049, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [61440/69249 (89%)]\tLoss: 1.856889, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [64000/69249 (92%)]\tLoss: 1.867985, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [66560/69249 (96%)]\tLoss: 1.877835, mean accuracy last epoch: 0.799\n",
      "Train Epoch 92 [34830/69249 (100%)]\tLoss: 1.898189, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [0/69249 (0%)]\tLoss: 1.843259, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [2560/69249 (4%)]\tLoss: 1.896265, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [5120/69249 (7%)]\tLoss: 1.868944, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [7680/69249 (11%)]\tLoss: 1.853104, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [10240/69249 (15%)]\tLoss: 1.861055, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [12800/69249 (18%)]\tLoss: 1.848935, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [15360/69249 (22%)]\tLoss: 1.896237, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [17920/69249 (26%)]\tLoss: 1.851446, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [20480/69249 (30%)]\tLoss: 1.889209, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [23040/69249 (33%)]\tLoss: 1.872695, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [25600/69249 (37%)]\tLoss: 1.879658, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [28160/69249 (41%)]\tLoss: 1.855444, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [30720/69249 (44%)]\tLoss: 1.874714, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [33280/69249 (48%)]\tLoss: 1.863957, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [35840/69249 (52%)]\tLoss: 1.892463, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [38400/69249 (55%)]\tLoss: 1.904043, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [40960/69249 (59%)]\tLoss: 1.875874, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [43520/69249 (63%)]\tLoss: 1.911273, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [46080/69249 (66%)]\tLoss: 1.891950, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [48640/69249 (70%)]\tLoss: 1.910781, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [51200/69249 (74%)]\tLoss: 1.865400, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [53760/69249 (77%)]\tLoss: 1.919164, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [56320/69249 (81%)]\tLoss: 1.882851, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [58880/69249 (85%)]\tLoss: 1.888284, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [61440/69249 (89%)]\tLoss: 1.841183, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [64000/69249 (92%)]\tLoss: 1.884306, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [66560/69249 (96%)]\tLoss: 1.888615, mean accuracy last epoch: 0.799\n",
      "Train Epoch 93 [34830/69249 (100%)]\tLoss: 1.835336, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [0/69249 (0%)]\tLoss: 1.887254, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [2560/69249 (4%)]\tLoss: 1.895757, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [5120/69249 (7%)]\tLoss: 1.888482, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [7680/69249 (11%)]\tLoss: 1.898957, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [10240/69249 (15%)]\tLoss: 1.880235, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [12800/69249 (18%)]\tLoss: 1.916718, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [15360/69249 (22%)]\tLoss: 1.895620, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [17920/69249 (26%)]\tLoss: 1.877817, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [20480/69249 (30%)]\tLoss: 1.879969, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [23040/69249 (33%)]\tLoss: 1.869522, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [25600/69249 (37%)]\tLoss: 1.908713, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [28160/69249 (41%)]\tLoss: 1.888397, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [30720/69249 (44%)]\tLoss: 1.908283, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [33280/69249 (48%)]\tLoss: 1.911170, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [35840/69249 (52%)]\tLoss: 1.866431, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [38400/69249 (55%)]\tLoss: 1.880473, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [40960/69249 (59%)]\tLoss: 1.880550, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [43520/69249 (63%)]\tLoss: 1.882751, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [46080/69249 (66%)]\tLoss: 1.868927, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [48640/69249 (70%)]\tLoss: 1.869220, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [51200/69249 (74%)]\tLoss: 1.840310, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [53760/69249 (77%)]\tLoss: 1.856642, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [56320/69249 (81%)]\tLoss: 1.884234, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [58880/69249 (85%)]\tLoss: 1.862094, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [61440/69249 (89%)]\tLoss: 1.881098, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [64000/69249 (92%)]\tLoss: 1.922360, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [66560/69249 (96%)]\tLoss: 1.912237, mean accuracy last epoch: 0.799\n",
      "Train Epoch 94 [34830/69249 (100%)]\tLoss: 1.857319, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [0/69249 (0%)]\tLoss: 1.888178, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [2560/69249 (4%)]\tLoss: 1.912630, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [5120/69249 (7%)]\tLoss: 1.877704, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [7680/69249 (11%)]\tLoss: 1.837134, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [10240/69249 (15%)]\tLoss: 1.836090, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [12800/69249 (18%)]\tLoss: 1.893850, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [15360/69249 (22%)]\tLoss: 1.851079, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [17920/69249 (26%)]\tLoss: 1.893813, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [20480/69249 (30%)]\tLoss: 1.877138, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [23040/69249 (33%)]\tLoss: 1.882514, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [25600/69249 (37%)]\tLoss: 1.868639, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [28160/69249 (41%)]\tLoss: 1.908622, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [30720/69249 (44%)]\tLoss: 1.849730, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [33280/69249 (48%)]\tLoss: 1.928136, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [35840/69249 (52%)]\tLoss: 1.911551, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [38400/69249 (55%)]\tLoss: 1.879910, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [40960/69249 (59%)]\tLoss: 1.856682, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [43520/69249 (63%)]\tLoss: 1.894037, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [46080/69249 (66%)]\tLoss: 1.892790, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [48640/69249 (70%)]\tLoss: 1.853002, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [51200/69249 (74%)]\tLoss: 1.856959, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [53760/69249 (77%)]\tLoss: 1.852841, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [56320/69249 (81%)]\tLoss: 1.913481, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [58880/69249 (85%)]\tLoss: 1.879029, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [61440/69249 (89%)]\tLoss: 1.874136, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [64000/69249 (92%)]\tLoss: 1.848597, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [66560/69249 (96%)]\tLoss: 1.891599, mean accuracy last epoch: 0.799\n",
      "Train Epoch 95 [34830/69249 (100%)]\tLoss: 1.870246, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [0/69249 (0%)]\tLoss: 1.871097, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [2560/69249 (4%)]\tLoss: 1.884158, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [5120/69249 (7%)]\tLoss: 1.924248, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [7680/69249 (11%)]\tLoss: 1.873892, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [10240/69249 (15%)]\tLoss: 1.854533, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [12800/69249 (18%)]\tLoss: 1.829477, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [15360/69249 (22%)]\tLoss: 1.962809, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [17920/69249 (26%)]\tLoss: 1.869142, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [20480/69249 (30%)]\tLoss: 1.865411, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [23040/69249 (33%)]\tLoss: 1.855485, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [25600/69249 (37%)]\tLoss: 1.883287, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [28160/69249 (41%)]\tLoss: 1.880451, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [30720/69249 (44%)]\tLoss: 1.849498, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [33280/69249 (48%)]\tLoss: 1.873397, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [35840/69249 (52%)]\tLoss: 1.882092, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [38400/69249 (55%)]\tLoss: 1.838080, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [40960/69249 (59%)]\tLoss: 1.852803, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [43520/69249 (63%)]\tLoss: 1.839601, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [46080/69249 (66%)]\tLoss: 1.913855, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [48640/69249 (70%)]\tLoss: 1.856818, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [51200/69249 (74%)]\tLoss: 1.878258, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [53760/69249 (77%)]\tLoss: 1.851968, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [56320/69249 (81%)]\tLoss: 1.894785, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [58880/69249 (85%)]\tLoss: 1.938397, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [61440/69249 (89%)]\tLoss: 1.871278, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [64000/69249 (92%)]\tLoss: 1.894394, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [66560/69249 (96%)]\tLoss: 1.852161, mean accuracy last epoch: 0.799\n",
      "Train Epoch 96 [34830/69249 (100%)]\tLoss: 1.889929, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [0/69249 (0%)]\tLoss: 1.898129, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [2560/69249 (4%)]\tLoss: 1.891726, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [5120/69249 (7%)]\tLoss: 1.902303, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [7680/69249 (11%)]\tLoss: 1.921192, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [10240/69249 (15%)]\tLoss: 1.893465, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [12800/69249 (18%)]\tLoss: 1.862311, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [15360/69249 (22%)]\tLoss: 1.872348, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [17920/69249 (26%)]\tLoss: 1.899389, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [20480/69249 (30%)]\tLoss: 1.841190, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [23040/69249 (33%)]\tLoss: 1.859816, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [25600/69249 (37%)]\tLoss: 1.871981, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [28160/69249 (41%)]\tLoss: 1.859547, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [30720/69249 (44%)]\tLoss: 1.933102, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [33280/69249 (48%)]\tLoss: 1.871266, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [35840/69249 (52%)]\tLoss: 1.868777, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [38400/69249 (55%)]\tLoss: 1.889716, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [40960/69249 (59%)]\tLoss: 1.838362, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [43520/69249 (63%)]\tLoss: 1.861015, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [46080/69249 (66%)]\tLoss: 1.895478, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [48640/69249 (70%)]\tLoss: 1.844980, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [51200/69249 (74%)]\tLoss: 1.892020, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [53760/69249 (77%)]\tLoss: 1.856119, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [56320/69249 (81%)]\tLoss: 1.886026, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [58880/69249 (85%)]\tLoss: 1.891423, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [61440/69249 (89%)]\tLoss: 1.863882, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [64000/69249 (92%)]\tLoss: 1.891385, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [66560/69249 (96%)]\tLoss: 1.856551, mean accuracy last epoch: 0.799\n",
      "Train Epoch 97 [34830/69249 (100%)]\tLoss: 1.882256, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [0/69249 (0%)]\tLoss: 1.912538, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [2560/69249 (4%)]\tLoss: 1.849460, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [5120/69249 (7%)]\tLoss: 1.857095, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [7680/69249 (11%)]\tLoss: 1.888269, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [10240/69249 (15%)]\tLoss: 1.864503, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [12800/69249 (18%)]\tLoss: 1.903706, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [15360/69249 (22%)]\tLoss: 1.864827, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [17920/69249 (26%)]\tLoss: 1.844806, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [20480/69249 (30%)]\tLoss: 1.865680, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [23040/69249 (33%)]\tLoss: 1.831415, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [25600/69249 (37%)]\tLoss: 1.861132, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [28160/69249 (41%)]\tLoss: 1.876071, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [30720/69249 (44%)]\tLoss: 1.907529, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [33280/69249 (48%)]\tLoss: 1.899610, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [35840/69249 (52%)]\tLoss: 1.899751, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [38400/69249 (55%)]\tLoss: 1.841295, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [40960/69249 (59%)]\tLoss: 1.902672, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [43520/69249 (63%)]\tLoss: 1.876243, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [46080/69249 (66%)]\tLoss: 1.881932, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [48640/69249 (70%)]\tLoss: 1.907346, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [51200/69249 (74%)]\tLoss: 1.900091, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [53760/69249 (77%)]\tLoss: 1.844184, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [56320/69249 (81%)]\tLoss: 1.874887, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [58880/69249 (85%)]\tLoss: 1.938263, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [61440/69249 (89%)]\tLoss: 1.917149, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [64000/69249 (92%)]\tLoss: 1.895787, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [66560/69249 (96%)]\tLoss: 1.841857, mean accuracy last epoch: 0.799\n",
      "Train Epoch 98 [34830/69249 (100%)]\tLoss: 1.851300, mean accuracy last epoch: 0.799\n",
      "Train Epoch 99 [0/69249 (0%)]\tLoss: 1.877175, mean accuracy last epoch: 0.799\n",
      "Train Epoch 99 [2560/69249 (4%)]\tLoss: 1.818082, mean accuracy last epoch: 0.799\n",
      "Train Epoch 99 [5120/69249 (7%)]\tLoss: 1.896069, mean accuracy last epoch: 0.799\n",
      "Train Epoch 99 [7680/69249 (11%)]\tLoss: 1.898772, mean accuracy last epoch: 0.799\n",
      "Train Epoch 99 [10240/69249 (15%)]\tLoss: 1.901022, mean accuracy last epoch: 0.799\n",
      "Train Epoch 99 [12800/69249 (18%)]\tLoss: 1.899899, mean accuracy last epoch: 0.799\n",
      "Train Epoch 99 [15360/69249 (22%)]\tLoss: 1.862489, mean accuracy last epoch: 0.799\n",
      "Train Epoch 99 [17920/69249 (26%)]\tLoss: 1.907183, mean accuracy last epoch: 0.799\n",
      "Train Epoch 99 [20480/69249 (30%)]\tLoss: 1.884099, mean accuracy last epoch: 0.799\n",
      "Train Epoch 99 [23040/69249 (33%)]\tLoss: 1.850388, mean accuracy last epoch: 0.799\n",
      "Train Epoch 99 [25600/69249 (37%)]\tLoss: 1.865069, mean accuracy last epoch: 0.799\n",
      "Train Epoch 99 [28160/69249 (41%)]\tLoss: 1.891266, mean accuracy last epoch: 0.799\n",
      "Train Epoch 99 [30720/69249 (44%)]\tLoss: 1.859774, mean accuracy last epoch: 0.800\n",
      "Train Epoch 99 [33280/69249 (48%)]\tLoss: 1.896493, mean accuracy last epoch: 0.800\n",
      "Train Epoch 99 [35840/69249 (52%)]\tLoss: 1.911846, mean accuracy last epoch: 0.800\n",
      "Train Epoch 99 [38400/69249 (55%)]\tLoss: 1.880083, mean accuracy last epoch: 0.800\n",
      "Train Epoch 99 [40960/69249 (59%)]\tLoss: 1.840132, mean accuracy last epoch: 0.800\n",
      "Train Epoch 99 [43520/69249 (63%)]\tLoss: 1.893603, mean accuracy last epoch: 0.800\n",
      "Train Epoch 99 [46080/69249 (66%)]\tLoss: 1.887961, mean accuracy last epoch: 0.800\n",
      "Train Epoch 99 [48640/69249 (70%)]\tLoss: 1.917341, mean accuracy last epoch: 0.800\n",
      "Train Epoch 99 [51200/69249 (74%)]\tLoss: 1.854238, mean accuracy last epoch: 0.800\n",
      "Train Epoch 99 [53760/69249 (77%)]\tLoss: 1.901529, mean accuracy last epoch: 0.800\n",
      "Train Epoch 99 [56320/69249 (81%)]\tLoss: 1.899979, mean accuracy last epoch: 0.800\n",
      "Train Epoch 99 [58880/69249 (85%)]\tLoss: 1.853664, mean accuracy last epoch: 0.800\n",
      "Train Epoch 99 [61440/69249 (89%)]\tLoss: 1.862987, mean accuracy last epoch: 0.800\n",
      "Train Epoch 99 [64000/69249 (92%)]\tLoss: 1.840353, mean accuracy last epoch: 0.800\n",
      "Train Epoch 99 [66560/69249 (96%)]\tLoss: 1.870923, mean accuracy last epoch: 0.800\n",
      "Train Epoch 99 [34830/69249 (100%)]\tLoss: 1.895747, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [0/69249 (0%)]\tLoss: 1.876381, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [2560/69249 (4%)]\tLoss: 1.910812, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [5120/69249 (7%)]\tLoss: 1.894690, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [7680/69249 (11%)]\tLoss: 1.887281, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [10240/69249 (15%)]\tLoss: 1.868820, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [12800/69249 (18%)]\tLoss: 1.851285, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [15360/69249 (22%)]\tLoss: 1.907201, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [17920/69249 (26%)]\tLoss: 1.899078, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [20480/69249 (30%)]\tLoss: 1.895646, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [23040/69249 (33%)]\tLoss: 1.873176, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [25600/69249 (37%)]\tLoss: 1.892134, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [28160/69249 (41%)]\tLoss: 1.889347, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [30720/69249 (44%)]\tLoss: 1.849875, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [33280/69249 (48%)]\tLoss: 1.852569, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [35840/69249 (52%)]\tLoss: 1.876388, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [38400/69249 (55%)]\tLoss: 1.880060, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [40960/69249 (59%)]\tLoss: 1.880753, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [43520/69249 (63%)]\tLoss: 1.903308, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [46080/69249 (66%)]\tLoss: 1.897185, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [48640/69249 (70%)]\tLoss: 1.923260, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [51200/69249 (74%)]\tLoss: 1.895321, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [53760/69249 (77%)]\tLoss: 1.886168, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [56320/69249 (81%)]\tLoss: 1.862687, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [58880/69249 (85%)]\tLoss: 1.885528, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [61440/69249 (89%)]\tLoss: 1.911212, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [64000/69249 (92%)]\tLoss: 1.903641, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [66560/69249 (96%)]\tLoss: 1.880298, mean accuracy last epoch: 0.800\n",
      "Train Epoch 100 [34830/69249 (100%)]\tLoss: 1.852694, mean accuracy last epoch: 0.800\n",
      "Epoch: 100, Mean Loss: 1.890462, Mean Accuracy: 0.799678, Training 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "accuracy_list = []\n",
    "mean_loss = 0\n",
    "mean_accuracy =0\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    for batch_idx, (data, target) in enumerate(GEX_dataloader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        loss_list.append(loss.item())\n",
    "        optimizer.step()\n",
    "        accuracy_list.append((output.argmax(1) == target.argmax(1)).type(torch.float).mean().item())\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Train Epoch {epoch} [{batch_idx * len(data)}/{len(GEX_dataloader.dataset)} ({100. * batch_idx / len(GEX_dataloader):.0f}%)]\\tLoss: {loss.item():.6f}, mean accuracy last epoch: {np.mean(accuracy_list[mean_accuracy:]):.3f}\")\n",
    "mean_loss = np.mean(loss_list)\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "print(f\"Epoch: {epoch}, Mean Loss: {mean_loss:.6f}, Mean Accuracy: {mean_accuracy:.6f}, Training {100. * epoch / epochs}% Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am trying to train a classifier on a dataset of cells with a single label. I am using the pytorch dataloader class to load the data into the model. I am using the following code to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier(\n",
       "  (cfc1): Linear(in_features=13431, out_features=20, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (cfc2): Linear(in_features=20, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5648e-17,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.887972116470337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eamonmcandrew/opt/anaconda3/envs/scINTEGRATION/lib/python3.9/site-packages/torch/_tensor_str.py:103: UserWarning:\n",
      "\n",
      "The operator 'aten::bitwise_and.Tensor_out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at  /Users/runner/miniforge3/conda-bld/pytorch-recipe_1664817783366/work/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8449829816818237\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.6840e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8838504552841187\n",
      "Target tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.8239e-10, 4.9540e-27, 4.2470e-24, 1.0000e+00, 8.1389e-07, 2.2309e-22,\n",
      "         3.6701e-21, 1.4629e-32, 8.9866e-26, 0.0000e+00, 0.0000e+00, 1.0769e-34,\n",
      "         4.6025e-37]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.856528878211975\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9983, 0.0000,\n",
      "         0.0000, 0.0000, 0.0017, 0.0000]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.848753809928894\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.5441e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3675e-26,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9227701425552368\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[7.7866e-28, 1.5912e-23, 2.2755e-35, 3.3904e-37, 3.5205e-35, 1.0000e+00,\n",
      "         1.8397e-33, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8566839694976807\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.7165e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8453092575073242\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.2106e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8727829456329346\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0925, 0.0000,\n",
      "         0.0000, 0.0000, 0.9075, 0.0000]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.829413652420044\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.4572e-29, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5379e-37,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8685524463653564\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 8.6818e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.876283884048462\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.9897e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8879092931747437\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[9.4776e-26, 3.8608e-19, 2.1656e-07, 6.2836e-31, 3.2960e-05, 2.6883e-11,\n",
      "         2.5548e-05, 7.2326e-08, 9.9977e-01, 1.7425e-04, 5.4323e-19, 7.9546e-27,\n",
      "         8.2508e-20]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8761587142944336\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.5388e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9998e-01,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.860777735710144\n",
      "Target tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 3.8603e-22, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.2432e-36, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8839319944381714\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.3351e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9947e-01,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.895719289779663\n",
      "Target tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 5.0756e-08, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.1039e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0348e-32,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8644955158233643\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8878943920135498\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4363e-26,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.876416563987732\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1781e-27, 0.0000e+00,\n",
      "         1.0000e+00, 9.3849e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0176e-38,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8802063465118408\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.880063533782959\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0711e-11, 2.6168e-15, 2.3117e-23, 2.1374e-16, 4.1718e-21, 1.0000e+00,\n",
      "         1.3935e-22, 3.1749e-36, 1.2578e-25, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8567993640899658\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 3.3264e-28, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9190499782562256\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.8942e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.880191445350647\n",
      "Target tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.1269e-34, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8764190673828125\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 1.7970e-35, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9266281127929688\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.5018e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.895652174949646\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7493e-36, 0.0000e+00,\n",
      "         1.0000e+00, 6.5942e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8760944604873657\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 1.5661e-34, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7155e-38,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8617910146713257\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5682e-38, 0.0000e+00,\n",
      "         1.0000e+00, 3.2681e-11, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8294880390167236\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9300e-28, 0.0000e+00,\n",
      "         1.0000e+00, 2.2076e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9077112674713135\n",
      "Target tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.1754e-32, 1.0000e+00, 0.0000e+00, 1.2481e-37, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8569045066833496\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[3.7038e-17, 6.6008e-16, 1.3725e-17, 3.3627e-27, 6.1239e-17, 1.0000e+00,\n",
      "         1.6428e-25, 0.0000e+00, 2.0914e-29, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8568189144134521\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.6121e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.880211353302002\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 6.6735e-20, 0.0000e+00, 6.6890e-14, 0.0000e+00,\n",
      "         1.4486e-10, 3.2218e-17, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8565326929092407\n",
      "Target tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.4228e-21, 1.0000e+00, 0.0000e+00, 1.3429e-37, 0.0000e+00,\n",
      "         5.6738e-38, 1.7873e-19, 0.0000e+00, 4.0335e-30, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8373239040374756\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0025, 0.0000,\n",
      "         0.0000, 0.0000, 0.9975, 0.0000]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8333711624145508\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.3430e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8645740747451782\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 7.2899e-37, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8722214698791504\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.1641e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8879375457763672\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.4933e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.856580138206482\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 2.4576e-20, 1.4168e-35, 1.0000e+00, 0.0000e+00,\n",
      "         3.0622e-37, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8448445796966553\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 2.3364e-17, 2.9926e-25, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.849112868309021\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 6.8449e-29, 3.5620e-38, 0.0000e+00, 6.1191e-36, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.856677770614624\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.6877e-37, 0.0000e+00,\n",
      "         1.0000e+00, 2.6247e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7284e-29,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8681349754333496\n",
      "Target tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.2169e-19, 1.9632e-37, 8.5338e-28, 1.0000e+00, 2.8468e-08, 0.0000e+00,\n",
      "         7.3307e-29, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1143e-32,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.872126579284668\n",
      "Target tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 8.6529e-18, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.0069e-22, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.864570140838623\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         7.9979e-31, 4.2863e-26, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.888002634048462\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1127e-19, 0.0000e+00,\n",
      "         1.0000e+00, 1.8769e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.868429183959961\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.3589e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8720957040786743\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.856892704963684\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 1.3532e-14, 1.6625e-26, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8836220502853394\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.1005e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8686527013778687\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.3944e-26, 1.5517e-28, 0.0000e+00, 1.5162e-29, 1.0000e+00,\n",
      "         4.0335e-31, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8179794549942017\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.6354e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.856709599494934\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 1.3241e-23, 0.0000e+00, 3.0263e-24, 0.0000e+00,\n",
      "         2.8827e-18, 1.9948e-28, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8606646060943604\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.9980e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9638e-04,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8607499599456787\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.1624e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8683489561080933\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 6.8659e-37, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8607550859451294\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0466, 0.0000,\n",
      "         0.0000, 0.0000, 0.9534, 0.0000]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.9075039625167847\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 5.0419e-18, 2.0909e-30, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8724172115325928\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0280, 0.0000,\n",
      "         0.0000, 0.0000, 0.9720, 0.0000]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.9152507781982422\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 3.9000e-36, 1.1187e-14, 0.0000e+00, 5.9375e-09, 0.0000e+00,\n",
      "         3.5976e-07, 6.0253e-12, 2.2838e-34, 1.0000e+00, 0.0000e+00, 2.9999e-38,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8485840559005737\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.903430700302124\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 2.6633e-35, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4170e-24,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.852734088897705\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.7746e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9035534858703613\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[3.1148e-26, 1.3651e-29, 0.0000e+00, 5.0956e-30, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8528578281402588\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8879854679107666\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.0152e-11, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8529905080795288\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0651e-12,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8998167514801025\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3784e-11,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8603951930999756\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0010, 0.0000,\n",
      "         0.0000, 0.0000, 0.9990, 0.0000]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.9115447998046875\n",
      "Target tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[6.7518e-17, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.7313e-21, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8255740404129028\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 3.6000e-37, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.1136e-31, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1392e-30,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8528438806533813\n",
      "Target tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[2.0664e-11, 1.0905e-23, 2.6871e-22, 1.0000e+00, 1.2321e-10, 3.4326e-34,\n",
      "         1.1735e-29, 0.0000e+00, 1.0911e-30, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8296183347702026\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 3.0141e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.7013e-30, 2.8825e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8686197996139526\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.6523e-36, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8761720657348633\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.0028e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8646678924560547\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.4001e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8918079137802124\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.5532e-28, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8916e-30,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8762853145599365\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8722785711288452\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[8.8813e-20, 4.3546e-15, 1.2974e-06, 1.8035e-23, 5.1745e-05, 2.2691e-09,\n",
      "         4.9220e-05, 3.4524e-07, 9.9975e-01, 1.4504e-04, 1.0752e-15, 6.7198e-21,\n",
      "         3.0704e-16]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8840898275375366\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 1.6516e-11, 1.2894e-18, 3.9559e-37, 5.9881e-36, 0.0000e+00,\n",
      "         8.2936e-25, 3.4255e-21, 4.5868e-31, 0.0000e+00, 0.0000e+00, 1.8685e-32,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8608864545822144\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.1896e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3924e-11,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8725769519805908\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 2.8960e-35, 0.0000e+00, 1.3186e-26, 0.0000e+00,\n",
      "         5.1690e-23, 7.4474e-37, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8567078113555908\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.1355e-35, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8645756244659424\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.0994e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8412165641784668\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.9104e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.845097303390503\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 4.3866e-09, 1.0540e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.1582e-24, 1.9198e-37, 0.0000e+00, 0.0000e+00, 6.6657e-37,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8917348384857178\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.829445242881775\n",
      "Target tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.9426e-30, 0.0000e+00, 0.0000e+00, 1.0000e+00, 9.9571e-21, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8371247053146362\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 1.6826e-14, 5.7777e-24, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8879092931747437\n",
      "Target tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 2.7973e-22, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.7851e-30, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9225447177886963\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.7703e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8840123414993286\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[2.3798e-11, 2.2802e-09, 1.6230e-05, 6.0479e-13, 9.7789e-05, 1.1873e-06,\n",
      "         1.2417e-04, 3.1341e-06, 9.9965e-01, 1.1194e-04, 4.8287e-11, 1.5554e-12,\n",
      "         3.3617e-11]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8841361999511719\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 7.5918e-20, 1.0426e-33, 1.0000e+00, 0.0000e+00,\n",
      "         2.7257e-29, 2.7891e-33, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9305548667907715\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.4497e-17, 1.3819e-13, 2.5186e-06, 1.0462e-20, 6.1158e-05, 1.1740e-08,\n",
      "         6.2758e-05, 6.1609e-07, 9.9974e-01, 1.3551e-04, 1.7904e-14, 1.0555e-18,\n",
      "         6.4609e-15]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8685706853866577\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 4.5344e-36, 3.0488e-35, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8567851781845093\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.9587e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8682873249053955\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.4605e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9996e-01,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8489956855773926\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 3.9463e-38, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1409e-30, 1.2062e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6850e-35,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.872645378112793\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.8727e-11, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.876067876815796\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 8.2448e-09, 1.3587e-26, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8959e-36,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8216723203659058\n",
      "Target tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[7.7043e-20, 0.0000e+00, 0.0000e+00, 1.0000e+00, 7.8872e-15, 0.0000e+00,\n",
      "         3.2880e-31, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.872382402420044\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.6330e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9114402532577515\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.4234e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8763971328735352\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.9113314151763916\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0943e-22,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.864349365234375\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 2.0886e-20, 2.5462e-29, 3.2504e-38, 1.2147e-36, 0.0000e+00,\n",
      "         6.5117e-26, 4.1907e-27, 4.8925e-37, 0.0000e+00, 0.0000e+00, 4.8473e-36,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8606898784637451\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.4789e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9999e-01,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8607083559036255\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8763402700424194\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.5162e-21, 2.7506e-16, 7.6370e-07, 1.1182e-25, 4.5278e-05, 6.1042e-10,\n",
      "         4.0536e-05, 2.1736e-07, 9.9976e-01, 1.5314e-04, 1.1368e-16, 1.1830e-22,\n",
      "         2.6930e-17]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8572566509246826\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8568494319915771\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 7.1921e-37, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.891558051109314\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[2.9318e-31, 7.0475e-23, 4.1519e-08, 8.2704e-38, 2.1740e-05, 4.4894e-13,\n",
      "         1.3951e-05, 1.7100e-08, 9.9976e-01, 2.0638e-04, 4.9390e-22, 2.7077e-32,\n",
      "         4.1895e-23]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8569440841674805\n",
      "Target tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.9493e-04, 6.5835e-17, 2.5493e-21, 9.9981e-01, 2.2060e-12, 4.7535e-23,\n",
      "         9.2456e-20, 2.3148e-33, 6.8686e-21, 0.0000e+00, 0.0000e+00, 4.0794e-38,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8491077423095703\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8684539794921875\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.9540e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8295066356658936\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6913e-25, 0.0000e+00,\n",
      "         1.0000e+00, 1.4478e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8800548315048218\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.7019e-31, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 2.8036e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.821607232093811\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.5357e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8762298822402954\n",
      "Target tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 6.3247e-22, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.1952e-25, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8646013736724854\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 1.1945e-15, 3.6468e-20, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.880270004272461\n",
      "Target tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[2.5037e-28, 0.0000e+00, 0.0000e+00, 1.0000e+00, 9.4994e-10, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8843693733215332\n",
      "Target tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.7168e-26, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.8529e-32, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8996161222457886\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 1.0003e-09, 1.7933e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8138912916183472\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 5.6409e-24, 4.7740e-23, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8643810749053955\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8565479516983032\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 1.2699e-22, 2.7044e-27, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8370250463485718\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 5.0294e-32, 0.0000e+00, 1.1276e-32, 0.0000e+00,\n",
      "         1.2742e-24, 2.7397e-36, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8646531105041504\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.6664e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8763314485549927\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 3.7551e-32, 0.0000e+00, 1.1077e-24, 0.0000e+00,\n",
      "         2.7252e-17, 7.6545e-26, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8607561588287354\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.6579e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8491861820220947\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.9871e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9998e-01,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8449459075927734\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 2.0666e-17, 3.2741e-10, 1.5905e-24, 2.9785e-37, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8724192380905151\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 1.6363e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8708000183105469\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.5609e-20, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6797e-36,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8331987857818604\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 2.7794e-24, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.1709e-30, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8682525157928467\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 8.4648e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8920286893844604\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 3.0662e-37, 0.0000e+00, 0.0000e+00, 9.9619e-24, 0.0000e+00,\n",
      "         1.0000e+00, 2.6440e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0227e-37,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8217763900756836\n",
      "Target tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.7369e-26, 9.3829e-12, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.9528e-26, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0211e-32,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.872353196144104\n",
      "Target tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[3.8004e-09, 0.0000e+00, 0.0000e+00, 1.0000e+00, 7.7542e-20, 2.0513e-30,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.860691785812378\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.9787e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.884181261062622\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8411662578582764\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.2786e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8842291831970215\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.1315e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8606065511703491\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.7509e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8802554607391357\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.1442e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.872220754623413\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 6.5603e-20, 0.0000e+00, 1.3816e-27, 0.0000e+00,\n",
      "         3.2791e-18, 8.6564e-26, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8684834241867065\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4836e-28, 0.0000e+00,\n",
      "         1.0000e+00, 2.1288e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8372397422790527\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8607370853424072\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0352, 0.0000,\n",
      "         0.0000, 0.0000, 0.9648, 0.0000]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.7864974737167358\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.3385e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8528246879577637\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0015, 0.0000,\n",
      "         0.0000, 0.0000, 0.9985, 0.0000]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8763772249221802\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 5.7250e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3574e-37,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.907297134399414\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8684909343719482\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 6.3023e-20, 2.7872e-30, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8333749771118164\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7391e-28, 0.0000e+00,\n",
      "         1.0000e+00, 5.1177e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.860780954360962\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 1.6694e-26, 1.9199e-35, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8370988368988037\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.5508e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9904e-01,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9153761863708496\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5160e-24,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8372821807861328\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8409031629562378\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.6539e-21, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8058887720108032\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.6515e-36, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.848939299583435\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.7182e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9192017316818237\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.2944e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8447952270507812\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 7.8294e-36, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.868251919746399\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 2.0895e-30, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.9782e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1831e-03,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.891667366027832\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[8.6167e-23, 3.9294e-17, 5.2574e-07, 3.1127e-27, 4.1213e-05, 2.4204e-10,\n",
      "         3.5355e-05, 1.5690e-07, 9.9976e-01, 1.5911e-04, 2.3345e-17, 6.8698e-24,\n",
      "         4.8479e-18]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8954075574874878\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.9311e-35, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8761719465255737\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3267e-36, 0.0000e+00,\n",
      "         1.0000e+00, 3.1012e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8804411888122559\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 2.3343e-30, 0.0000e+00, 2.1185e-18, 0.0000e+00,\n",
      "         3.8585e-13, 4.8065e-20, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8295387029647827\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.2607e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8682861328125\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8957107067108154\n",
      "Target tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 6.6053e-22, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.841193675994873\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.5497e-25, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9110368490219116\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0121e-18, 1.0000e+00, 3.9833e-26, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.5540e-30, 1.0583e-12, 7.8651e-32, 0.0000e+00, 0.0000e+00, 3.4749e-17,\n",
      "         2.0829e-35]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9074618816375732\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[2.8258e-20, 1.0000e+00, 3.0901e-30, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.8195e-27, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8959624767303467\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 8.6929e-23, 2.5449e-35, 1.0000e+00, 0.0000e+00,\n",
      "         5.0432e-24, 6.2760e-27, 0.0000e+00, 6.7900e-37, 0.0000e+00, 1.4856e-22,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8723927736282349\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 2.8944e-36, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.9632e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1500e-28,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.88405179977417\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.8852e-22, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8916372060775757\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 4.6264e-26, 2.6888e-24, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8685377836227417\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.8383e-38, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8959691524505615\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 4.3342e-23, 0.0000e+00, 2.6468e-19, 0.0000e+00,\n",
      "         1.9228e-13, 1.0936e-19, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8606624603271484\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.0774e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3301e-38,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9037529230117798\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[3.3172e-30, 1.5082e-24, 2.9817e-26, 5.4247e-34, 2.5529e-19, 1.0000e+00,\n",
      "         4.1235e-26, 0.0000e+00, 3.8160e-32, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.860539436340332\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.2750e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8647541999816895\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 4.4535e-18, 4.5199e-15, 3.7701e-18, 1.6093e-28, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 7.6364e-35, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8607197999954224\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0881e-20, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8920787572860718\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 2.9257e-17, 8.5650e-34, 1.0000e+00, 0.0000e+00,\n",
      "         8.3830e-28, 1.3955e-38, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8720266819000244\n",
      "Target tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[8.8222e-16, 2.1328e-31, 1.8780e-30, 1.0000e+00, 2.6031e-14, 2.9480e-36,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8369264602661133\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 7.0718e-31, 2.1700e-35, 0.0000e+00, 3.9663e-35, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.83747398853302\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[5.5441e-32, 2.3080e-19, 4.2751e-17, 6.6198e-36, 3.7041e-13, 1.0000e+00,\n",
      "         4.2600e-26, 0.0000e+00, 9.1439e-32, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9073548316955566\n",
      "Target tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 3.6744e-11, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.7417e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8803240060806274\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.1908e-28, 1.0000e+00, 1.9655e-30, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0572e-32, 9.2318e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0267e-26,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.942725658416748\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.5683e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8568525314331055\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.3505e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2087e-10,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8764680624008179\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.2781e-31, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8841880559921265\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.1559e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9999e-01,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8452353477478027\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.6511e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8643134832382202\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 1.8232e-23, 2.5270e-21, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.848667025566101\n",
      "Target tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.7890e-22, 7.7468e-11, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.2419e-36, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8607029914855957\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.1021e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9996e-01,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8763368129730225\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 1.7173e-38, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9073946475982666\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 1.1074e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9151748418807983\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.2317e-11, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8643707036972046\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8763478994369507\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 3.1276e-34, 4.6334e-20, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.884169340133667\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.4581e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8488696813583374\n",
      "Target tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[8.2441e-28, 0.0000e+00, 0.0000e+00, 1.0000e+00, 4.6745e-27, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8682314157485962\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 1.6245e-21, 1.0220e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8410731554031372\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 4.7394e-14, 1.1498e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8764829635620117\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.4525e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9991e-01,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8643465042114258\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.9541e-11, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8916701078414917\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 3.0361e-20, 2.8903e-21, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8608180284500122\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 4.9452e-18, 0.0000e+00, 1.2788e-18, 0.0000e+00,\n",
      "         1.4177e-15, 2.8455e-24, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8603966236114502\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 2.7912e-28, 0.0000e+00, 0.0000e+00, 4.7167e-30, 0.0000e+00,\n",
      "         1.0000e+00, 1.0509e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2987e-32,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8415433168411255\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.0923e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8407762050628662\n",
      "Target tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.7464e-20, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8447813987731934\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8917460441589355\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 3.1937e-19, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         1.6492e-21, 1.7468e-25, 0.0000e+00, 1.3859e-35, 0.0000e+00, 1.2561e-29,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8530057668685913\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 1.5965e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8724188804626465\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[4.2587e-34, 1.4139e-27, 2.2206e-35, 1.4377e-32, 2.3401e-26, 1.0000e+00,\n",
      "         2.5516e-32, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8997018337249756\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 1.9898e-26, 7.6780e-31, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8686014413833618\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.3693e-32, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9036824703216553\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 6.5363e-24, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8567936420440674\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 1.1064e-22, 2.4840e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8840432167053223\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 1.9786e-07, 2.2592e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.5844e-33, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6332e-36,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8955974578857422\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 6.9694e-24, 7.6248e-29, 1.0000e+00, 0.0000e+00,\n",
      "         1.9572e-24, 2.4246e-33, 7.5524e-36, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9033623933792114\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.8155e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8176013231277466\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.2125e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.860679268836975\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 3.9418e-19, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         3.4148e-27, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.9072715044021606\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 9.4089e-28, 1.1756e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8763377666473389\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8569865226745605\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 1.7329e-33, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8526878356933594\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9049, 0.0000,\n",
      "         0.0000, 0.0000, 0.0951, 0.0000]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8528556823730469\n",
      "Target tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[5.1163e-21, 0.0000e+00, 0.0000e+00, 1.0000e+00, 3.2282e-17, 0.0000e+00,\n",
      "         2.7309e-33, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8605504035949707\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.1312e-23, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8995673656463623\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 3.6679e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.899579644203186\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 2.0181e-24, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8566672801971436\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[9.9997e-01, 2.7163e-05, 1.8772e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         9.4976e-30, 5.0967e-20, 3.4660e-30, 0.0000e+00, 0.0000e+00, 2.5034e-24,\n",
      "         7.0987e-36]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8529657125473022\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0981e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9989e-01,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8685946464538574\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 2.1421e-11, 1.4135e-24, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.0771e-37, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8994605541229248\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 7.7900e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8528733253479004\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.8402e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8530153036117554\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 8.6237e-11, 2.4512e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.0728e-28, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0771e-37,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8489513397216797\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[5.5405e-28, 3.4874e-29, 0.0000e+00, 1.3824e-27, 6.2592e-29, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8528648614883423\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.9927e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8607752323150635\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 3.9496e-08, 5.6687e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.883870244026184\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 8.7594e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8648309707641602\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8255136013031006\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8802361488342285\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0101, 0.0000,\n",
      "         0.0000, 0.0000, 0.9899, 0.0000]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.9075349569320679\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 2.0951e-38, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8253787755966187\n",
      "Target tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 3.3876e-29, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8450411558151245\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 1.7838e-16, 2.7430e-37, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8918333053588867\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 1.4498e-11, 1.7836e-21, 1.9159e-36, 0.0000e+00, 0.0000e+00,\n",
      "         1.0985e-37, 2.5395e-36, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.868476152420044\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[3.0553e-32, 6.8119e-23, 8.8627e-08, 0.0000e+00, 5.5003e-05, 1.2192e-12,\n",
      "         3.1313e-05, 2.9252e-08, 9.9932e-01, 5.9016e-04, 9.4719e-23, 2.9469e-33,\n",
      "         1.3219e-23]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8372172117233276\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.4543e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9965e-01,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8491382598876953\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.6176e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.833402156829834\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>), Loss 1.8254228830337524\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1591e-26,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8762764930725098\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7935e-21, 0.0000e+00,\n",
      "         1.0000e+00, 7.9920e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.876255750656128\n",
      "Target tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.1903e-23, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8451695442199707\n",
      "Target tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 2.1729e-20, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         2.0059e-23, 1.2838e-15, 0.0000e+00, 3.8665e-31, 0.0000e+00, 1.4772e-30,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8802887201309204\n",
      "Target tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 7.2331e-29, 1.4574e-37, 0.0000e+00, 2.7501e-30, 1.0000e+00,\n",
      "         7.0894e-37, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.85286545753479\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 8.3246e-23, 1.6218e-19, 2.2464e-38, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8411636352539062\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.6362e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8664385080337524\n",
      "Target tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='mps:0'), Output tensor([[1.0000e+00, 6.0433e-12, 5.7417e-32, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.2941e-35, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8607969284057617\n",
      "Target tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='mps:0'), Output tensor([[0.0000e+00, 0.0000e+00, 1.0732e-25, 0.0000e+00, 8.3288e-14, 0.0000e+00,\n",
      "         7.0894e-12, 1.2038e-19, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]], device='mps:0', grad_fn=<SliceBackward0>), Loss 1.8823124170303345\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(GEX_dataloader):\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    print(f\"Target {target[:1]}, Output {output[:1]}, Loss {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7bd1782580>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise the loss\n",
    "\n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "    return pred\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_accuracy(model, data_loader):\n",
    "    accuracy_total = []\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        pred = predict(model, data).cpu()\n",
    "        actual = target.argmax(dim=1, keepdim=True).cpu()\n",
    "        accuracy_total.append(pred.eq(actual).sum().item() / len(pred))\n",
    "    return np.mean(accuracy_total)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8206059240824966"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_total_accuracy(model, GEX_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scdata = sc.read_h5ad(\"/Users/eamonmcandrew/Desktop/Single_cell_integration/Data/Multi-ome/GEX.h5ad\")\n",
    "# cell_data = pd.DataFrame(scdata.X.todense().T)\n",
    "# cell_cell_corr = pd.DataFrame(np.corrcoef(cell_data.values, rowvar=False), columns=cell_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell_cell_corr = cell_cell_corr.where(np.triu(np.ones(cell_cell_corr.shape), k=1).astype(np.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grad_cam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/eamonmcandrew/Desktop/Single_cell_integration/Expiriments/Classifier.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/eamonmcandrew/Desktop/Single_cell_integration/Expiriments/Classifier.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m grad_cam(model, GEX_dataloader)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grad_cam' is not defined"
     ]
    }
   ],
   "source": [
    "grad_cam(model, GEX_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('scINTEGRATION')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d226e3599a48bcd2e3e064e4b49e64b5c23bb1e3c85e4572c7816e0051bede7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
