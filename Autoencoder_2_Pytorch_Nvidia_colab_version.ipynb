{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"\n",
        "https://colab.research.google.com/drive/1uhuvoJViyXdhckE7EYHNSXchm9nzAMU2?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>\n",
        "\n"
      ],
      "metadata": {
        "id": "0zrXiqG0c3SM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O5L6g-FKlX2d",
        "outputId": "dc1f604d-4215-4687-bdfe-036e5006f4e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scanpy\n",
            "  Downloading scanpy-1.9.1-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 15.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: patsy in /usr/local/lib/python3.7/dist-packages (from scanpy) (0.5.3)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from scanpy) (1.3.5)\n",
            "Collecting anndata>=0.7.4\n",
            "  Downloading anndata-0.8.0-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (from scanpy) (5.5.0)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.7/dist-packages (from scanpy) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scanpy) (1.21.6)\n",
            "Collecting matplotlib>=3.4\n",
            "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 58.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba>=0.41.0 in /usr/local/lib/python3.7/dist-packages (from scanpy) (0.56.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from scanpy) (0.11.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from scanpy) (4.64.1)\n",
            "Collecting umap-learn>=0.3.10\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.7/dist-packages (from scanpy) (2.6.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from scanpy) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from scanpy) (1.0.2)\n",
            "Requirement already satisfied: importlib_metadata>=0.7 in /usr/local/lib/python3.7/dist-packages (from scanpy) (4.13.0)\n",
            "Requirement already satisfied: statsmodels>=0.10.0rc2 in /usr/local/lib/python3.7/dist-packages (from scanpy) (0.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from scanpy) (21.3)\n",
            "Collecting session-info\n",
            "  Downloading session_info-1.0.0.tar.gz (24 kB)\n",
            "Requirement already satisfied: h5py>=3 in /usr/local/lib/python3.7/dist-packages (from scanpy) (3.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from anndata>=0.7.4->scanpy) (4.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=3->scanpy) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=0.7->scanpy) (3.10.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4->scanpy) (3.0.9)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 43.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4->scanpy) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4->scanpy) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4->scanpy) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4->scanpy) (0.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.41.0->scanpy) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.41.0->scanpy) (0.39.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->scanpy) (2022.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4->scanpy) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->scanpy) (3.1.0)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 51.9 MB/s \n",
            "\u001b[?25hCollecting stdlib_list\n",
            "  Downloading stdlib_list-0.8.0-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: umap-learn, pynndescent, session-info\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=da3369b08296118e07a6101524c05391d6c1a81bed4ae3300d52aac00754c179\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/52/a5/1fd9e3e76a7ab34f134c07469cd6f16e27ef3a37aeff1fe821\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.8-py3-none-any.whl size=55512 sha256=b3556e615c79bdbafc440c174500d1b84b58c9b97f3393c965d8fd4c0d53b6b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/bc/eb/974072a56a7082a302f8b4be1ad6d21bf5019235c2eff65928\n",
            "  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8048 sha256=a0eb6b2757dd79e7da3c5efe2a2a027efab4aacf98c6677d86e76c32428b6ed2\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/ad/14/6a42359351a18337a8683854cfbba99dd782271f2d1767f87f\n",
            "Successfully built umap-learn pynndescent session-info\n",
            "Installing collected packages: fonttools, stdlib-list, pynndescent, matplotlib, umap-learn, session-info, anndata, scanpy\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed anndata-0.8.0 fonttools-4.38.0 matplotlib-3.5.3 pynndescent-0.5.8 scanpy-1.9.1 session-info-1.0.0 stdlib-list-0.8.0 umap-learn-0.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        " !pip install scanpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "metadata": {
        "id": "9qDwC6h2TgD6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0R1ODB9AldTh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c064c4c1-6afa-4391-8ca4-5e111fd2d1d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/scintegration/checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE-HkwvPOsWT",
        "outputId": "e389691b-1180-42d5-f551-81d61f628045"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/scintegration/checkpoints’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z48orueqlSAt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "import scanpy as sc\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import sklearn.preprocessing\n",
        "\n",
        "\n",
        "pio.renderers.default = \"notebook\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import platform\n",
        "platform.platform()\n",
        "if torch.cuda.is_available:\n",
        "     device = torch.device(\"cuda:0\")"
      ],
      "metadata": {
        "id": "17-IMKsyPFcl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ub6HOSG7Tum5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKpkPzD-PT0Q",
        "outputId": "aa4ee0a4-981c-40a2-a776-11eaf4892769"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ph2p2XgPlSAy"
      },
      "outputs": [],
      "source": [
        "scdata = sc.read_h5ad(\"/content/drive/MyDrive/scintegration/GEX.h5ad\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q_Vsd2y4lSAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7661a94f-dd6e-468b-fa27-6f46af2058bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69249, 13431)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "scdata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oeoSKb2LlSAz"
      },
      "outputs": [],
      "source": [
        "# sc.pp.log1p(scdata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Mz0GFAzslSBD"
      },
      "outputs": [],
      "source": [
        "class GEX_Dataset(torch.utils.data.Dataset):\n",
        "    \n",
        "      def __init__(self, data,  scaler = None, cat_var = None):\n",
        "          \n",
        "            self.data = data\n",
        "            \n",
        "            # we need to work with the dense matrix\n",
        "            self.values = data.X.todense()\n",
        "            \n",
        "            self.cat_var = cat_var\n",
        "            \n",
        "            # numerically encode the labels\n",
        "            self.cat_var_data =  torch.tensor(sklearn.preprocessing.LabelEncoder().fit_transform(self.data.obs[self.cat_var]))\n",
        "            \n",
        "            # scale the data according to user inpt to scaler argument\n",
        "            if scaler == \"Standard\":\n",
        "                self.scaled_values = torch.tensor(sklearn.preprocessing.StandardScaler().fit_transform(self.values))\n",
        "            elif scaler == \"MinMax\":\n",
        "                self.scaled_values = torch.tensor(sklearn.preprocessing.MinMaxScaler().fit_transform(self.values))\n",
        "            else:\n",
        "                self.scaled_values = torch.tensor(self.values)\n",
        "                \n",
        "    #   return the number of genes when called \n",
        "             \n",
        "      @property\n",
        "      def n_features(self):\n",
        "          return self.values.shape[1]\n",
        "          \n",
        "          \n",
        "    #  A dataset class needs the following two methods to work with the dataloader class     \n",
        "          \n",
        "    #   return the number of cells when called\n",
        "      def __len__(self):\n",
        "          return len(self.data)\n",
        "    \n",
        "    #  return an individual cell and its label when called\n",
        "      def __getitem__(self, idx):\n",
        "           return self.scaled_values[idx], self.cat_var_data[idx]\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3GHq6XzJlSBE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bddad0d6-5846-4ee7-8d6c-28d9781d945c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning:\n",
            "\n",
            "np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning:\n",
            "\n",
            "np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "\n"
          ]
        }
      ],
      "source": [
        "GEX_Dataset = GEX_Dataset(scdata, scaler = \"Standard\", cat_var = \"batch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Nx7VTZKPlSBE"
      },
      "outputs": [],
      "source": [
        "input_size = GEX_Dataset.n_features\n",
        "hidden_size = 128 # hidden dimension\n",
        "latent_size = 16  # latent vector dimension\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "lr = 1e-4\n",
        "train_loss = []\n",
        "log_interval = 20\n",
        "checkpoints = \"/content/drive/MyDrive/scintegration/checkpoints\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZX8oIritlSBF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b546df8-d6bf-46a1-ff59-9dbf9e0c2c87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13431"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "GEX_Dataset.n_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6SeEVIPBlSBF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "F-Beg6XUlSBF"
      },
      "outputs": [],
      "source": [
        "GEX_dataloader = DataLoader(GEX_Dataset, batch_size=batch_size, shuffle=True)\n",
        "GEX_dataloader_test = DataLoader(GEX_Dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BxtnLd2qlSBF"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self) :\n",
        "        super(VAE, self).__init__()\n",
        "        self.efc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.efc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.efc3_mu = nn.Linear(hidden_size, latent_size)\n",
        "        self.efc3_sigma = nn.Linear(hidden_size, latent_size)\n",
        "        \n",
        "        self.dfc1 = nn.Linear(latent_size, hidden_size)\n",
        "        self.dfc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.dfc3 = nn.Linear(hidden_size, input_size)\n",
        "        \n",
        "    def encode(self, x):\n",
        "        x = self.efc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.efc2(x)\n",
        "        x = F.relu(x)\n",
        "        mu = self.efc3_mu(x)\n",
        "        sigma = self.efc3_sigma(x)\n",
        "        return((mu,sigma))\n",
        "    \n",
        "    def reparametarise (self, mu, sigma):\n",
        "        std = torch.exp(0.5*sigma)\n",
        "        eps = torch.randn_like(std)\n",
        "        return(mu + eps*std)\n",
        "    \n",
        "    def decode(self, x):\n",
        "        x = self.dfc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dfc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dfc3(x)\n",
        "        x = torch.tanh(x)\n",
        "        return(x)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu, sigma = self.encode(x)\n",
        "        z = self.reparametarise(mu, sigma)\n",
        "        x_gen = self.decode(z)\n",
        "        return(x_gen, mu, sigma)\n",
        "      \n",
        "\n",
        "       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fyfDFYjklSBG"
      },
      "outputs": [],
      "source": [
        "def loss_function(x_gen, x, mu, sigma):\n",
        "    BCE = F.binary_cross_entropy_with_logits(x_gen, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + sigma - mu.pow(2) - torch.exp(sigma))\n",
        "    return(BCE + KLD)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GKcnz05Ic2FY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hEBSAOIylSBG"
      },
      "outputs": [],
      "source": [
        "def init_layers(layer):\n",
        "    if type(layer) == nn.Linear:\n",
        "        torch.nn.init.uniform_(layer.weight -0.08, 0.08)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2bnZ2wgSlSBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b78a7c8-4b0b-40ec-db8e-3bb94d469c39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VAE(\n",
              "  (efc1): Linear(in_features=13431, out_features=128, bias=True)\n",
              "  (efc2): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (efc3_mu): Linear(in_features=128, out_features=16, bias=True)\n",
              "  (efc3_sigma): Linear(in_features=128, out_features=16, bias=True)\n",
              "  (dfc1): Linear(in_features=16, out_features=128, bias=True)\n",
              "  (dfc2): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (dfc3): Linear(in_features=128, out_features=13431, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "vae = VAE()\n",
        "vae.to(device)\n",
        "vae = vae.apply(init_layers)\n",
        "optimizer = optim.Adam(vae.parameters(), lr=lr)\n",
        "vae.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "peKzW9nOlSBG"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mgK0-rzelSBG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v56b8sx1lSBH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e0abc7e-4008-4882-ea8d-85a00427693b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch 0 [0/69249] Loss: 1194281.125000\n",
            "Train epoch 0 [2560/69249] Loss: 1168533.375000\n",
            "Train epoch 0 [5120/69249] Loss: 1098465.250000\n",
            "Train epoch 0 [7680/69249] Loss: 910684.687500\n",
            "Train epoch 0 [10240/69249] Loss: 691564.250000\n",
            "Train epoch 0 [12800/69249] Loss: 593120.062500\n",
            "Train epoch 0 [15360/69249] Loss: 562120.812500\n",
            "Train epoch 0 [17920/69249] Loss: 572966.062500\n",
            "Train epoch 0 [20480/69249] Loss: 550089.625000\n",
            "Train epoch 0 [23040/69249] Loss: 561971.000000\n",
            "Train epoch 0 [25600/69249] Loss: 559031.750000\n",
            "Train epoch 0 [28160/69249] Loss: 556502.375000\n",
            "Train epoch 0 [30720/69249] Loss: 531279.250000\n",
            "Train epoch 0 [33280/69249] Loss: 559358.500000\n",
            "Train epoch 0 [35840/69249] Loss: 537757.750000\n",
            "Train epoch 0 [38400/69249] Loss: 537992.375000\n",
            "Train epoch 0 [40960/69249] Loss: 532498.625000\n",
            "Train epoch 0 [43520/69249] Loss: 551549.312500\n",
            "Train epoch 0 [46080/69249] Loss: 532538.687500\n",
            "Train epoch 0 [48640/69249] Loss: 532012.375000\n",
            "Train epoch 0 [51200/69249] Loss: 552131.562500\n",
            "Train epoch 0 [53760/69249] Loss: 549563.125000\n",
            "Train epoch 0 [56320/69249] Loss: 539008.750000\n",
            "Train epoch 0 [58880/69249] Loss: 511899.781250\n",
            "Train epoch 0 [61440/69249] Loss: 537645.187500\n",
            "Train epoch 0 [64000/69249] Loss: 556521.312500\n",
            "Train epoch 0 [66560/69249] Loss: 528030.812500\n",
            "Train epoch 0 [69120/69249] Loss: 556563.250000\n",
            "Train epoch 1 [0/69249] Loss: 544856.500000\n",
            "Train epoch 1 [2560/69249] Loss: 536853.000000\n",
            "Train epoch 1 [5120/69249] Loss: 559990.562500\n",
            "Train epoch 1 [7680/69249] Loss: 545939.875000\n",
            "Train epoch 1 [10240/69249] Loss: 547718.187500\n",
            "Train epoch 1 [12800/69249] Loss: 545369.625000\n",
            "Train epoch 1 [15360/69249] Loss: 549351.812500\n",
            "Train epoch 1 [17920/69249] Loss: 534031.562500\n",
            "Train epoch 1 [20480/69249] Loss: 523824.437500\n",
            "Train epoch 1 [23040/69249] Loss: 536943.687500\n",
            "Train epoch 1 [25600/69249] Loss: 547069.750000\n",
            "Train epoch 1 [28160/69249] Loss: 554564.000000\n",
            "Train epoch 1 [30720/69249] Loss: 537146.937500\n",
            "Train epoch 1 [33280/69249] Loss: 570852.625000\n",
            "Train epoch 1 [35840/69249] Loss: 537292.000000\n",
            "Train epoch 1 [38400/69249] Loss: 550532.687500\n",
            "Train epoch 1 [40960/69249] Loss: 552831.125000\n",
            "Train epoch 1 [43520/69249] Loss: 523190.812500\n",
            "Train epoch 1 [46080/69249] Loss: 520304.218750\n",
            "Train epoch 1 [48640/69249] Loss: 535962.000000\n",
            "Train epoch 1 [51200/69249] Loss: 546200.125000\n",
            "Train epoch 1 [53760/69249] Loss: 528564.125000\n",
            "Train epoch 1 [56320/69249] Loss: 529695.812500\n",
            "Train epoch 1 [58880/69249] Loss: 541699.812500\n",
            "Train epoch 1 [61440/69249] Loss: 536813.062500\n",
            "Train epoch 1 [64000/69249] Loss: 525907.625000\n",
            "Train epoch 1 [66560/69249] Loss: 533667.812500\n",
            "Train epoch 1 [69120/69249] Loss: 528069.875000\n",
            "Train epoch 2 [0/69249] Loss: 544789.125000\n",
            "Train epoch 2 [2560/69249] Loss: 548712.000000\n",
            "Train epoch 2 [5120/69249] Loss: 543027.562500\n",
            "Train epoch 2 [7680/69249] Loss: 520497.937500\n",
            "Train epoch 2 [10240/69249] Loss: 535332.250000\n",
            "Train epoch 2 [12800/69249] Loss: 532583.437500\n",
            "Train epoch 2 [15360/69249] Loss: 546992.750000\n",
            "Train epoch 2 [17920/69249] Loss: 539037.937500\n",
            "Train epoch 2 [20480/69249] Loss: 537235.312500\n",
            "Train epoch 2 [23040/69249] Loss: 511908.406250\n",
            "Train epoch 2 [25600/69249] Loss: 538207.437500\n",
            "Train epoch 2 [28160/69249] Loss: 536654.562500\n",
            "Train epoch 2 [30720/69249] Loss: 553581.375000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for epoch in range(epochs+1):\n",
        "\tfor batch_idx, (data, _) in enumerate(GEX_dataloader):\n",
        "\t\tdata = data.to(device)\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tx_gen, mu, sigma = vae(data)\n",
        "\t\tloss = loss_function(x_gen, data, mu, sigma)\n",
        "\t\tif torch.isnan(loss):\n",
        "\t\t\tprint(f\"Nan Loss @ Epoch {epoch} Batch {batch_idx}\")\n",
        "\t\t\tbreak\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\ttrain_loss.append(loss.item())\n",
        "\t\tif batch_idx % log_interval == 0:\n",
        "\t\t\tprint(f\"Train epoch {epoch} [{batch_idx*len(data)}/{len(GEX_dataloader.dataset)}] Loss: {loss.item():.6f}\")\n",
        "\t\t\n",
        "\t\ttorch.save(vae.state_dict(), os.path.join(checkpoints, f'vae_epoch_{epoch}.pt'))\n",
        "\t\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hq-RMWGlSBH"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(model, optimizer, filename):\n",
        "    print(f'Loading checkpoint {filename} for model {model}')\n",
        "    model.load_state_dict(torch.load(filename))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSyuC8eTlSBH"
      },
      "outputs": [],
      "source": [
        "load_checkpoint(vae, optimizer, os.path.join(checkpoints, 'vae_epoch_4.pt'))\n",
        "vae.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gg79EYfMlSBH"
      },
      "outputs": [],
      "source": [
        "def get_embeddings(vae, dataloader):\n",
        "    with torch.no_grad():\n",
        "        embeddings = []\n",
        "        labels = []\n",
        "        for batch, label in dataloader:\n",
        "            batch = batch.to(device)\n",
        "            _, mu, _ = vae(batch)\n",
        "            embeddings.append(mu.cpu().numpy())\n",
        "            labels.append(label.cpu().numpy())\n",
        "        embeddings = np.concatenate(embeddings)\n",
        "        labels = np.concatenate(labels)\n",
        "        return embeddings, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPv6KsH0lSBH"
      },
      "outputs": [],
      "source": [
        "embeddings, labels = get_embeddings(vae, GEX_dataloader_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL8wgawNlSBH"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usdY5071lSBH"
      },
      "outputs": [],
      "source": [
        "def plot_embeddings(dataframe, color_by=None, title=None):\n",
        "    fig = px.scatter(dataframe, x=0, y=1, color=color_by, title=title)\n",
        "    fig.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_xHsZU2lSBH"
      },
      "outputs": [],
      "source": [
        "dataframe = pd.DataFrame(embeddings, index = labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6URXEhWxlSBH"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(scdata.obsm[\"GEX_X_pca\"], x=0, y=1, color=scdata.obs[\"batch\"], template=\"simple_white\")\n",
        "fig = fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=1400,\n",
        "    height=1000)\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VG6J9EclSBI"
      },
      "outputs": [],
      "source": [
        "plot_embeddings(dataframe, color_by=dataframe.index, title=\"VAE Embeddings\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcf4MMBylSBI"
      },
      "outputs": [],
      "source": [
        "scdata.obsm[\"VAE_z\"] = embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tYi0rzZlSBI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoGp2j40lSBI"
      },
      "outputs": [],
      "source": [
        "scdata.obsm[\"VAE_z\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4OAIUfqlSBI"
      },
      "outputs": [],
      "source": [
        "sc.pp.neighbors(scdata, use_rep=\"VAE_z\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybMrD_53lSBI"
      },
      "outputs": [],
      "source": [
        "sc.tl.umap(scdata, min_dist=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVE3jfnMlSBI"
      },
      "outputs": [],
      "source": [
        "scdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "370CqtIllSBI"
      },
      "outputs": [],
      "source": [
        "sc.pl.umap(scdata, color=\"cell_type\", wspace=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRmeLnyylSBI"
      },
      "outputs": [],
      "source": [
        "sc.pl.umap(scdata, color=[\"batch\", \"cell_type\"], wspace=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzfGUaCtlSBJ"
      },
      "outputs": [],
      "source": [
        "def decode_embeddings(vae, embeddings):\n",
        "    with torch.no_grad():\n",
        "        embeddings = torch.tensor(embeddings).to(device)\n",
        "        x_gen = vae.decode(embeddings)\n",
        "        return x_gen.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YW08z2VJlSBJ"
      },
      "outputs": [],
      "source": [
        "scdata.obsm[\"VAE_x\"] = decode_embeddings(vae, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2KvDu8jlSBJ"
      },
      "outputs": [],
      "source": [
        "sc.pp.neighbors(scdata, use_rep=\"VAE_x\", n_neighbors=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNAkBXo9lSBJ"
      },
      "outputs": [],
      "source": [
        "sc.tl.umap(scdata, min_dist=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK5KKILTlSBJ"
      },
      "outputs": [],
      "source": [
        "sc.pl.umap(scdata, color=\"batch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YF8SVVLhlSBJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3DEdlGflSBJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmcM3BaSlSBJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqFhwVPwlSBJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7hZHOomlSBJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('scINTEGRATION')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "1d226e3599a48bcd2e3e064e4b49e64b5c23bb1e3c85e4572c7816e0051bede7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}