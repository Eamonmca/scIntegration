{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f9c643aa7f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import scanpy as sc\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "def get_device_and_gmount():\n",
    "    # Get the operating system and version\n",
    "    os = platform.system()\n",
    "    version = platform.release()\n",
    "\n",
    "    # Get the machine's architecture\n",
    "    arch = platform.machine()\n",
    "\n",
    "    # Set the default renderer based on the operating system\n",
    "    if os == 'Darwin':\n",
    "        pio.renderers.default = 'notebook'\n",
    "        print(\"Using Apple MPS on Macbook Pro\")\n",
    "    \n",
    "    elif os == 'Linux' and version == '18.04':\n",
    "        pio.renderers.default = 'colab'\n",
    "        print(\"Using Colab on Linux\")\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        path = '/content/drive/My Drive/Colab Notebooks/Experiments/'\n",
    "\n",
    "    # Set the device based on the machine's architecture\n",
    "    if arch == 'x86_64':\n",
    "        device = torch.device('mps') if os == 'Darwin' else torch.device('cuda')\n",
    "        gmount = True if os == 'Linux' else False\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        gmount = False\n",
    "\n",
    "    print(\"Using device:\", device)\n",
    "    \n",
    "    return device, gmount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple MPS on Macbook Pro\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device, gmount = get_device_and_gmount()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gmount:\n",
    "    scdata = sc.read_h5ad(\"/content/gdrive/MyDrive/scintegration/GEX.h5ad\")\n",
    "    \n",
    "scdata = sc.read_h5ad(\"/Users/eamonmcandrew/Desktop/Single_cell_integration/Data/Multi-ome/GEX.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 69249 × 13431\n",
       "    obs: 'GEX_pct_counts_mt', 'GEX_n_counts', 'GEX_n_genes', 'GEX_size_factors', 'GEX_phase', 'ATAC_nCount_peaks', 'ATAC_atac_fragments', 'ATAC_reads_in_peaks_frac', 'ATAC_blacklist_fraction', 'ATAC_nucleosome_signal', 'cell_type', 'batch', 'ATAC_pseudotime_order', 'GEX_pseudotime_order', 'Samplename', 'Site', 'DonorNumber', 'Modality', 'VendorLot', 'DonorID', 'DonorAge', 'DonorBMI', 'DonorBloodType', 'DonorRace', 'Ethnicity', 'DonorGender', 'QCMeds', 'DonorSmoker'\n",
       "    var: 'feature_types', 'gene_id'\n",
       "    uns: 'ATAC_gene_activity_var_names', 'dataset_id', 'genome', 'organism'\n",
       "    obsm: 'ATAC_gene_activity', 'ATAC_lsi_full', 'ATAC_lsi_red', 'ATAC_umap', 'GEX_X_pca', 'GEX_X_umap'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Darwin'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platform.system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(data, test_size, random_state, split_criteria):\n",
    "    \"\"\"\n",
    "    Splits the data into train and test sets stratified by the batch column\n",
    "    \"\"\"\n",
    "    train = []\n",
    "    test = []\n",
    "    for batch in data.obs[split_criteria].unique():\n",
    "        batch_data = data[data.obs[split_criteria] == batch]\n",
    "        batch_train, batch_test = sklearn.model_selection.train_test_split(batch_data, test_size=test_size, random_state=random_state)\n",
    "        batch_train, batch_test = list(batch_train.obs.index), list(batch_test.obs.index)\n",
    "        train.extend(batch_train)\n",
    "        test.extend(batch_test)\n",
    "        \n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = stratified_split(scdata, 0.2, 9000, split_criteria='cell_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55392, 13857)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = scdata[train]\n",
    "test_data = scdata[test]\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gmount == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    path = '/content/drive/My Drive/Colab Notebooks/Experiments/' \n",
    "    scdata = sc.read_h5ad(\"/content/gdrive/MyDrive/scintegration/GEX.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meamomc\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"Single Cell Omics integration\", entity=\"scintegration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GEX_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, scaler=None, cat_var=None, label_encoder=None):\n",
    "        self.data = data\n",
    "        self.values = np.asarray(data.X.todense())\n",
    "        self.cat_var = cat_var\n",
    "\n",
    "        label_encoder_functions = {\n",
    "            \"numeric\": lambda: torch.tensor(sklearn.preprocessing.LabelEncoder().fit_transform(self.data.obs[self.cat_var]), dtype=torch.long),\n",
    "            \"range_map\": lambda: sklearn.preprocessing.LabelEncoder().fit_transform(self.data.obs[self.cat_var]).reshape(-1, 1),\n",
    "            \"one_hot\": lambda: sklearn.preprocessing.OneHotEncoder().fit_transform(sklearn.preprocessing.LabelEncoder().fit_transform(self.data.obs[self.cat_var]).reshape(-1, 1)).toarray()\n",
    "        }\n",
    "\n",
    "        if label_encoder in label_encoder_functions:\n",
    "            cat_var_data = label_encoder_functions[label_encoder]()\n",
    "            if label_encoder == \"range_map\":\n",
    "                cat_var_data = torch.tensor(sklearn.preprocessing.MinMaxScaler().fit_transform(cat_var_data), dtype=torch.float32)\n",
    "            elif label_encoder == \"one_hot\":\n",
    "                cat_var_data = torch.tensor(cat_var_data, dtype=torch.float32)\n",
    "        else:\n",
    "            cat_var_data = None\n",
    "        self.cat_var_data = cat_var_data\n",
    "\n",
    "        scaler_functions = {\n",
    "            \"Standard\": lambda: sklearn.preprocessing.StandardScaler().fit_transform(self.values),\n",
    "            \"MinMax\": lambda: sklearn.preprocessing.MinMaxScaler().fit_transform(self.values)\n",
    "        }\n",
    "\n",
    "        if scaler in scaler_functions:\n",
    "            self.scaled_values = torch.tensor(scaler_functions[scaler](), dtype=torch.float32)\n",
    "        else:\n",
    "            self.scaled_values = torch.tensor(self.values, dtype=torch.float32)\n",
    "\n",
    "    @property\n",
    "    def n_features(self):\n",
    "        return self.values.shape[1]\n",
    "\n",
    "    @property\n",
    "    def n_catagories(self):\n",
    "        return self.cat_var_data.shape[1] if self.cat_var_data is not None else 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.scaled_values[idx], self.cat_var_data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "    def __init__(self, input_size, dropout, hidden_sizes, output_size):\n",
    "        super(classifier, self).__init__()\n",
    "        # Create a list of Linear layers with the specified hidden sizes\n",
    "        self.hidden_layers = [nn.Linear(input_size, hidden_size) for hidden_size in hidden_sizes]\n",
    "        # Create a BatchNorm1d layer for each hidden layer\n",
    "        self.batch_norm_layers = [nn.BatchNorm1d(hidden_size) for hidden_size in hidden_sizes]\n",
    "        # Create a Dropout layer for each hidden layer\n",
    "        self.dropout_layers = [nn.Dropout(dropout) for _ in hidden_sizes]\n",
    "        # Create a Linear layer for the output\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Loop through the hidden layers\n",
    "        for hidden_layer, batch_norm_layer, dropout_layer in zip(self.hidden_layers, self.batch_norm_layers, self.dropout_layers):\n",
    "            # Apply the hidden layer, batch norm layer, and dropout layer\n",
    "            x = hidden_layer(x)\n",
    "            x = batch_norm_layer(x)\n",
    "            x = F.relu(x)\n",
    "            x = dropout_layer(x)\n",
    "        # Apply the output layer and return the output\n",
    "        x = self.output_layer(x)\n",
    "        x = F.softmax(x, dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, GEX_dataloader_train, model, optimizer, criterion):\n",
    "    # Set the model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize lists to store the losses and accuracies for each batch\n",
    "    epoch_loss_list = []\n",
    "    epoch_accuracy_list = []\n",
    "    \n",
    "    # Iterate over the batches in the dataloader\n",
    "    for batch_idx, (data, target) in enumerate(GEX_dataloader_train):\n",
    "        # Move the data and target tensors to the specified device (GPU)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # Clear the gradients of all optimized parameters\n",
    "        optimizer.zero_grad()\n",
    "        # Feed the data through the model and get the output\n",
    "        output = model(data)\n",
    "        # Calculate the loss using the specified loss function\n",
    "        loss = criterion(output, target)\n",
    "        # Calculate the accuracy by comparing the model's predictions to the ground truth labels\n",
    "        accuracy = (output.argmax(1) == target.argmax(1)).type(torch.float).mean().item()\n",
    "        # Backpropagate the loss to update the model's parameters\n",
    "        loss.backward()\n",
    "        # Update the model's parameters using the optimizer\n",
    "        optimizer.step()\n",
    "        # Append the loss and accuracy for this batch to the corresponding lists\n",
    "        epoch_loss_list.append(loss.item())\n",
    "        epoch_accuracy_list.append(accuracy)\n",
    "        \n",
    "    # Calculate the mean loss and accuracy for the entire epoch\n",
    "    epoch_loss = np.mean(epoch_loss_list)\n",
    "    epoch_accuracy = np.mean(epoch_accuracy_list)\n",
    "    \n",
    "    # Return the epoch loss and accuracy\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_epoch(epoch, GEX_Dataset_test, model, optimizer, criterion, confusion = False):\n",
    "    # Set the model to eval mode\n",
    "    model.eval()\n",
    "    # Tell PyTorch not to track gradients while evaluating the model\n",
    "    with torch.no_grad():\n",
    "        # Initialize lists to store the losses and accuracies for each batch\n",
    "        epoch_loss_list = []\n",
    "        epoch_accuracy_list = []\n",
    "        \n",
    "        # Iterate over the batches in the dataloader\n",
    "        for batch_idx, (data, target) in enumerate(GEX_Dataset_test):\n",
    "            # Move the data and target tensors to the specified device (GPU)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # Feed the data through the model and get the output\n",
    "            output = model(data)\n",
    "            # Calculate the loss using the specified loss function\n",
    "            loss = criterion(output, target)\n",
    "            # Calculate the accuracy by comparing the model's predictions to the ground truth labels\n",
    "            accuracy = (output.argmax(1) == target.argmax(1)).type(torch.float).mean().item()\n",
    "            # Append the loss and accuracy for this batch to the corresponding lists\n",
    "            epoch_loss_list.append(loss.item())\n",
    "            epoch_accuracy_list.append(accuracy)\n",
    "            \n",
    "            if confusion: \n",
    "            # Calculate and log the confusion matrix for this batch\n",
    "                ground_truth_class_ids = target.argmax(1).cpu().numpy()\n",
    "                predicted_class_ids = output.argmax(1).cpu().numpy()\n",
    "                wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None, y_true=ground_truth_class_ids, preds=predicted_class_ids, class_names=scdata.obs[\"batch\"].unique())})\n",
    "        \n",
    "        # Calculate the mean loss and accuracy for the entire epoch\n",
    "        epoch_loss = np.mean(epoch_loss_list)\n",
    "        epoch_accuracy = np.mean(epoch_accuracy_list)\n",
    "        \n",
    "    # Return the epoch loss and accuracy\n",
    "    return epoch_loss, epoch_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 6gdsiwyr\n",
      "Sweep URL: https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/6gdsiwyr\n"
     ]
    }
   ],
   "source": [
    "sweep_configuration = {\n",
    "    'method': 'grid',\n",
    "    'name': 'sweep',\n",
    "    'metric': {\n",
    "        'goal': 'maximize', \n",
    "        'name': 'val_acc'\n",
    "\t\t},\n",
    "    'parameters': {\n",
    "        'batch_size': {'value': 512},\n",
    "        'epochs': {'value' : 500},\n",
    "        'lr': {'value' : 0.00361},\n",
    "        'random_seed': {'value': 9000},\n",
    "        'dropout': {'values': [0,0.1, 0.2, 0.]},\n",
    "        'hidden_sizes': {'values': [[256, 128, 64], [256, 128, 64], [256, 128, 64], [256, 128, 64]]},\n",
    "        'split_criteria': {'value': 'cell_type'},\n",
    "        'eval_size_percentage' : {'value': 0.2}\n",
    "        \n",
    "        \n",
    "}}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_configuration, project=\"Single Cell Omics integration\", entity=\"scintegration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = wandb.config = {\n",
    "#   \"lr\" : 0.00361,\n",
    "#   \"epochs\": 100,\n",
    "#   \"batch_size\": 1024,\n",
    "#   \"dropout\": 0.2,\n",
    "#   \"hidden_size\": 20,\n",
    "#   \"random_seed\": 9000,\n",
    "#   \"split_criteria\": \"batch\",\n",
    "#   \"eval_size_percentage\" : 0.2,\n",
    "  \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(config = None):\n",
    "  \n",
    "  \n",
    "    if config is not None:\n",
    "        config = wandb.config\n",
    "        run = wandb.init(project=\"Single Cell Omics integration\", entity=\"scintegration\", config=config)\n",
    "    else:\n",
    "      run = wandb.init(project=\"Single Cell Omics integration\", entity=\"scintegration\")\n",
    "\n",
    "    # Load the learning rate, batch size, epochs, random seed, dropout, and hidden size from the wandb configuration\n",
    "    lr = wandb.config.lr\n",
    "    batch_size = wandb.config.batch_size\n",
    "    epochs = wandb.config.epochs\n",
    "    random_seed = wandb.config.random_seed\n",
    "    dropout = wandb.config.dropout\n",
    "    # hidden_size = wandb.config.hidden_size\n",
    "    split_criteria = wandb.config.split_criteria\n",
    "    eval_size_percentage = wandb.config.eval_size_percentage\n",
    "    hidden_sizes = wandb.config.hidden_sizes\n",
    "    \n",
    "    # train test split\n",
    "    train, test = stratified_split(scdata, 0.2, wandb.config.random_seed, split_criteria=split_criteria)\n",
    "    train_data = scdata[train]\n",
    "    test_data = scdata[test]\n",
    "    \n",
    "    # create datasets\n",
    "    GEX_Dataset_train = GEX_Dataset(train_data, scaler = \"Standard\", cat_var = \"batch\", label_encoder = \"one_hot\")\n",
    "    GEX_Dataset_test = GEX_Dataset(test_data, scaler = \"Standard\", cat_var = \"batch\", label_encoder = \"one_hot\")\n",
    "    \n",
    "    # Create dataloaders for the training and eval datasets\n",
    "    GEX_dataloader_train = torch.utils.data.DataLoader(GEX_Dataset_train, batch_size = wandb.config.batch_size, shuffle = True)\n",
    "    GEX_dataloader_test = torch.utils.data.DataLoader(GEX_Dataset_test, batch_size = wandb.config.batch_size, shuffle = True)\n",
    "    \n",
    "    input_size = GEX_Dataset_train.n_features\n",
    "    output_size = GEX_Dataset_train.n_catagories\n",
    "    \n",
    "\n",
    "    # Instantiate the model, optimizer, and criterion outside the for loop\n",
    "    model = classifier(input_size=input_size, dropout=dropout, hidden_sizes=hidden_sizes, output_size=output_size)\n",
    "    \n",
    "\n",
    "    # Move the model to the specified device (e.g. Nvidia GPU, Apple MPS, CPU)\n",
    "    model.to(device)\n",
    "\n",
    "    # Instantiate the Adam optimizer with the specified learning rate\n",
    "    optimizer = optim.Adam(model.parameters(), lr=wandb.config.lr)\n",
    "\n",
    "    # Instantiate the Cross Entropy loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Train the model for one epoch\n",
    "        train_loss, train_acc = train_one_epoch(epoch, GEX_dataloader_train, model, optimizer, criterion)\n",
    "\n",
    "        # Evaluate the model on the eval dataset\n",
    "        val_loss, val_acc = evaluate_one_epoch(epoch, GEX_dataloader_test, model, optimizer, criterion)\n",
    "        \n",
    "        # If the validation accuracy is the best seen so far, save the model's weights and biases to wandb\n",
    "        if val_acc > best_val_acc:\n",
    "          best_val_acc = val_acc\n",
    "          wandb.save('model_best_val_acc.h5')\n",
    "\n",
    "\n",
    "        # Log the epoch, train accuracy, train loss, validation accuracy, and validation loss to wandb\n",
    "        wandb.log({\n",
    "          'epoch': epoch, \n",
    "          'train_acc': train_acc,\n",
    "          'train_loss': train_loss, \n",
    "          'val_acc': val_acc, \n",
    "          'val_loss': val_loss\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: evm45n22 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teval_size_percentage: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [256, 128, 64]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_seed: 9000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit_criteria: cell_type\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meamomc\u001b[0m (\u001b[33mscintegration\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eamonmcandrew/Desktop/Single_cell_integration/Github/scIntegration/wandb/run-20221202_233137-evm45n22</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/evm45n22\" target=\"_blank\">iconic-sweep-1</a></strong> to <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/6gdsiwyr\" target=\"_blank\">https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/6gdsiwyr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">iconic-sweep-1</strong>: <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/evm45n22\" target=\"_blank\">https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/evm45n22</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221202_233137-evm45n22/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run evm45n22 errored: RuntimeError('Placeholder storage has not been allocated on MPS device!')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run evm45n22 errored: RuntimeError('Placeholder storage has not been allocated on MPS device!')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 78ex0eiy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teval_size_percentage: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [256, 128, 64]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_seed: 9000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit_criteria: cell_type\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eamonmcandrew/Desktop/Single_cell_integration/Github/scIntegration/wandb/run-20221202_233158-78ex0eiy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/78ex0eiy\" target=\"_blank\">eager-sweep-2</a></strong> to <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/6gdsiwyr\" target=\"_blank\">https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/6gdsiwyr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7c38b8384c45a5883a2ba1c733e62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.214218…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eager-sweep-2</strong>: <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/78ex0eiy\" target=\"_blank\">https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/78ex0eiy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221202_233158-78ex0eiy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 78ex0eiy errored: RuntimeError('Placeholder storage has not been allocated on MPS device!')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 78ex0eiy errored: RuntimeError('Placeholder storage has not been allocated on MPS device!')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5226p0v8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teval_size_percentage: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_sizes: [256, 128, 64]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_seed: 9000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit_criteria: cell_type\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eamonmcandrew/Desktop/Single_cell_integration/Github/scIntegration/wandb/run-20221202_233219-5226p0v8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/5226p0v8\" target=\"_blank\">jolly-sweep-3</a></strong> to <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/6gdsiwyr\" target=\"_blank\">https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/6gdsiwyr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f088719ee8bd43f5a9673b0b49155b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.214366…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">jolly-sweep-3</strong>: <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/5226p0v8\" target=\"_blank\">https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/5226p0v8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221202_233219-5226p0v8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 5226p0v8 errored: RuntimeError('Placeholder storage has not been allocated on MPS device!')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 5226p0v8 errored: RuntimeError('Placeholder storage has not been allocated on MPS device!')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train_func, count=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('scINTEGRATION')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d226e3599a48bcd2e3e064e4b49e64b5c23bb1e3c85e4572c7816e0051bede7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
