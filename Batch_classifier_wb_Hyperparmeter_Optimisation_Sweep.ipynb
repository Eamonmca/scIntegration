{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fc510f77970>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import scanpy as sc\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "def get_device_and_gmount():\n",
    "    # Get the operating system and version\n",
    "    os = platform.system()\n",
    "    version = platform.release()\n",
    "\n",
    "    # Get the machine's architecture\n",
    "    arch = platform.machine()\n",
    "\n",
    "    # Set the default renderer based on the operating system\n",
    "    if os == 'Darwin':\n",
    "        pio.renderers.default = 'notebook'\n",
    "        print(\"Using Apple MPS on Macbook Pro\")\n",
    "    \n",
    "    elif os == 'Linux' and version == '18.04':\n",
    "        pio.renderers.default = 'colab'\n",
    "        print(\"Using Colab on Linux\")\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        path = '/content/drive/My Drive/Colab Notebooks/Experiments/'\n",
    "\n",
    "    # Set the device based on the machine's architecture\n",
    "    if arch == 'x86_64':\n",
    "        device = torch.device('mps') if os == 'Darwin' else torch.device('cuda')\n",
    "        gmount = True if os == 'Linux' else False\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        gmount = False\n",
    "\n",
    "    print(\"Using device:\", device)\n",
    "    \n",
    "    return device, gmount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple MPS on Macbook Pro\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device, gmount = get_device_and_gmount()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gmount:\n",
    "    scdata = sc.read_h5ad(\"/content/gdrive/MyDrive/scintegration/GEX.h5ad\")\n",
    "    \n",
    "scdata = sc.read_h5ad(\"/Users/eamonmcandrew/Desktop/Single_cell_integration/Data/Multi-ome/GEX.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 69249 × 13431\n",
       "    obs: 'GEX_pct_counts_mt', 'GEX_n_counts', 'GEX_n_genes', 'GEX_size_factors', 'GEX_phase', 'ATAC_nCount_peaks', 'ATAC_atac_fragments', 'ATAC_reads_in_peaks_frac', 'ATAC_blacklist_fraction', 'ATAC_nucleosome_signal', 'cell_type', 'batch', 'ATAC_pseudotime_order', 'GEX_pseudotime_order', 'Samplename', 'Site', 'DonorNumber', 'Modality', 'VendorLot', 'DonorID', 'DonorAge', 'DonorBMI', 'DonorBloodType', 'DonorRace', 'Ethnicity', 'DonorGender', 'QCMeds', 'DonorSmoker'\n",
       "    var: 'feature_types', 'gene_id'\n",
       "    uns: 'ATAC_gene_activity_var_names', 'dataset_id', 'genome', 'organism'\n",
       "    obsm: 'ATAC_gene_activity', 'ATAC_lsi_full', 'ATAC_lsi_red', 'ATAC_umap', 'GEX_X_pca', 'GEX_X_umap'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Darwin'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platform.system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(data, test_size, random_state, split_criteria):\n",
    "    \"\"\"\n",
    "    Splits the data into train and test sets stratified by the batch column\n",
    "    \"\"\"\n",
    "    train = []\n",
    "    test = []\n",
    "    for batch in data.obs[split_criteria].unique():\n",
    "        batch_data = data[data.obs[split_criteria] == batch]\n",
    "        batch_train, batch_test = sklearn.model_selection.train_test_split(batch_data, test_size=test_size, random_state=random_state)\n",
    "        batch_train, batch_test = list(batch_train.obs.index), list(batch_test.obs.index)\n",
    "        train.extend(batch_train)\n",
    "        test.extend(batch_test)\n",
    "        \n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = stratified_split(scdata, 0.2, 9000, split_criteria='cell_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55392, 13857)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = scdata[train]\n",
    "test_data = scdata[test]\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gmount == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    path = '/content/drive/My Drive/Colab Notebooks/Experiments/' \n",
    "    scdata = sc.read_h5ad(\"/content/gdrive/MyDrive/scintegration/GEX.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meamomc\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"Single Cell Omics integration\", entity=\"scintegration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GEX_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, scaler=None, cat_var=None, label_encoder=None):\n",
    "        self.data = data\n",
    "        self.values = np.asarray(data.X.todense())\n",
    "        self.cat_var = cat_var\n",
    "\n",
    "        label_encoder_functions = {\n",
    "            \"numeric\": lambda: torch.tensor(sklearn.preprocessing.LabelEncoder().fit_transform(self.data.obs[self.cat_var]), dtype=torch.long),\n",
    "            \"range_map\": lambda: sklearn.preprocessing.LabelEncoder().fit_transform(self.data.obs[self.cat_var]).reshape(-1, 1),\n",
    "            \"one_hot\": lambda: sklearn.preprocessing.OneHotEncoder().fit_transform(sklearn.preprocessing.LabelEncoder().fit_transform(self.data.obs[self.cat_var]).reshape(-1, 1)).toarray()\n",
    "        }\n",
    "\n",
    "        if label_encoder in label_encoder_functions:\n",
    "            cat_var_data = label_encoder_functions[label_encoder]()\n",
    "            if label_encoder == \"range_map\":\n",
    "                cat_var_data = torch.tensor(sklearn.preprocessing.MinMaxScaler().fit_transform(cat_var_data), dtype=torch.float32)\n",
    "            elif label_encoder == \"one_hot\":\n",
    "                cat_var_data = torch.tensor(cat_var_data, dtype=torch.float32)\n",
    "        else:\n",
    "            cat_var_data = None\n",
    "        self.cat_var_data = cat_var_data\n",
    "\n",
    "        scaler_functions = {\n",
    "            \"Standard\": lambda: sklearn.preprocessing.StandardScaler().fit_transform(self.values),\n",
    "            \"MinMax\": lambda: sklearn.preprocessing.MinMaxScaler().fit_transform(self.values)\n",
    "        }\n",
    "\n",
    "        if scaler in scaler_functions:\n",
    "            self.scaled_values = torch.tensor(scaler_functions[scaler](), dtype=torch.float32)\n",
    "        else:\n",
    "            self.scaled_values = torch.tensor(self.values, dtype=torch.float32)\n",
    "\n",
    "    @property\n",
    "    def n_features(self):\n",
    "        return self.values.shape[1]\n",
    "\n",
    "    @property\n",
    "    def n_catagories(self):\n",
    "        return self.cat_var_data.shape[1] if self.cat_var_data is not None else 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.scaled_values[idx], self.cat_var_data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "    def __init__(self, input_size, dropout, hidden_size, output_size):\n",
    "        super(classifier, self).__init__()\n",
    "        self.cfc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.cfc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cfc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.cfc2(x)\n",
    "        x = F.softmax(x, dim = 1)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, GEX_dataloader_train, model, optimizer, criterion):\n",
    "    # Set the model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize lists to store the losses and accuracies for each batch\n",
    "    epoch_loss_list = []\n",
    "    epoch_accuracy_list = []\n",
    "    \n",
    "    # Iterate over the batches in the dataloader\n",
    "    for batch_idx, (data, target) in enumerate(GEX_dataloader_train):\n",
    "        # Move the data and target tensors to the specified device (GPU)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # Clear the gradients of all optimized parameters\n",
    "        optimizer.zero_grad()\n",
    "        # Feed the data through the model and get the output\n",
    "        output = model(data)\n",
    "        # Calculate the loss using the specified loss function\n",
    "        loss = criterion(output, target)\n",
    "        # Calculate the accuracy by comparing the model's predictions to the ground truth labels\n",
    "        accuracy = (output.argmax(1) == target.argmax(1)).type(torch.float).mean().item()\n",
    "        # Backpropagate the loss to update the model's parameters\n",
    "        loss.backward()\n",
    "        # Update the model's parameters using the optimizer\n",
    "        optimizer.step()\n",
    "        # Append the loss and accuracy for this batch to the corresponding lists\n",
    "        epoch_loss_list.append(loss.item())\n",
    "        epoch_accuracy_list.append(accuracy)\n",
    "        \n",
    "    # Calculate the mean loss and accuracy for the entire epoch\n",
    "    epoch_loss = np.mean(epoch_loss_list)\n",
    "    epoch_accuracy = np.mean(epoch_accuracy_list)\n",
    "    \n",
    "    # Return the epoch loss and accuracy\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_epoch(epoch, GEX_Dataset_test, model, optimizer, criterion, confusion = False):\n",
    "    # Set the model to eval mode\n",
    "    model.eval()\n",
    "    # Tell PyTorch not to track gradients while evaluating the model\n",
    "    with torch.no_grad():\n",
    "        # Initialize lists to store the losses and accuracies for each batch\n",
    "        epoch_loss_list = []\n",
    "        epoch_accuracy_list = []\n",
    "        \n",
    "        # Iterate over the batches in the dataloader\n",
    "        for batch_idx, (data, target) in enumerate(GEX_Dataset_test):\n",
    "            # Move the data and target tensors to the specified device (GPU)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # Feed the data through the model and get the output\n",
    "            output = model(data)\n",
    "            # Calculate the loss using the specified loss function\n",
    "            loss = criterion(output, target)\n",
    "            # Calculate the accuracy by comparing the model's predictions to the ground truth labels\n",
    "            accuracy = (output.argmax(1) == target.argmax(1)).type(torch.float).mean().item()\n",
    "            # Append the loss and accuracy for this batch to the corresponding lists\n",
    "            epoch_loss_list.append(loss.item())\n",
    "            epoch_accuracy_list.append(accuracy)\n",
    "            \n",
    "            if confusion: \n",
    "            # Calculate and log the confusion matrix for this batch\n",
    "                ground_truth_class_ids = target.argmax(1).cpu().numpy()\n",
    "                predicted_class_ids = output.argmax(1).cpu().numpy()\n",
    "                wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None, y_true=ground_truth_class_ids, preds=predicted_class_ids, class_names=scdata.obs[\"batch\"].unique())})\n",
    "        \n",
    "        # Calculate the mean loss and accuracy for the entire epoch\n",
    "        epoch_loss = np.mean(epoch_loss_list)\n",
    "        epoch_accuracy = np.mean(epoch_accuracy_list)\n",
    "        \n",
    "    # Return the epoch loss and accuracy\n",
    "    return epoch_loss, epoch_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: dq9iljc6\n",
      "Sweep URL: https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/dq9iljc6\n"
     ]
    }
   ],
   "source": [
    "sweep_configuration = {\n",
    "    'method': 'grid',\n",
    "    'name': 'sweep',\n",
    "    'metric': {\n",
    "        'goal': 'maximize', \n",
    "        'name': 'val_acc'\n",
    "\t\t},\n",
    "    'parameters': {\n",
    "        'batch_size': {'value': 1024},\n",
    "        'epochs': {'value' : 200},\n",
    "        'lr': {'value' : 0.00361},\n",
    "        'random_seed': {'values': [9000, 9001, 9002, 9003, 9004, 9005, 9006, 9007, 9008, 9009]},\n",
    "        'dropout': {'value': 0.2},\n",
    "        'hidden_size': {'value': 20},\n",
    "        'split_criteria': {'value': 'cell_type'},\n",
    "        'eval_size_percentage' : {'value': 0.2}\n",
    "        \n",
    "        \n",
    "}}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_configuration, project=\"Single Cell Omics integration\", entity=\"scintegration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = wandb.config = {\n",
    "#   \"lr\" : 0.00361,\n",
    "#   \"epochs\": 100,\n",
    "#   \"batch_size\": 1024,\n",
    "#   \"dropout\": 0.2,\n",
    "#   \"hidden_size\": 20,\n",
    "#   \"random_seed\": 9000,\n",
    "#   \"split_criteria\": \"batch\",\n",
    "#   \"eval_size_percentage\" : 0.2,\n",
    "  \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(config = None):\n",
    "  \n",
    "  \n",
    "    if config is not None:\n",
    "        config = wandb.config\n",
    "        run = wandb.init(project=\"Single Cell Omics integration\", entity=\"scintegration\", config=config)\n",
    "    else:\n",
    "      run = wandb.init(project=\"Single Cell Omics integration\", entity=\"scintegration\")\n",
    "\n",
    "    # Load the learning rate, batch size, epochs, random seed, dropout, and hidden size from the wandb configuration\n",
    "    lr = wandb.config.lr\n",
    "    batch_size = wandb.config.batch_size\n",
    "    epochs = wandb.config.epochs\n",
    "    random_seed = wandb.config.random_seed\n",
    "    dropout = wandb.config.dropout\n",
    "    hidden_size = wandb.config.hidden_size\n",
    "    split_criteria = wandb.config.split_criteria\n",
    "    eval_size_percentage = wandb.config.eval_size_percentage\n",
    "    \n",
    "    \n",
    "    # train test split\n",
    "    train, test = stratified_split(scdata, 0.2, wandb.config.random_seed, split_criteria=split_criteria)\n",
    "    train_data = scdata[train]\n",
    "    test_data = scdata[test]\n",
    "    \n",
    "    # create datasets\n",
    "    GEX_Dataset_train = GEX_Dataset(train_data, scaler = \"Standard\", cat_var = \"batch\", label_encoder = \"one_hot\")\n",
    "    GEX_Dataset_test = GEX_Dataset(test_data, scaler = \"Standard\", cat_var = \"batch\", label_encoder = \"one_hot\")\n",
    "    \n",
    "    # Create dataloaders for the training and eval datasets\n",
    "    GEX_dataloader_train = torch.utils.data.DataLoader(GEX_Dataset_train, batch_size = wandb.config.batch_size, shuffle = True)\n",
    "    GEX_dataloader_test = torch.utils.data.DataLoader(GEX_Dataset_test, batch_size = wandb.config.batch_size, shuffle = True)\n",
    "    \n",
    "    input_size = GEX_Dataset_train.n_features\n",
    "    output_size = GEX_Dataset_train.n_catagories\n",
    "    \n",
    "\n",
    "    # Instantiate the model, optimizer, and criterion outside the for loop\n",
    "    model = classifier(input_size=input_size, dropout=dropout, hidden_size=hidden_size, output_size=output_size)\n",
    "\n",
    "    # Move the model to the specified device (e.g. Nvidia GPU, Apple MPS, CPU)\n",
    "    model.to(device)\n",
    "\n",
    "    # Instantiate the Adam optimizer with the specified learning rate\n",
    "    optimizer = optim.Adam(model.parameters(), lr=wandb.config.lr)\n",
    "\n",
    "    # Instantiate the Cross Entropy loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Train the model for one epoch\n",
    "        train_loss, train_acc = train_one_epoch(epoch, GEX_dataloader_train, model, optimizer, criterion)\n",
    "\n",
    "        # Evaluate the model on the eval dataset\n",
    "        val_loss, val_acc = evaluate_one_epoch(epoch, GEX_dataloader_test, model, optimizer, criterion)\n",
    "        \n",
    "        # If the validation accuracy is the best seen so far, save the model's weights and biases to wandb\n",
    "        if val_acc > best_val_acc:\n",
    "          best_val_acc = val_acc\n",
    "          wandb.save('model_best_val_acc.h5')\n",
    "\n",
    "\n",
    "        # Log the epoch, train accuracy, train loss, validation accuracy, and validation loss to wandb\n",
    "        wandb.log({\n",
    "          'epoch': epoch, \n",
    "          'train_acc': train_acc,\n",
    "          'train_loss': train_loss, \n",
    "          'val_acc': val_acc, \n",
    "          'val_loss': val_loss\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: boirulzz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teval_size_percentage: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_seed: 9000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit_criteria: cell_type\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meamomc\u001b[0m (\u001b[33mscintegration\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eamonmcandrew/Desktop/Single_cell_integration/Github/scIntegration/wandb/run-20221202_200113-boirulzz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/boirulzz\" target=\"_blank\">lucky-sweep-1</a></strong> to <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/dq9iljc6\" target=\"_blank\">https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/dq9iljc6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ac7a32a6fe4203921ac17ad43d8b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.206123…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▆▇▇████████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁███▇█▇▇▆▇▇▇▆▇▇▆▇▆▆██▇▇▆▇▇▇▆▇▇▅▆▇▆▇▇▆▇▇▇</td></tr><tr><td>val_loss</td><td>█▂▂▁▂▁▂▂▂▂▁▂▂▂▂▂▂▂▃▁▁▁▂▂▂▂▁▂▂▂▃▂▂▂▂▂▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>200</td></tr><tr><td>train_acc</td><td>0.89851</td></tr><tr><td>train_loss</td><td>1.79054</td></tr><tr><td>val_acc</td><td>0.85023</td></tr><tr><td>val_loss</td><td>1.83871</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lucky-sweep-1</strong>: <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/boirulzz\" target=\"_blank\">https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/boirulzz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221202_200113-boirulzz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run boirulzz errored: TypeError(\"evaluate_one_epoch() got an unexpected keyword argument 'log_conf_mat'\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run boirulzz errored: TypeError(\"evaluate_one_epoch() got an unexpected keyword argument 'log_conf_mat'\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8oss2qf3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teval_size_percentage: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_seed: 9001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit_criteria: cell_type\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eamonmcandrew/Desktop/Single_cell_integration/Github/scIntegration/wandb/run-20221202_200915-8oss2qf3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/8oss2qf3\" target=\"_blank\">smart-sweep-2</a></strong> to <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/dq9iljc6\" target=\"_blank\">https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/dq9iljc6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅████████████████▇█████████████▇███████</td></tr><tr><td>val_loss</td><td>█▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>200</td></tr><tr><td>train_acc</td><td>0.9344</td></tr><tr><td>train_loss</td><td>1.75476</td></tr><tr><td>val_acc</td><td>0.86551</td></tr><tr><td>val_loss</td><td>1.82309</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">smart-sweep-2</strong>: <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/8oss2qf3\" target=\"_blank\">https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/8oss2qf3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221202_200915-8oss2qf3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 8oss2qf3 errored: TypeError(\"evaluate_one_epoch() got an unexpected keyword argument 'log_conf_mat'\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 8oss2qf3 errored: TypeError(\"evaluate_one_epoch() got an unexpected keyword argument 'log_conf_mat'\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: krjft6ox with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teval_size_percentage: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_seed: 9002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit_criteria: cell_type\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eamonmcandrew/Desktop/Single_cell_integration/Github/scIntegration/wandb/run-20221202_201655-krjft6ox</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/krjft6ox\" target=\"_blank\">golden-sweep-3</a></strong> to <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/dq9iljc6\" target=\"_blank\">https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/dq9iljc6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6dc750727e64f50aac96ad6fec640a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.205941…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆████████████</td></tr><tr><td>train_loss</td><td>█▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▆▇▇▇▇█▇██████</td></tr><tr><td>val_loss</td><td>█▇▇▇▇▇▆▇▇▇▇▇▇▆▆▇▇▆▇▆▆▆▆▆▇▆▇▃▂▂▁▂▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>200</td></tr><tr><td>train_acc</td><td>0.89828</td></tr><tr><td>train_loss</td><td>1.7908</td></tr><tr><td>val_acc</td><td>0.84279</td></tr><tr><td>val_loss</td><td>1.8462</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">golden-sweep-3</strong>: <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/krjft6ox\" target=\"_blank\">https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/krjft6ox</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221202_201655-krjft6ox/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run krjft6ox errored: TypeError(\"evaluate_one_epoch() got an unexpected keyword argument 'log_conf_mat'\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run krjft6ox errored: TypeError(\"evaluate_one_epoch() got an unexpected keyword argument 'log_conf_mat'\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: al5r5zfm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teval_size_percentage: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_seed: 9003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit_criteria: cell_type\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eamonmcandrew/Desktop/Single_cell_integration/Github/scIntegration/wandb/run-20221202_202452-al5r5zfm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/al5r5zfm\" target=\"_blank\">dulcet-sweep-4</a></strong> to <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/dq9iljc6\" target=\"_blank\">https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/dq9iljc6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8620d744034a9d8a01ca1065f8b4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.205828…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▆▇▇█▇██████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁█████▇▇▇█▇▇▇▇▇█▇██▇█████▇█████████▇█▇██</td></tr><tr><td>val_loss</td><td>█▂▁▁▁▁▂▂▂▁▂▁▂▁▂▁▂▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>200</td></tr><tr><td>train_acc</td><td>0.89986</td></tr><tr><td>train_loss</td><td>1.78915</td></tr><tr><td>val_acc</td><td>0.85227</td></tr><tr><td>val_loss</td><td>1.83659</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dulcet-sweep-4</strong>: <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/al5r5zfm\" target=\"_blank\">https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/al5r5zfm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221202_202452-al5r5zfm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run al5r5zfm errored: TypeError(\"evaluate_one_epoch() got an unexpected keyword argument 'log_conf_mat'\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run al5r5zfm errored: TypeError(\"evaluate_one_epoch() got an unexpected keyword argument 'log_conf_mat'\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 45sviw7m with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teval_size_percentage: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_seed: 9004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplit_criteria: cell_type\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eamonmcandrew/Desktop/Single_cell_integration/Github/scIntegration/wandb/run-20221202_203322-45sviw7m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/45sviw7m\" target=\"_blank\">bumbling-sweep-5</a></strong> to <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/dq9iljc6\" target=\"_blank\">https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/sweeps/dq9iljc6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7cc7e0884442d5911f3b6bf5aa41d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.205903…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇█████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁█▇▇▇▅▆▆▆▆▆▅▆▆▆▆▆█▆▆▇▆▆▆▅▆▄▅▅▅▄▅▆▆▆▆▆▅▆▅</td></tr><tr><td>val_loss</td><td>█▂▂▂▂▃▂▃▂▂▂▃▂▂▂▂▂▁▂▂▂▂▂▂▃▂▃▃▃▃▃▃▂▂▂▂▂▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>200</td></tr><tr><td>train_acc</td><td>0.9586</td></tr><tr><td>train_loss</td><td>1.7305</td></tr><tr><td>val_acc</td><td>0.89412</td></tr><tr><td>val_loss</td><td>1.79465</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">bumbling-sweep-5</strong>: <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/45sviw7m\" target=\"_blank\">https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/45sviw7m</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221202_203322-45sviw7m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 45sviw7m errored: TypeError(\"evaluate_one_epoch() got an unexpected keyword argument 'log_conf_mat'\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 45sviw7m errored: TypeError(\"evaluate_one_epoch() got an unexpected keyword argument 'log_conf_mat'\")\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train_func, count=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('scINTEGRATION')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d226e3599a48bcd2e3e064e4b49e64b5c23bb1e3c85e4572c7816e0051bede7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
