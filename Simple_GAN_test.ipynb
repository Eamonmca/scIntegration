{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7ff28aa511c0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import scanpy as sc\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "def get_device_and_gmount():\n",
    "    # Get the operating system and version\n",
    "    os = platform.system()\n",
    "    version = platform.release()\n",
    "\n",
    "    # Get the machine's architecture\n",
    "    arch = platform.machine()\n",
    "\n",
    "    # Set the default renderer based on the operating system\n",
    "    if os == 'Darwin':\n",
    "        pio.renderers.default = 'notebook'\n",
    "        print(\"Using Apple MPS on Macbook Pro\")\n",
    "    \n",
    "    elif os == 'Linux' and version == '18.04':\n",
    "        pio.renderers.default = 'colab'\n",
    "        print(\"Using Colab on Linux\")\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        path = '/content/drive/My Drive/Colab Notebooks/Experiments/'\n",
    "\n",
    "    # Set the device based on the machine's architecture\n",
    "    if arch == 'x86_64':\n",
    "        device = torch.device('mps') if os == 'Darwin' else torch.device('cuda')\n",
    "        gmount = True if os == 'Linux' else False\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        gmount = False\n",
    "\n",
    "    print(\"Using device:\", device)\n",
    "    \n",
    "    return device, gmount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple MPS on Macbook Pro\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device, gmount = get_device_and_gmount()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gmount:\n",
    "    scdata = sc.read_h5ad(\"/content/gdrive/MyDrive/scintegration/GEX.h5ad\")\n",
    "    \n",
    "scdata = sc.read_h5ad(\"/Users/eamonmcandrew/Desktop/Single_cell_integration/Data/Multi-ome/GEX.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(data, test_size, random_state, split_criteria):\n",
    "    \"\"\"\n",
    "    Splits the data into train and test sets stratified by the batch column\n",
    "    \"\"\"\n",
    "    train = []\n",
    "    test = []\n",
    "    for batch in data.obs[split_criteria].unique():\n",
    "        batch_data = data[data.obs[split_criteria] == batch]\n",
    "        batch_train, batch_test = sklearn.model_selection.train_test_split(batch_data, test_size=test_size, random_state=random_state)\n",
    "        batch_train, batch_test = list(batch_train.obs.index), list(batch_test.obs.index)\n",
    "        train.extend(batch_train)\n",
    "        test.extend(batch_test)\n",
    "        \n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gmount == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    path = '/content/drive/My Drive/Colab Notebooks/Experiments/' \n",
    "    scdata = sc.read_h5ad(\"/content/gdrive/MyDrive/scintegration/GEX.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meamomc\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GEX_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, scaler=None, cat_var=None, label_encoder=None):\n",
    "        self.data = data\n",
    "        self.values = np.asarray(data.X.todense())\n",
    "        self.cat_var = cat_var\n",
    "\n",
    "        label_encoder_functions = {\n",
    "            \"numeric\": lambda: torch.tensor(sklearn.preprocessing.LabelEncoder().fit_transform(self.data.obs[self.cat_var]), dtype=torch.long),\n",
    "            \"range_map\": lambda: sklearn.preprocessing.LabelEncoder().fit_transform(self.data.obs[self.cat_var]).reshape(-1, 1),\n",
    "            \"one_hot\": lambda: sklearn.preprocessing.OneHotEncoder().fit_transform(sklearn.preprocessing.LabelEncoder().fit_transform(self.data.obs[self.cat_var]).reshape(-1, 1)).toarray()\n",
    "        }\n",
    "\n",
    "        if label_encoder in label_encoder_functions:\n",
    "            cat_var_data = label_encoder_functions[label_encoder]()\n",
    "            if label_encoder == \"range_map\":\n",
    "                cat_var_data = torch.tensor(sklearn.preprocessing.MinMaxScaler().fit_transform(cat_var_data), dtype=torch.float32)\n",
    "            elif label_encoder == \"one_hot\":\n",
    "                cat_var_data = torch.tensor(cat_var_data, dtype=torch.float32)\n",
    "        else:\n",
    "            cat_var_data = None\n",
    "        self.cat_var_data = cat_var_data\n",
    "\n",
    "        scaler_functions = {\n",
    "            \"Standard\": lambda: sklearn.preprocessing.StandardScaler().fit_transform(self.values),\n",
    "            \"MinMax\": lambda: sklearn.preprocessing.MinMaxScaler().fit_transform(self.values)\n",
    "        }\n",
    "\n",
    "        if scaler in scaler_functions:\n",
    "            self.scaled_values = torch.tensor(scaler_functions[scaler](), dtype=torch.float32)\n",
    "        else:\n",
    "            self.scaled_values = torch.tensor(self.values, dtype=torch.float32)\n",
    "\n",
    "    @property\n",
    "    def n_features(self):\n",
    "        return self.values.shape[1]\n",
    "\n",
    "    @property\n",
    "    def n_catagories(self):\n",
    "        return self.cat_var_data.shape[1] if self.cat_var_data is not None else 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.scaled_values[idx], self.cat_var_data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEX_Dataset = GEX_Dataset(scdata, scaler=\"Standard\", cat_var=\"batch\", label_encoder=\"one_hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.map2(x)\n",
    "        x = F.elu(x)\n",
    "        return self.map3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the discriminator network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.elu(self.map2(x))\n",
    "        return F.sigmoid(self.map3(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GAN model\n",
    "class GAN(nn.Module):\n",
    "    def __init__(self, generator, discriminator):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.discriminator(self.generator(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13431"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GEX_Dataset.n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of the generator and discriminator networks\n",
    "generator = Generator(input_size=100, hidden_size=256, output_size=GEX_Dataset.n_features)\n",
    "discriminator = Discriminator(input_size=GEX_Dataset.n_features, hidden_size=256, output_size=1)\n",
    "\n",
    "# Create instance of the GAN model\n",
    "gan = GAN(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(gan.parameters(), lr=0.0002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meamomc\u001b[0m (\u001b[33mscintegration\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eamonmcandrew/Desktop/Single_cell_integration/Expiriments/wandb/run-20221203_104615-1kr5myvf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration/runs/1kr5myvf\" target=\"_blank\">pretty-dream-243</a></strong> to <a href=\"https://wandb.ai/scintegration/Single%20Cell%20Omics%20integration\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# Train the GAN model\n",
    "run = wandb.init(project=\"Single Cell Omics integration\", entity=\"scintegration\")\n",
    "GEX_dataloader_train = torch.utils.data.DataLoader(GEX_Dataset, batch_size = 128, shuffle = True)\n",
    "for epoch in range(100):\n",
    "    for data, _ in GEX_dataloader_train:\n",
    "        # Generate fake data\n",
    "        noise = torch.randn(data.shape[0], 100)\n",
    "        fake_data = gan.generator(noise)\n",
    "\n",
    "        # Train the discriminator\n",
    "        optimizer.zero_grad()\n",
    "        pred_real = gan.discriminator(data)\n",
    "        pred_fake = gan.discriminator(fake_data.detach())\n",
    "        loss_real = loss_fn(pred_real, torch.ones_like(pred_real))\n",
    "        loss_fake = loss_fn(pred_fake, torch.zeros_like(pred_fake))\n",
    "        loss_discriminator = (loss_real + loss_fake) / 2\n",
    "        loss_discriminator.backward()\n",
    "        wandb.log({\"loss_discriminator\": loss_discriminator})\n",
    "        \n",
    "        # Train the generator\n",
    "        optimizer.zero_grad()\n",
    "        pred_fake = gan.discriminator(fake_data)\n",
    "        loss_generator = loss_fn(pred_fake, torch.ones_like(pred_fake))\n",
    "        loss_generator.backward()\n",
    "        wandb.log({\"loss_generator\": loss_generator})\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fake data\n",
    "def generate_fake_data(generator, batch_size, n_features):\n",
    "    generator.eval()\n",
    "    noise = torch.randn(batch_size, 100)\n",
    "    fake_data = generator(noise)\n",
    "    return fake_data.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_fake_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/eamonmcandrew/Desktop/Single_cell_integration/Expiriments/Simple_GAN_test.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/eamonmcandrew/Desktop/Single_cell_integration/Expiriments/Simple_GAN_test.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fake_data \u001b[39m=\u001b[39m generate_fake_data(generator, \u001b[39m128\u001b[39m, GEX_Dataset\u001b[39m.\u001b[39mn_features)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_fake_data' is not defined"
     ]
    }
   ],
   "source": [
    "fake_data = generate_fake_data(generator, 128, GEX_Dataset.n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = sc.AnnData(fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(scdata, n_neighbors=10)\n",
    "sc.tl.umap(scdata)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('scINTEGRATION')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d226e3599a48bcd2e3e064e4b49e64b5c23bb1e3c85e4572c7816e0051bede7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
